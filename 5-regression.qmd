# 회귀모형 {#sec-regression}

```{r}
#| echo: false
library(fpp2)
library(tidyverse)
```

## ARMA 오차 회귀모형 {-}

- 예제 : 분기별 호주 맥주 생산량 자료 (`fpp2::ausbeer`)

**1. 백색잡음오차 시계열 회귀모형 적합**

`ausbeer`는 1956년 1분기부터 2010년 2분기까지 호주의 분기별 맥주 생산량이다. 전체 기간 중 1975년 1분기 이후 자료에 대한 회귀모형을 적합시켜보자. 마지막 2년 자료는 test data로 남겨두자.

```{r}
train_b <- window(ausbeer, start = 1975, end = c(2008, 2))
test_b <- window(ausbeer, start = c(2008, 3))
```

@fig-ausbeer-1 은 전체 자료의 시계열 그래프이다. Test data는 빨간 색으로 구분했다.

```{r}
#| label: fig-ausbeer-1
#| fig-cap: "자료 `ausbeer`의 시계열 그래프"
autoplot(train_b) + 
  autolayer(test_b, color = "red", size = 0.8) + 
  labs(y = NULL, x = NULL)
```

시계열자료에 대한 회귀모형의 적합은 함수 `tslm()`으로 할 수 있다. 함수 `tslm()`은 `lm()`과 실질적으로 동일한 함수지만, `ts` 객체에 대한 회귀모형 적합을 위한 함수이다. 잔차 및 적합값이 `ts` 객체로 생성되고, 결측값 처리 방식이 시계열자료에 적합하도록 설정되었다.

추세 변수와 계절 변수를 시점 $t$를 이용하여 생성하는 방법을 살펴보자. 먼저 추세 변수는 함수 `time()`으로 자료가 관측된 시점을 생성할 수 있다. 자료 `train_b`에 대해 함수 `time()`을 적용한 결과를 살펴보자. 1975년 1분기 값을 1975.00으로 두고, 1/4 간격으로 다음 분기의 관측 시점을 생성하고 있다.

```{r}
time(train_b)[1:9]
```

관측 시점을 $t = 1, 2, 3, \ldots$ 로 하여 사용하고자 한다면, `1:length(train_b)`를 추세 변수로 사용하거나, 함수 `tslm()`에서 `trend`를 추세 변수로 사용하면 된다.

계절 변수로 dummy 변수를 사용한다면 함수 `forecast::seasonaldummy()`를 사용하거나, 함수 `tslm()`에서 `season`을 변수로 사용하면 된다. 계절 주기에 맞추어 필요한 dummy 변수를 생성한다.

```{r}
seasonaldummy(train_b)[1:5,]
```

Fourier series 변수를 사용한다면 함수 `forecast::fourier()`를 사용하면 된다. 모형에 포함되는 fourier series 변수들의 최대 주기는 옵션 `K`에 지정하면 된다.

```{r}
fourier(train_b, K = 2)[1:5,]
```

S1-4와 C1-4는 $K=1$ 에 해당하는 $\sin(2\pi t/4)$ 와 $\cos(2\pi t/4)$ 를 의미하고, C2-4는 $K=2$ 에 해당하는 $\cos(2\pi 2t/4)$ 를 나타내고 있다.

함수 `time()`에 의한 추세 변수와 `seasonaldummy()`에 의한 계절 변수를 사용하여 회귀모형을 적합해 보고, 그 결과를 확인해 보자.

```{r}
fit1 <- tslm(train_b ~ time(train_b) + seasonaldummy(train_b))
```

```{r}
summary(fit1)
```

이번에는 변수 `trend`와 `season`을 사용해서 적합해 보고, 결과를 확인해 보자.

```{r}
fit2 <- tslm(train_b ~ trend + season)
```

```{r}
summary(fit2)
```


`fit1`과 `fit2`의 적합 결과가 서로 다른 것처럼 보인다. 그러나 추세의 기울기가 다른 것은 모형에서 사용된 추세 변수의 간격이 다르기 때문이다. 즉, 두 모형의 추세 기울기가 4배 차이 나는 이유는 모형 `fit1`에서 사용된 추세 변수의 간격이 1/4인 반면에 모형 `fit2`에서 사용된 추세 변수의 간격은 1이기 때문이다.

또한 절편이 다른 것은 두 모형의 기준 범주가 다르며, 사용된 추세 변수의 범위가 다르기 때문이다. 즉, `fit1`에서 사용된 추세 변수는 1975.00부터 값을 갖고 있지만, `fit2`에서는 추세 변수가 1부터 값을 갖고 있으며, 함수 `seasonaldummy()`는 마지막 범주를 기준 범주로 설정하는데, 변수 `season`은 첫 번째 범주를 기준 범주로 설정하고 있어서, dummy 변수의 구성도 다르게 된다.

두 모형의 적합값을 비교해 보면 실질적으로 같은 모형임을 알 수 있다.

```{r}
tibble(fit1 = fit1$fitted, fit2 = fit2$fitted)
```

이번에는 함수 `time()`에 의한 추세 변수와 `fourier()`에 의한 Fourier series 변수를 사용하여 회귀모형을 적합해 보고, 그 결과를 확인해 보자. 분기별 자료의 최대 주기인 `K=2`를 지정해서 확인해 보자.

```{r}
fit3 <- tslm(train_b ~ time(train_b) + fourier(train_b, K=2))
```

```{r}
summary(fit3)
```

Fourier series의 모든 변수를 사용한 모형은 dummy 변수를 사용한 모형과 실질적으로 동일한 모형이 된다. `fit1`과 `fit3`의 적합값을 비교해 보자.

```{r}
tibble(fit1 = fit1$fitted, fit3 = fit3$fitted)
```

시계열자료 회귀모형의 모형 진단을 실시해서, 가정 만족에 문제가 있는지 확인해 보자. 함수 `checkresiduals()`는 `lm()` 또는 `tslm()`으로 생성된 객체에 대해서 Breusch-Godfrey 검정으로 독립성을 확인한다.
검정 결과는 오차가 독립이 아니라는 결론이며, 잔차의 시계열 그래프와 ACF에서도 같은 모습을 확인할 수 있다.
시계열자료에 회귀모형을 적합해 생성된 잔차 사이에는 강한 상관 관계가 존재하고 있음을 확인할 수 있었다. 이것은 설명이 안 된 패턴이 남아 있음을 의미하는 것이며, 따라서 추가적인 작업이 필요한 것이다.

```{r}
checkresiduals(fit1)
```


**2.  ARMA 오차 시계열 회귀모형 적합**

자료 `ausbeer`에 대해 적합된 백색잡음 회귀모형은 잔차가 독립성을 만족하지 못하는 문제가 발견되었다. 잔차에 남아 있는 패턴을 ARMA 모형으로 설명하기 위해 ARMA 오차 회귀모형을 적합시켜보자.

```{r}
train_b <- window(ausbeer, start = 1975, end = c(2008, 2))
test_b <- window(ausbeer, start = c(2008, 3))
```

```{r}
fit4 <- auto.arima(train_b,
                   xreg = cbind(Time = time(train_b), 
                                Qtr = seasonaldummy(train_b)),
                   stepwise = FALSE)
```

```{r}
summary(fit4)
```

잔차에 가장 적합한 모형은 ARIMA(3,0,0)(1,0,0)~4~가 선택되었다. 즉, 잔차에 비계절형 요소 뿐 아니라 계절형 요소도 남아 있다는 것이다.

ARMA 오차 회귀모형 `fit4`에 대한 모형 진단을 실시해 보자. 모든 가정이 만족되고 있음을 알 수 있다.

```{r}
checkresiduals(fit4)
```

ARMA 오차 회귀모형의 예측은 함수 `forecast()`로 할 수 있다. 사용법은 `forecast(object, xreg, ...)`가 되는데, `object`에는 함수 `Arima()` 혹은 `auto.arima()`로 생성된 객체를 지정하고, `xreg`에는 예측 시점에 대한 설명변수의 자료를 벡터 또는 행렬의 형태로 지정하면 된다.

Test data인 `test_b`에 대한 예측을 실시해 보자.

```{r}
fc4 <- forecast(fit4, 
                xreg = cbind(Time = time(test_b), 
                             Qtr = seasonaldummy(test_b))
                )
```

ARMA 오차 회귀모형의 예측 결과와 백색잡음 회귀모형의 예측 결과를 비교해 보자. 함수 `tslm()`에 변수 `trend`와 `season`을 사용한 `fit2`에 대한 예측은 다음과 같이 실시할 수 있다.

```{r}
fit2 <- tslm(train_b ~ trend + season)
fc2 <- forecast(fit2, h = length(test_b))
```

점 예측 결과는 `fc2$mean`과 `fc4$mean`에 할당되어 있다. 두 결과를 비교해 보자. 큰 차이는 없는 것으로 보인다.

```{r}
tibble(fc2 = fc2$mean, fc4 = fc4$mean)
```

95% 예측 구간의 폭을 비교해 보자. 예측 구간의 상한은 `fc2$upper`과 `fc4$upper`에 할당되었고, 하한은 `fc2$lower`과 `fc4$lower`에 각각 할당되어 있다. 예측 구간의 신뢰수준으로 80%와 95%가 사용되는 것이 디폴트이며, 따라서 다음과 같이 95% 예측 구간의 폭을 계산할 수 있다. ARMA 오차 회귀모형의 예측 구간인 `fc4`의 폭이 더 좁은 것을 확인할 수 있다.

```{r}
tibble(fc2 = fc2$upper[,2] - fc2$lower[,2], 
       fc4 = fc4$upper[,2] - fc4$lower[,2])
```

예측 오차의 크기를 비교해 보자. 예측 오차의 크기에는 큰 차이가 없음을 알 수 있다.

```{r}
accuracy(fc2, test_b)
```

```{r}
accuracy(fc4, test_b)
```

예측 결과를 그래프로 나타내서 비교해 보자.

```{r}
library(patchwork)
```

```{r}
#| label: fig-ausbeer-2
#| fig-cap: "`ausbeer` 자료에 대한 예측 결과"
#| fig-width: 8
#| fig-height: 4
p1 <- autoplot(fc2, include=8) +
  autolayer(test_b, color = "red", size=.8) +
  labs(y = NULL, x = NULL)

p2 <- autoplot(fc4, include=8) +
  autolayer(test_b, color = "red", size=.8) +
  labs(y = NULL, x = NULL)
p1 + p2
```

-   예제: 1970년 1월부터 2005년 12월까지 지구 기온 자료 (`global.txt`)

`global.txt`는 1856년 1월부터 2005년 12월까지의 지구 기온 자료 자료인데, 그 중 1970년 이후 자료만을 대상으로 ARMA 오차 회귀모형과 ARIMA 모형, 그리고 ETS 모형으로 예측 모형을 각각 적합시키고 예측 결과를 비교해 보자.

자료를 불러 들이고 training data와 test data로 분리시키자.

```{r}
global <- scan("https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/global.txt")
global.ts <- ts(global, start = c(1856, 1), frequency = 12)
train_g <- window(global.ts, start = 1970, end = c(2003,12))
test_g <- window(global.ts, start = 2004)
```

@fig-global-1 은 1970년부터 자료의 시계열 그래프이다. Test data는 빨간 색으로 구분했다.

```{r}
#| label: fig-global-1
#| fig-cap: "자료 `global.txt`의 training data와 test data의 시계열 그래프"
autoplot(train_g) + 
  autolayer(test_g, color = "red", size = .8) +
  labs(x = NULL, y = NULL)
```

**1.  ARMA 오차 회귀모형 적합**

계절 성분이 있는 시계열자료에 회귀모형을 적용할 때에는 계절 성분을 dummy 변수로 나타낼 것인지, Fourier series 변수로 나타낼 것인지를 선택해야 한다.
먼저 선형 추세와 dummy 변수를 사용한 회귀모형을 적합시켜 보자. 추세 변수는 함수 `time()`으로 생성하고, 계절 변수는 함수 `seasonaldummy()`로 생성한다.

```{r}
Time <- time(train_g)
Month <- seasonaldummy(train_g)
```

모형 `fit1`의 적합 과정에서 `stepwise = FASLE`와 `approximation = FALSE`를 제외했는데, 두 옵션을 추가해도 같은 결과를 얻게 된다.

```{r}
fit1 <- auto.arima(train_g, xreg = cbind(Time, Month))
```

```{r}
summary(fit1)
```

잔차는 AR(2) 모형으로 적합되었다.

이번에는 선형 추세와 Fourier series 변수를 사용한 회귀모형을 적합시켜 보자. Fourier series 변수를 사용하기 위해서는 최적 주기를 결정해야 한다.

```{r}
Time <- time(train_g)
res <- vector("numeric", 6)
for(i in seq(res)){
  xreg <- cbind(Time, fourier(train_g, K = i))
  fit <- auto.arima(train_g, xreg = xreg)
  res[i] <- fit$aicc
}
```

객체 `res`에는 6개 모형의 AICc가 입력되어 있다. 그 중 두 번째 모형의 AICc가 가장 작은 값임을 확인할 수 있다.

```{r}
res
```

```{r}
(k_min <- which.min(res))
```

이제 $K=2$ 를 최적 주기로 하는 Fourier series 변수를 사용한 회귀모형을 적합시켜 보자.

```{r}
Fourier <- fourier(train_g, K = k_min)
fit2 <- auto.arima(train_g, xreg = cbind(Time, Fourier))
```

```{r}
summary(fit2)
```

`fit1`의 경우와 동일하게 `fit2`에서도 잔차는 AR(2) 모형으로 적합되었다.

두 모형의 검진을 실시해 보자. 
먼저 선형 추세와 dummy 변수를 사용한 회귀모형인 모형 `fit1`의 모형 검진을 진행해 보자. 
모형 `fit1`의 경우에는 가정 만족에 큰 문제가 없는 것으로 보인다.

```{r}
checkresiduals(fit1)
```

선형 추세와 Fourier series 변수를 사용한 회귀모형인 모형 `fit2`의 모형 검진도 진행해 보자. 
모형 `fit2`에도 큰 문제 없이 가정을 만족하고 있음을 알 수 있다.

```{r}
checkresiduals(fit2)
```

이제 두 회귀모형 중 한 모형을 선택해 보자. 선택 기준으로는 AICc를 사용해 보자.

```{r}
c(fit1$aicc, fit2$aicc)
```

모형 `fit2`의 AICc가 더 작게 계산되었고, 따라서 최종 예측 모형으로 선택하자. 

```{r}
fit_reg <- fit2
```

**2.  ARIMA 모형의 적합**

차분 및 계절 차분이 필요한지 여부를 확인해 보자.

```{r}
ggtsdisplay(train_g)
```

뚜렷한 추세가 시계열 그래프에서 보이며, 표본 ACF 그래프에서 매우 큰 값의 $r_{1}$ 과 천천히 감소하는 모습에서 1차 차분이 필요한 것을 알 수 있다. 그러나 계절 차분이 필요한지 여부는 명확하게 보이지 않는다. 단위근 검정 결과를 확인해 보자.

```{r}
ndiffs(train_g)
nsdiffs(train_g)
```

1차 차분은 필요하지만, 계절 차분은 필요 없는 것로 나타났다. 이제 1차 차분을 실시한 자료를 대상으로 시계열 그래프와 ACF, PACF를 작성해 보자. 정상성이 만족된 것으로 보인다.

```{r}
train_g %>% 
  diff() %>% 
  ggtsdisplay()
```

이제 잔차의 표본 ACF와 PACF를 이용해서 모형 식별을 시도해 보자. 비계절 요소는 1시차에서 6시차까지의 패턴으로 인식하게 되는데, ACF는 3시차까지 모두 유의하고, PACF는 1시차와 3시차가 유의한 것으로 나타났다. 이러한 경우에는 ACF를 감소, PACF는 감소 또는 3시차에서 절단으로 볼 수 있으며, 따라서 ARMA 모형이나 AR 모형이 가능할 것으로 보인다. 계절형 요소는 12, 24, 36시차에서 ACF와 PACF가 모두 매우 작은 값을 갖고 있기 때문에, 계절형 요소가 없는 것으로 볼 수도 있고, AR(1)~12~ 또는 MA(1)~12~로 볼 수도 있는 상황이다.

함수 `auto.arima()`를 사용해서 AICc가 가장 작은 모형을 찾아 보자.

```{r}
fit_arima <- auto.arima(train_g,
                        stepwise = FALSE,
                        approximation = FALSE)
```

적합 결과는 비계절형 요소만 있는 ARIMA(2,1,1)이 선택된 것을 알 수 있다. 

```{r}
fit_arima
```

모형 `fit_arima`에 대한 검진을 실시해 보자. 모든 가정이 만족되고 있음을 볼 수 있다.

```{r}
checkresiduals(fit_arima)
```

**3.  ETS 모형의 적합**

함수 `ets()`로 AICc가 최소인 모형을 선택해 보자.

```{r}
fit_ets <- ets(train_g)
```

최적 모형은 `r fit_ets$method`이 선택되었다.

```{r}
fit_ets
```

모형 `fit_ets`에 대한 검진을 실시해 보자.

```{r}
checkresiduals(fit_ets)
```

독립성 가정에 문제가 있는 것으로 나타났다.
독립성 가정을 만족시키지 못하는 모형의 경우에는 예측의 신빙성에 문제가 있을 수 있는데, 점 예측 (point forecast) 결과보다 예측 구간에 더 큰 문제가 있을 수 있다. 간혹 모든 가정을 만족시키는 모형을 찾지 못하는 경우도 있는데, 이런 경우에는 예측 결과를 적용할 때 조심할 필요가 있다.

이제 세 가지 모형인 `fit_reg`, `fit_arima`, `fit_ets`에 의한 예측을 실시하고, 결과를 비교해 보자.

```{r}
new_reg <- cbind(Time = time(test_g), 
                Fourier = fourier(test_g, K = k_min)) 
fc_reg <- forecast(fit_reg, xreg = new_reg)
fc_arima <- forecast(fit_arima, h = length(test_g))
fc_ets <- forecast(fit_ets, h = length(test_g))
```

예측 오차를 비교해 보자.

```{r}
accuracy(fc_reg, test_g)
```

```{r}
accuracy(fc_arima, test_g)
```

```{r}
accuracy(fc_ets, test_g)
```

Test data에 대한 예측 결과를 비교해 보면, 전체적으로 큰 차이는 없는 것으로 보인다. MASE로는 ARMA 오차 회귀모형이 ARIMA 모형 보다 조금 작은 값을 보이고 있으나, RMSE와 MAPE로는 ARIMA 모형이 조금 작은 값을 보이고 있다.
예측 결과를 test data와 함께 표시한 그래프는 @fig-global-2 에서 볼 수 있다. 
예측 구간의 폭을 비교할 수 있도록 세 그래프의 Y축 구간은 동일하게 설정하였다.  

```{r}
#| label: fig-global-2
#| fig-cap: "자료 `global.txt`에 대한 세 모형의 예측 결과"
#| fig-width: 8
#| fig-height: 8
y_lim <- c(-.06, 1.06)
p1 <- autoplot(fc_reg, include = 12) + 
  autolayer(test_g, color = "red", size = .8) +
  labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2])
p2 <- autoplot(fc_arima, include = 12) + 
  autolayer(test_g, color = "red", size = .8) +
  labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2])
p3 <- autoplot(fc_ets, include=12) + 
  autolayer(test_g, color = "red", size = .8) +
  labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2])

p1 / p2 / p3
```

-   예제: 1949년부터 1960년 월별 국제선 탑승자 수 자료 (`AirPassengers`)

`AirPassengers`는 1949년 1월부터 1960년 12월까지 월별 국제선 탑승자 수 자료이다. ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형에 의한 예측 모형을 적합시키고, 예측 결과를 비교해 보자. 예측 결과의 평가를 위해 마지막 2년 자료는 test data로 남겨두자.

```{r}
train_AP <- window(AirPassengers, end = c(1958, 12))
test_AP <- window(AirPassengers, start = c(1959, 1))
```

전체 기간에 대한 시계열 그래프를 @fig-AP-1 에 작성해 보자. Test data는 빨간 색으로 구분하였다.

```{r}
#| label: fig-AP-1
#| fig-cap: "자료 `AirPassengers`의 시계열 그래프"
autoplot(train_AP) + 
  autolayer(test_AP, color = "red", size = .8) +
  labs(x = NULL, y = NULL)
```

증가 추세가 있고, 명확한 계절 성분이 있는 자료이다. 또한 계절 변동 폭이 추세가 증가함에 따라 점점 커지고 있음도 알 수 있다. 따라서 분산 안정화가 필요한 자료이다.
분산 안정화를 위해 Box-Cox 변환 모수를 추정해 보자.

```{r}
(lam <- BoxCox.lambda(train_AP))
```

변환 모수가 $\lambda=$ `r lam` 로 추정되었다. 추정된 변환 모수에 의한 변환 결과와 로그 변환에 의한 결과를 비교해 보자. @fig-AP-2 에서 볼 수 있듯이 두 변환 결과는 크게 차이가 나지 않는 것으로 보인다. 이런 경우에는 변환 결과에 대한 해석이 가능한 로그 변환을 선택하는 것이 일반적이라고 하겠다.

```{r}
#| label: fig-AP-2
#| fig-cap: 분산 안정화 변환
#| fig-width: 8
#| fig-height: 4
p1 <- BoxCox(train_AP, lambda = lam) %>% 
  autoplot() + 
  labs(title = paste("Box-Cox", "lambda = ", signif(lam, 3)), x = NULL)
p2 <- train_AP %>% 
  log() %>% 
  autoplot() + labs(title = "Log", x = NULL)
p1+p2
```

**1.  ETS 모형 적합**

ETS 모형은 계절 성분을 승법 형태로 설명할 수 있는 모형이기 때문에, 계절 성분의 진폭 안정화가 반드시 필요한 모형은 아니다. 또한 모수에 대한 해석보다 예측이 주된 용도이기 때문에, 분산 안정화 변환 결과에 대한 해석이 그렇게 중요한 요소가 되지 않는다. 따라서 원자료에 대한 ETS 모형과 Box-Cox 변환 자료에 대한 ETS 모형, 그리고 로그 변환 자료에 대한 ETS 모형을 각각 적합하고 예측 결과를 비교해 보자.

```{r}
ets_1 <- ets(train_AP, lambda = lam) 
ets_fc1 <- forecast(ets_1, h = length(test_AP)) 

ets_2 <- ets(train_AP, lambda = 0)
ets_fc2 <- forecast(ets_2, h = length(test_AP)) 

ets_3 <- ets(train_AP)
ets_fc3 <- forecast(ets_3, h = length(test_AP)) 
```

@fig-AP-3 는 세 가지 ETS 모형의 예측 결과를 test data와 함께 나타낸 그래프이다. Box-Cox 변환 자료에 대한 ETS 모형의 예측 결과가 test data와 가장 근접한 것으로 보인다. Test data를 이용해서 모형을 선택하는 것이 바람직한 방식은 아니지만, 모형 비교를 위한 다른 마땅한 방법이 없는 상황을 고려하였다.

```{r}
#| label: fig-AP-3
#| fig-cap: "`AirPassengers` 자료에 대한 ETS 모형의 예측 결과 비교"
#| fig-width: 8
#| fig-height: 9
p1 <- autoplot(ets_fc1, include = 0) +
  autolayer(test_AP, color = "red", size = .8) + labs(y = NULL, subtitle = "ets_fc1")
p2 <- autoplot(ets_fc2, include = 0) +
  autolayer(test_AP, color = "red", size = .8) + labs(y = NULL, subtitle = "ets_fc2")
p3 <- autoplot(ets_fc3, include = 0) +
  autolayer(test_AP, color = "red", size = .8) + labs(y = NULL, subtitle = "ets_fc3")
p1/p2/p3
```

Box-Cox 변환 자료에 대한 ETS 모형을 최적 ETS 모형으로 선택하고, 모형 진단을 실시해 보자.
독립성 가정을 위반하는 것으로 나타났다.

```{r}
fit_ets <- ets(train_AP, lambda = lam)
```

```{r}
checkresiduals(fit_ets)
```


**2.  ARMA 오차 회귀모형 적합**

회귀모형은 분산 안정화가 필수적인 모형이며, 변환 결과에 대한 해석도 필요한 모형이다. 따라서 로그 변환된 자료를 대상으로 모형 적합을 진행해 보자.

계절 성분을 dummy 변수로 나타내는 모형을 적합해 보자.

```{r}
Time <- time(train_AP)
Month <- seasonaldummy(train_AP)
fit_r1 <- auto.arima(train_AP, xreg = cbind(Time, Month),
                     lambda = 0) 
```

`stepwise = FALSE`를 포함시키면 실행 시간이 지나치게 오래 걸리기 때문에 제외했다. 적합 결과를 살펴보자.

```{r}
fit_r1
```

잔차에 계절형과 비계절형 요소가 모두 남아 있는 것을 알 수 있다. 모형 검진을 실시해 보자. 큰 문제는 없는 것으로 보인다.

```{r}
checkresiduals(fit_r1)
```

이번에는 Fourier series 변수를 사용한 회귀모형을 적합해 보자. 먼저 최적 차수를 확인하자.

```{r}
Time <- time(train_AP)
res <- vector("numeric", 6)
for(i in seq(res)){
  xreg <- cbind(Time, fourier(train_AP, K = i))
  fit <- auto.arima(train_AP, xreg = xreg, 
                    lambda = 0)
  res[i] <- fit$aicc
}
```

```{r}
(min_k <- which.min(res))
```


$K=5$ 가 최적 차수로 확인되었다. 최적 차수에 의한 Fourier series 변수를 사용한 회귀모형을 적합하고 결과를 확인해 보자.

```{r}
Time <- time(train_AP)
Fourier <- fourier(train_AP, K = min_k)
fit_r2 <- auto.arima(train_AP, xreg = cbind(Time, Fourier),
                     lambda = 0)
```

```{r}
summary(fit_r2)
```

잔차에 계절형과 비계절형 요소가 모두 남아 있는 것을 알 수 있다. 모형 검진을 실시해 보자. 큰 문제가 없는 것으로 보인다.

```{r}
checkresiduals(fit_r2)
```

이제 두 모형 중 한 모형을 최적 모형으로 선택해야 한다. 사실 두 모형은 거의 동일한 모형이다. 두 번째 모형이 11개의 Fourier series 변수 중 10개 사용한 모형이기 때문인데, 만일 $K=6$ 이 선택되어 11개의 Fourier series 변수를 모두 사용한다면 dummy 변수를 사용한 모형과 사실상 동일한 모형이 된다. 두 모형의 AICc를 근거로 한 모형을 선택해 보자.

```{r}
c(fit_r1$aicc, fit_r2$aicc)
```

두 번째 모형의 AICc가 조금 더 작은 값으로 계산되었다. 따라서 Fourier series 변수를 사용한 모형을 최적 회귀모형으로 선택하자.

```{r}
fit_reg <- fit_r2
```

**3.  ARIMA 모형 적합**

ARIMA 모형도 회귀모형의 경우처럼 분산 안정화가 필수적인 모형이며, 변환 결과에 대한 해석도 필요한 모형이다. 따라서 로그 변환된 자료를 대상으로 모형 적합을 진행해 보자. 우선 로그 변환된 자료에 대한 시계열 그래프와 표본 ACF를 작성해 보자.

```{r}
train_AP %>% 
  log() %>% 
  ggtsdisplay()
```

뚜렷한 추세와 계절 성분이 있는 자료임을 알 수 있다. 계절 차분을 실시하고, 그 결과를 확인해 보자.

```{r}
train_AP %>% 
  log() %>% 
  diff(lag = 12) %>% 
  ggtsdisplay()
```

시계열 그래프와 ACF로는 1차 차분이 더 필요한지 여부를 확실하게 결정하기 어려워 보인다.
이런 상황에서는 계절 차분만 실시한 자료에 대한 ARIMA 모형 적합도 시도해 볼 필요가 있는 것으로 보인다.

계절 차분된 자료에 1차 차분을 추가로 실시하고, 그 결과를 확인해 보자. 비정상성 요소가 완전히 제거된 것을 볼 수 있다.

```{r}
train_AP %>% 
  log() %>% 
  diff(lag = 12) %>% 
  diff() %>% 
  ggtsdisplay()
```

단위근 검정 결과를 확인해 보자. 계절 차분과 1차 차분이 모두 필요한 것으로 나타난다.

```{r}
train_AP %>% 
  log() %>% 
  ndiffs()
```

```{r}
train_AP %>% 
  log() %>% 
  nsdiffs()
```

단위근 검정 결과에도 불구하고 1차 차분이 명확하게 필요한 상황으로 판단하기 어렵다고 보고, 계절 차분만 실시한 경우와 계절 차분과 1차 차분을 모두 실시한 경우에 대해서 각각 ARIMA 모형을 적합시켜 보자. 
먼저 계절 차분과 1차 차분을 모두 실시한 자료를 대상으로 ARIMA 모형을 적합해 보자.

```{r}
fit_a1 <- auto.arima(train_AP, lambda = 0, 
                    stepwise = FALSE)
```

적합 결과는 다음과 같다.

```{r}
summary(fit_a1)
```

모형 검진 결과에서는 어떤 문제도 발견되지 않았다.

```{r}
checkresiduals(fit_a1)
```

이번에는 계절 차분만을 실시한 자료를 대상으로 ARIMA 모형을 적합해 보자.

```{r}
fit_a2 <- auto.arima(train_AP, d = 0, lambda = 0, 
                     stepwise = FALSE)
```

적합 결과는 다음과 같다.

```{r}
fit_a2
```

모형 검진을 실시해 보면, 모든 가정이 만족되는 것으로 보인다.

```{r}
checkresiduals(fit_a2)
```

이제 두 모형 중 하나의 모형을 선택해 보자. 두 모형은 차분을 실시한 횟수가 각기 다른 자료를 사용한 것이기 때문에 AICc 등의 비교는 의미가 없다. 따라서 Test data를 대상으로 더 근접한 예측 결과를 산출하는 모형을 선택하기로 하자.

```{r}
fc_a1 <- forecast(fit_a1, h = length(test_AP))
fc_a2 <- forecast(fit_a2, h = length(test_AP))
```

```{r}
#| label: fig-AP-4
#| fig-cap: ARIMA 모형의 예측 결과
#| fig-width: 8
#| fig-height: 4

p1 <- autoplot(fc_a1, include = 0) +
  autolayer(test_AP, color = "red", size = 1) +
  labs(y = NULL, subtitle = "fc_a1")
p2 <- autoplot(fc_a2, include = 0) +
  autolayer(test_AP, color = "red", size = 1) +
  labs(y = NULL, subtitle = "fc_a2")

p1 + p2
```

두 번째 모형인 ARIMA(2,0,0)(0,1,1)~12~의 예측 결과가 test data에 더 근접한 것으로 보인다.

```{r}
fit_arima <- fit_a2
```

이제는 ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형의 예측 결과를 비교해 보자.

```{r}
new_t <- cbind(Time = time(test_AP), 
               Fourier = fourier(test_AP, K = min_k))
fc_reg <- forecast(fit_r2, xreg = new_t)

fc_ets <- forecast(fit_ets, h = length(test_AP))
fc_arima <- forecast(fit_arima, h = length(test_AP))
```

```{r}
accuracy(fc_reg, test_AP)
```

```{r}
accuracy(fc_ets, test_AP)
```

```{r}
accuracy(fc_arima, test_AP)
```

ARIMA 모형의 예측 오차가 가장 작은 것으로 나타났다. 예측 결과를 그래프로 비교해 보자.

```{r}
#| label: fig-AP-5
#| fig-cap: "`AirPassengers` 자료에 대한 예측 결과 비교"
#| fig-width: 8
#| fig-height: 4

p1 <- autoplot(fc_reg, include = 0) + 
  autolayer(test_AP, color = "red", size = 1) +
  labs(x=NULL, y=NULL) 
p2 <- autoplot(fc_arima, include = 0) + 
  autolayer(test_AP, color = "red", size = 1) +
  labs(x=NULL, y=NULL) 
p3 <- autoplot(fc_ets, include = 0) + 
  autolayer(test_AP, color = "red", size = 1) +
  labs(x=NULL, y=NULL)

p1 + p2 + p3
```

## ARMA 오차 Dynamic 회귀모형 {-}


-   예제 : 2014년 호주 빅토리아주의 일일 전기 수요량 자료 (`fpp2::elecdaily`)

`elecdaily`는 $365 \times 3$ 의 ts 객체 행렬이다. 처음 3개 행을 출력해 보자.

```{r}
elecdaily[1:3,]
```

첫 번째 열인 `Demand`는 일일 전기 수요량이고, 두 번째 열인 `WorkDay`는 휴일이면 0, 근무일이면 1을 값으로 갖고 있으며, 세 번째 열인 `Temperature`는 당일 최고 기온이다. 
세 변수의 시계열 그래프를 @fig-elecd-1 에 작성해 보자.

```{r}
#| label: fig-elecd-1
#| fig-cap: "자료 `elecdaily`를 구성하고 있는 세 변수의 시계열 그래프"
autoplot(elecdaily, facets = TRUE)
```

시계열자료 행렬 `elecdaily`의 각 열을 개별 시계열자료로 분리해 보자.

```{r}
Demand <- elecdaily[,1]
Work <- elecdaily[,2]
Temp <- elecdaily[,3]
```

세 시계열자료는 동일한 기간과 주기를 갖고 있는데, 변수 `Demand`로 확인해 보자.

```{r}
start(Demand); end(Demand); frequency(Demand)
```

시작 시점은 2014년 첫 번째 주 네 번째 날이고, 종료 시점은 2014년 53번째 주 네 번째 날이다. 일일 자료이므로 주기는 7로 설정되어 있다. 주 중 네 번째 날의 요일은 다음과 같이 패키지 `lubridate`의 함수 `wday()`로 할 수 있다.

```{r}
library(lubridate)
wday(ymd("2014-1-1"), label = TRUE)
```

반응변수인 `Demand`와 셜명변수인 `Temp`의 정상성 만족 여부를 확인해 보자. 두 변수 모두 차분이 필요한 것으로 보인다.

```{r}
Demand %>% 
  ggtsdisplay(main = "Demand")
```

```{r}
Temp %>% 
  ggtsdisplay(main = "Temperature")
```

단위근 검정 결과도 확인해 보자.

```{r}
ndiffs(Demand)
ndiffs(Temp)
```

이제 두 변수의 관계를 산점도를 이용해서 살펴보자. @fig-elecd-2 에서 두 변수 사이에 2차 함수의 관계가 있음을 볼 수 있다. 회귀모형에 변수 `Temp`의 제곱항도 포함시켜야 할 것으로 보인다.

```{r}
#| label: fig-elecd-2
#| fig-cap: "`Demand`와 `Temperature`의 산점도"
tibble(Demand, Temp) %>% 
  ggplot(aes(x = as.numeric(Temp), y = as.numeric(Demand))) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(x = "Temperature", y = "Demand")
```

Dynamic 회귀모형을 적합시켜보자. 함수 `auto.arima()`에 설명변수 `Temp`와 `Temp^2`, `Work`를 행렬 형태로 `xreg`에 지정해 보자.

```{r}
xreg <- cbind(Temp, Temp2 = Temp^2, Work)
fit <- auto.arima(Demand, xreg = xreg, stepwise = FALSE)
```

적합 결과를 확인해 보자.

```{r}
summary(fit)
```

적합된 회귀모형에 절편이 없는 것을 볼 수 있는데, 이것은 차분을 실시한 자료를 대상으로 회귀모형을 적합시켰기 때문이다.

적합된 모형의 진단을 실시해 보자. 독립성 가정에는 문제가 있는 것으로 보인다.

```{r}
checkresiduals(fit)
```

이제 적합된 Dynamic 회귀모형을 이용해서 2015년 1월 1이부터 1월 10일까지의 전력 수요량을 예측해 보자. 이 때 문제가 되는 것은 해당 기간에 대한 변수 `Temp`의 값도 미리 알 수 없다는 것이다. 이 문제는 변수 `Temp`의 미래 값을 다른 방법으로 예측해서 사용하거나, 특정한 값으로 가정하고 `Demand`의 미래 값을 예측해야 한다.

여기에서는 2014년 1월 1일부터 1월 10일까지의 `Temp` 값을 그대로 사용해서 예측을 실시해 보자. 변수 `Work`의 값은 2015년 1월 1일 목요일부터 1월 10일 토요일까지 휴일과 근무일을 구분해서 입력할 수 있다.

```{r}
old_T <- Temp[1:10]
new_x <- cbind(Temp = old_T, Temp2 = old_T^2,
               Work = c(0,1,0,0,1,1,1,1,1,0))
fc <- forecast(fit, xreg = new_x)
```

예측 결과에 대한 그래프를 작성해 보자.

```{r}
#| label: fig-elecd-3
#| fig-cap: "`Demand`의 예측 결과"
autoplot(fc)
```

-   예제: 미국 소득, 소비 등의 1970년 1분기부터 2016년 3분기까지 분기별 변화 비율 (`fpp2::uschange`)

`uschange`는 $187 \times 5$ 의 ts 객체 행렬이다.

```{r}
uschange[1:3,]
```

다섯 개 시계열자료는 동일한 시작 시점, 종료 시점과 주기를 갖고 있는데, 첫 번째 시계열자료를 이용해서 확인해 보자. 분기별 자료이므로 주기는 4이고, 시작 시점은 1970년 1분기이며, 종료 시점은 2016년 3분기이다.

```{r}
start(uschange[,1])
end(uschange[,1])
frequency(uschange[,1])
```

첫 번째 시계열자료인 `Consumption`에 대한 예측 모형을 적합해 보자. ARIMA 모형과 ETS 모형에 의한 예측 모형, ARMA 오차 회귀모형, 그리고 행렬 `uschange`의 다른 시계열자료를 설명변수로 사용하는 dynamic 회귀모형에 의한 예측 모형을 적합해 보자.

`uschange`를 구성하고 있는 다섯 변수의 시계열 그래프를 @fig-uschange-1 에 작성해 보자.
뚜렷한 추세나 계절 성분이 있는 시계열자료는 없는 것으로 보인다.

```{r}
#| label: fig-uschange-1
#| fig-cap: "`uschange`의 다섯 시계열자료의 그래프"
autoplot(uschange, facets=TRUE) + 
  labs(y = NULL, x = NULL)
```

다섯 시계열자료의 ACF는 함수 `ggAcf()`에 개별 시계열자료를 각각 입력해서 작성할 수도 있지만, 조금은 번거로운 작업이 된다. 대신 함수 `ggAcf()`에 행렬 `uschange`를 그대로 입력하면 두 변수씩의 모든 조합에 대한 상관 행렬이 작성되는데, 그 중 대각 패널에 각 변수의 ACF가 작성된다. 

```{r}
#| label: fig-uschange-2
#| fig-cap: "`uschange`의 다섯 시계열자료의 표본 ACF"
ggAcf(uschange)
```

@fig-uschange-1 과 @fig-uschange-2 을 근거로 다섯 시계열자료는 모두 정상성을 만족하고 있는 것으로 보인다.

Dynamic 회귀모형에서 설명변수로 사용할 수 있는 시계열자료는 `Income`, `Production`, `Savings`, 그리고 `Unemployment`이다. 함수 `GGally::ggpairs()`로 다섯 변수의 산점도 행렬을 작성해 보자.

```{r}
#| label: fig-uschange-3
#| fig-cap: "`uschange`의 다섯 시계열자료의 산점도 행렬"
#| fig-width: 8
#| fig-height: 6
GGally::ggpairs(as_tibble(uschange) %>% 
                  relocate(Consumption, .after=last_col()),
                lower=list(continuous="smooth_loess"))
```

변수 (`Income`, `Savings`)과 (`Production`, `Uneployment`) 사이에 높은 관련성이 있는 것으로 보여서, 변수 `Income`과 `Production`만을 설명변수로 포함시키고자 한다. 엄격하고 타당한 변수 선택 방식은 아니지만 가능하면 간단한 모형을 구성하고자 한다.

이제 자료를 분리하고 예측 모형을 적합시켜보자.

```{r}
uschange_te <- tail(uschange, n = 8)
uschange_tr <- head(uschange, n = nrow(uschange)-8)
```

ARIMA 모형을 적합하고, 결과를 확인해 보자.

```{r}
fit_arima <- auto.arima(uschange_tr[,1], 
                   stepwise = FALSE, approximation = FALSE)
```

```{r}
fit_arima
```

ETS 모형을 적합하고, 결과를 확인해 보자.

```{r}
fit_ets <- ets(uschange_tr[,1])
```

```{r}
fit_ets
```

관측 시점만을 설명변수로 사용하는 ARMA 오차 회귀모형을 적합해 보자. 추세 변수는 함수 `time()`으로 생성하고, 계절 성분은 dummy 변수로 표현해 보자.

```{r}
Time <-  time(uschange_tr[,1])
Qtr <-  seasonaldummy(uschange_tr[,1])
```

```{r}
fit_reg <- auto.arima(uschange_tr[,1],
                      xreg = cbind(Time, Qtr),
                      stepwise = FALSE, approximation = FALSE)
```

```{r}
fit_reg
```

Dynamic 회귀모형도 적합해 보자.

```{r}
fit_dyn <- auto.arima(uschange_tr[,1], d = 0,     
                   xreg = uschange_tr[,c(2,3)], 
                   stepwise = FALSE, approximation = FALSE)
```

```{r}
fit_dyn
```

적합시킨 네 모형에 대한 모형 검진도 실시해 보자.
다른 가정 사항에는 모든 모형에 문제가 없는 것으로 나타났지만,
Ljung-Box 검정 결과에서 ETS 모형이 독립성 가정을 위반하고 있는 것으로 보인다. 

```{r}
checkresiduals(fit_arima)
```

```{r}
checkresiduals(fit_ets)
```

```{r}
checkresiduals(fit_reg)
```

```{r}
checkresiduals(fit_dyn)
```

이제 test data에 대한 예측을 실시해 보자. 모형 `fit_dyn`의 경우에는 test data 시점에서 설명변수의 관측 문제가 있지만, 다른 모형과의 비교를 위해서 설명변수의 값이 알려져 있다고 가정하겠다. 이 가정으로 모형 `fit_dyn`의 예측은 결과가 더 좋게 나올 수 있다.

```{r}
fc_arima <- forecast(fit_arima, h = 8)
fc_ets <- forecast(fit_ets, h = 8)
fc_dyn <- forecast(fit_dyn, 
                   xreg = uschange_te[,c(2,3)])
```

```{r}
Time <-  time(uschange_te[,1])
Qtr <-  seasonaldummy(uschange_te[,1])
fc_reg <- forecast(fit_reg, 
                   xreg = cbind(Time, Qtr))
```

예측 결과를 test data와 비교해 보자.
모형 `fit_dyn`의 예측 오류가 가장 작은 것으로 나타났다. 
ETS 모형도 예측 오류가 다른 모형보다 비교적 작은 것으로 나타났다.

```{r}
accuracy(fc_arima, uschange_te[,1])
```

```{r}
accuracy(fc_ets, uschange_te[,1])
```

```{r}
accuracy(fc_reg, uschange_te[,1])
```

```{r}
accuracy(fc_dyn, uschange_te[,1])
```

예측 결과를 그래프로 나타내서 비교해 보자.
ETS 모형의 경우 비교적 작은 예측 오류가 나왔지만 모든 시점에서 동일한 예측 결과을 보이는 모형이 선택되었고, 예측 구간의 폭이 가장 넓다는 점을 고려한다면, 바람직한 예측 모형은 아니라고 하겠다.  


```{r}
#| label: fig-uschange-4
#| fig-cap: "`uschange`의 `Consumption`에 대한 예측 결과 비교"
#| fig-width: 8
#| fig-height: 8

y_lim <- c(-1, 2.5)
p1 <- autoplot(fc_arima, include = 8) + 
  autolayer(uschange_te[,1], color = "red", size = .8) + 
  ylab(NULL) + ylim(y_lim[1], y_lim[2])
p2 <- autoplot(fc_ets, include = 8) + 
  autolayer(uschange_te[,1], color = "red", size = .8) + 
  ylab(NULL) + ylim(y_lim[1], y_lim[2])
p3 <- autoplot(fc_reg, include = 8) + 
  autolayer(uschange_te[,1], color = "red", size = .8) + 
  ylab(NULL) + ylim(y_lim[1], y_lim[2])
p4 <- autoplot(fc_dyn, include = 8) + 
  autolayer(uschange_te[,1], color = "red", size = .8) + 
  ylab(NULL) + ylim(y_lim[1], y_lim[2])

(p1 + p2) / (p3 + p4)
```

