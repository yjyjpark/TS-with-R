[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "머리말\n\n\n\n\n시간의 흐름에 따라 관측되는 시계열자료는 경영\\(\\cdot\\)경제 분야 뿐 아니라 이제는 다른 많은 분야에서도 흔히 접할 수 있는 형태의 자료이다. 시계열자료의 가장 큰 특징은 자료들 사이에 강한 상관관계가 존재할 수 있다는 것인데, 이런 특징으로 인하여 선형회귀모형과 같이 자료의 독립성을 가정으로 하고 있는 모형으로는 시계열자료의 분석에 한계가 있다.\n이 책에서는 시계열자료의 예측 모형으로 가장 많이 사용되는 ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형을 다루고 있으며, 특히 시계열분석에서 가장 많이 사용되는 R 패키지 중 하나인 패키지 forecast의 다양한 함수의 활용 방법을 소개하고 있다.\n이 책은 교우사에서 출판한 “R로 알아가는 시계열분석”에서 사용된 실습 예제만을 추려서 독자들의 R 실습에 작은 도움이 되고자, Quarto을 사용하여 Rstudio에서 작성되었다. 또한 이 책애서는 R의 기초적인 사용법 및 패키지 tidyverse에 대한 소개 없이 사용하고 있으며, R code에는 프롬프트(> 또는 +)를 제거하였고, console 창에 출력되는 실행 결과물은 ##으로 시작되도록 하였다.\n제공된 R code를 쉽게 복사하는 방법은 R code 블록에 마우스를 놓으면 아래 그림과 같이 우측 상단에 기호가 나타나는데, 그 기호를 클릭하는 것이다.\n\n이 책을 작성할 때의 R 세션 정보는 다음과 같다.\n\nsessionInfo()\n## R version 4.2.2 (2022-10-31 ucrt)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows 10 x64 (build 22621)\n## \n## Matrix products: default\n## \n## locale:\n## [1] LC_COLLATE=Korean_Korea.utf8  LC_CTYPE=Korean_Korea.utf8   \n## [3] LC_MONETARY=Korean_Korea.utf8 LC_NUMERIC=C                 \n## [5] LC_TIME=Korean_Korea.utf8    \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] expsmooth_2.3   fma_2.4         forecast_8.19   fpp2_2.4       \n##  [5] forcats_0.5.2   stringr_1.5.0   dplyr_1.0.10    purrr_0.3.5    \n##  [9] readr_2.1.3     tidyr_1.2.1     tibble_3.1.8    ggplot2_3.4.0  \n## [13] tidyverse_1.3.2\n## \n## loaded via a namespace (and not attached):\n##  [1] tseries_0.10-52     httr_1.4.4          jsonlite_1.8.4     \n##  [4] modelr_0.1.10       assertthat_0.2.1    TTR_0.24.3         \n##  [7] googlesheets4_1.0.1 cellranger_1.1.0    yaml_2.3.6         \n## [10] pillar_1.8.1        backports_1.4.1     lattice_0.20-45    \n## [13] glue_1.6.2          quadprog_1.5-8      digest_0.6.30      \n## [16] rvest_1.0.3         colorspace_2.0-3    htmltools_0.5.4    \n## [19] timeDate_4021.107   pkgconfig_2.0.3     broom_1.0.1        \n## [22] haven_2.5.1         scales_1.2.1        tzdb_0.3.0         \n## [25] timechange_0.1.1    googledrive_2.0.0   generics_0.1.3     \n## [28] ellipsis_0.3.2      withr_2.5.0         urca_1.3-3         \n## [31] nnet_7.3-18         cli_3.4.1           quantmod_0.4.20    \n## [34] magrittr_2.0.3      crayon_1.5.2        readxl_1.4.1       \n## [37] evaluate_0.18       fs_1.5.2            fansi_1.0.3        \n## [40] nlme_3.1-160        xts_0.12.2          xml2_1.3.3         \n## [43] tools_4.2.2         hms_1.1.2           gargle_1.2.1       \n## [46] lifecycle_1.0.3     munsell_0.5.0       reprex_2.0.2       \n## [49] compiler_4.2.2      rlang_1.0.6         grid_4.2.2         \n## [52] rstudioapi_0.14     htmlwidgets_1.5.4   rmarkdown_2.18     \n## [55] gtable_0.3.1        fracdiff_1.5-2      curl_4.3.3         \n## [58] DBI_1.1.3           R6_2.5.1            zoo_1.8-11         \n## [61] lubridate_1.9.0     knitr_1.41          fastmap_1.1.0      \n## [64] utf8_1.2.2          stringi_1.7.8       parallel_4.2.2     \n## [67] Rcpp_1.0.9          vctrs_0.5.1         dbplyr_2.2.1       \n## [70] tidyselect_1.2.0    xfun_0.35           lmtest_0.9-40"
  },
  {
    "objectID": "1-tsplot.html",
    "href": "1-tsplot.html",
    "title": "",
    "section": "",
    "text": "예제: 백화점 매출액 자료\n\ndepart.txt는 어떤 백화점의 1984년 1월부터 1988년 12월까지의 월별 매출액이 입력되어 있다. 함수 scan()을 사용하여 자료를 R로 불러오자. 함수 scan()은 한 변수로 이루어진 텍스트 파일을 R로 불러올 때 사용할 수 있는 함수이다.\n\ndepart <- scan(\"https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/depart.txt\")\n\n이제 벡터 depart를 함수 ts()를 사용하여 ts 객체로 변환시켜보자.\n\ndepart.ts <- ts(depart, start = c(1984, 1), frequency = 12)\ndepart.ts\n##       Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n## 1984  423  458  607  564  536  536  804  540  488  627  672 1447\n## 1985  514  518  699  654  612  612  884  605  547  705  698 1555\n## 1986  561  564  773  717  665  667  994  661  616  786  806 1754\n## 1987  622  636  874  831  769  779 1142  764  718  930  943 2039\n## 1988  736  752 1057  947  868  931 1311  896  867 1073 1069 2333\n\n\n\n\n\n예제: 백화점 매출액 자료\n\n백화점 매출액 자료인 depart.ts의 시계열 그래프를 Figure 1 에 작성해 보자.\n\nlibrary(fpp2)\nautoplot(depart.ts) +\n  labs(title = \"Monthly sales of a department store\", \n       x = \"Year\", y = NULL)\n\n\n\n\nFigure 1: 백화점 월별 매출액\n\n\n\n\n\n예제: 지구 온도 자료\n\n1856년 1월부터 2005년 12월까지 지구 온도 자료가 global.txt에 입력되어 있다. 이 자료의 시계열 그래프를 Figure 2 에 작성해 보자.\n\nglobal <- scan(\"https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/global.txt\")\nglobal.ts <- ts(global, start = c(1856, 1), frequency = 12)\n\n\nautoplot(global.ts) +\n  labs(title = \"Global Temperature 1985 ~ 2005\", \n       x = \"Year\", y = NULL)\n\n\n\n\nFigure 2: 1856년부터 2005년까지 지구 온도 시계열 그래프\n\n\n\n\nFigure 2 에서 볼 수 있는 것은 대략 1970년 이후로 지속적인 상승 패턴이 있다는 점이다. 1970년 이후 자료에 대한 시계열 그래프를 다시 작성해 보자. 이것을 위해서는 이미 생성된 ts 객체에서 일부분을 선택해야 하는데, 이 작업은 함수 window()로 할 수 있다.\n\nglobal.1970 <- window(global.ts, start = 1970)\n\n이제 1970년 1월 이후 자료에 대한 시계열 그래프를 Figure 3 에 작성해 보자.\n\nautoplot(global.1970) +\n  labs(title = \"Global Temperature 1970 ~ 2005\", \n       x = \"Year\", y = NULL)\n\n\n\n\nFigure 3: 1970년부터 2005년까지 지구 온도 시계열 그래프\n\n\n\n\nFigure 3 의 시계열 그래프에 회귀직선을 추가하면, 상승 추세를 조금 더 명확하게 확인할 수 있다. 회귀직선을 추가한 그래프를 Figure 4 에 작성해 보자.\n\nautoplot(global.1970) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Global Temperature 1970 ~ 2005\", \n       x = \"Year\", y = NULL)\n\n\n\n\nFigure 4: 시계열 그래프에 회귀직선 추가\n\n\n\n\n\n예제: 다중 시계열 그래프\n\ncbe.txt에는 호주에서 1958년부터 생산된 초콜릿, 맥주 및 전기의 월별 생산량이 입력되어 있다. 파일은 행과 열의 구조를 갖고 있으며, 각 자료는 빈 칸으로 구분되어 있다. 이런 구조의 텍스트 파일을 불러오기 위해서 패키지 readr의 함수 read_table()을 사용하였다.\n\nlibrary(readr)\nCBE <- read_table(\"https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/cbe.txt\")\nCBE %>% print(n = 3)\n## # A tibble: 396 × 3\n##    choc  beer  elec\n##   <dbl> <dbl> <dbl>\n## 1  1451  96.3  1497\n## 2  2037  84.4  1463\n## 3  2477  91.2  1648\n## # … with 393 more rows\n\ntibble로 입력된 자료를 ts 객체로 변환해 보자. 함수 ts()에 데이터 프레임을 입력하면 열을 구성하는 벡터를 각각 개별 ts 객체로 변환시킨다.\n\ncbe <- ts(CBE, start = 1958, frequency = 12)\nhead(CBE, n = 3)\n## # A tibble: 3 × 3\n##    choc  beer  elec\n##   <dbl> <dbl> <dbl>\n## 1  1451  96.3  1497\n## 2  2037  84.4  1463\n## 3  2477  91.2  1648\n\ncbe에는 시계열자료 choc, beer와 elec로 구성되어 있음을 알 수 있다. 이러한 다중 시계열 자료를 함수 autoplot()에 입력한 다중 시계열 그래프를 Figure 5 에 작성해 보자.\n\nautoplot(cbe) + ylab(NULL)\n\n\n\n\nFigure 5: 다중 시계열 그래프\n\n\n\n\n만일 다중 시계열자료의 scale에 큰 차이가 있다면 하나의 그래프에 작성하는 것보다는 facet 그래프를 작성하는 것이 더 효과적이다. Facet 다중 시계열 그래프를 Figure 6 에 작성해 보자.\n\nautoplot(cbe, facets = TRUE) + ylab(NULL)\n\n\n\n\nFigure 6: 다중 시계열 그래프\n\n\n\n\n\n\n\n\n예제: AirPassengers\n\n우선 함수 ggseasonplot()에 의한 seasonal 그래프를 Figure 7 에 작성해 보자.\n\nggseasonplot(AirPassengers)\n\n\n\n\nFigure 7: 함수 ggseasonalplot()으로 작성된 seasonal 그래프\n\n\n\n\n연도 범례를 포함시킨 seasonal 그래프를 Figure 8 에 작성해 보자.\n\nggseasonplot(AirPassengers, year.labels = TRUE)\n\n\n\n\nFigure 8: 함수 ggseasonalplot()으로 작성된 seasonal 그래프\n\n\n\n\n그래프 양쪽에 연도 범례를 포함시킨 seasonal 그래프를 Figure 9 에 작성해 보자.\n\nggseasonplot(AirPassengers, \n             year.labels = TRUE, year.labels.left = TRUE)\n\n\n\n\nFigure 9: 함수 ggseasonalplot()에서 year.labels.left = TRUE를 포함시킨 seasonal 그래프\n\n\n\n\n극좌표 형태의 seasonal 그래프를 Figure 10 에 작성해 보자.\n\nggseasonplot(AirPassengers, polar = TRUE)\n\n\n\n\nFigure 10: 함수 ggseasonalplot()에서 polar = TRUE를 포함시킨 seasonal 그래프\n\n\n\n\n이번에는 함수 ggsubseriesplot()으로 그래프를 Figure 11 에 작성해 보자. 월별로 자료를 구분해서 선 그래프를 작성하고, 파란 선으로 월별 평균을 표시한 그래프이다.\n\nggsubseriesplot(AirPassengers)\n\n\n\n\nFigure 11: 함수 ggsubseriesplot()으로 작성된 seasonal 그래프\n\n\n\n\n월별로 구분된 자료를 대상으로 상자그림을 작성해서 보는 것도 의미있는 분석이 될 수 있을 것이다. 상자그림을 작성하기 위해서는 ts 객체인 AirPassengers를 숫자형 벡터로 변환시키고, 각 자료의 주기를 함수 cycle()로 추출해서 요인으로 변환시키는 것이 필요하다. 상자그림으로 계절 요소의 변동을 Figure 12 에 작성해 보자.\n\ntibble(AP = as.numeric(AirPassengers), \n       mon = as.factor(cycle(AirPassengers))) %>% \n  ggplot(aes(x = mon, y = AP)) +\n  geom_boxplot() +\n  labs(x = \"Month\", y = \"Air Passengers\")\n\n\n\n\nFigure 12: 상자그림으로 나타낸 계절 변동 요소\n\n\n\n\n\n\n\n\n백화점 매출액 자료인 depart.ts에 대한 다음의 seasonal 그래프를 각각 작성하고, 계절 변동의 패턴에 대해 설명해 보자.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1981년 1월부터 1992년 12월까지 국내에 입국한 월별 관광객 수가 입력되어 있는 Ktour.txt에 대하여, 다음의 작업을 진행해 보자.\n\n\nts 객체로 변환\n시계열 그래프 작성\nseasonal 그래프 작성"
  },
  {
    "objectID": "2-decomposition.html",
    "href": "2-decomposition.html",
    "title": "",
    "section": "",
    "text": "이동평균법에서 차수 \\(m\\)의 효과: elecsales\n\n이동평균법의 차수를 증가시키면, 더 많은 자료를 이용해서 평균값을 계산하게 되고, 따라서 더 매끄러운 추세 곡선을 얻게 된다. elecsales에 \\(m\\)-MA를 적용시켜 얻은 결과를 원자료와 함께 그래프로 나타내 보자. 우선 3-MA의 결과를 Figure 1 에 나타내 보자.\n\nautoplot(elecsales, series = \"Data\") +\n  autolayer(ma(elecsales, 3), series = \"3-MA\") +\n  scale_color_manual(values = c(\"Data\" = \"blue\", \n                                \"3-MA\" = \"red\")) +\n  labs(title = \"3-MA\", color = NULL, y = NULL)\n\n\n\n\nFigure 1: elecsales에 3-MA를 적용한 결과\n\n\n\n\n3-MA의 결과는 원자료보다 매끄로운 형태를 보이고 있음을 알 수 있다. 이제 차수 \\(m\\)을 증가시키면 어떤 결과를 얻게 되는지 Figure 2 에서 살펴보자.\n\nlibrary(patchwork)\np1 <- autoplot(elecsales) + autolayer(ma(elecsales, 3), size = .8, color = \"red\") + \n  labs(y = NULL, title = \"3-MA\")\np2 <- autoplot(elecsales) + autolayer(ma(elecsales, 5), size = .8, color = \"red\") + \n  labs(y = NULL, title = \"5-MA\")\np3 <- autoplot(elecsales) + autolayer(ma(elecsales, 7), size = .8, color = \"red\") + \n  labs(y = NULL, title = \"7-MA\")\np4 <- autoplot(elecsales) + autolayer(ma(elecsales, 9), size = .8, color = \"red\") + \n  labs(y = NULL, title = \"9-MA\")\n(p1+p2)/(p3+p4)\n\n\n\n\nFigure 2: elecsales 자료에 대한 차수 m의 효과\n\n\n\n\n이번에는 호주에서 1956년부터 2010년까지 분기별 맥주 생산량 자료인 ausbeer에 대하여 \\(2 \\times m\\)-MA를 적용한 결과를 원자료와 함께 Figure 3 의 그래프로 나타내 보자.\n\nlibrary(patchwork)\np1 <- autoplot(ausbeer) + autolayer(ma(ausbeer, 4), size = .8, color = \"red\") + \n  labs(y = NULL, title = \"4-MA\")\np2 <- autoplot(ausbeer) + autolayer(ma(ausbeer, 8), size = .8, color = \"red\") + \n  labs(y = NULL, title = \"8-MA\")\np3 <- autoplot(ausbeer) + autolayer(ma(ausbeer, 12), size = .8, color = \"red\") + \n  labs(y = NULL, title = \"12-MA\")\np4 <- autoplot(ausbeer) + autolayer(ma(ausbeer, 24), size = .8, color = \"red\") + \n  labs(y = NULL, title = \"24-MA\")\n(p1+p2)/(p3+p4)\n\n\n\n\nFigure 3: ausbeer 자료에 대한 차수 m의 효과\n\n\n\n\n\n전통적 분해 기법 적용 예제: fpp2::elecequip\n\n\ndecompose(elecequip) %>% \n  autoplot() \n\n\n\n\nFigure 4: elecequip 자료에 대한 전통적 분해 기법 적용 결과\n\n\n\n\n각 패널의 오른쪽 끝에 높이가 동일한 막대를 배치하여, 각 성분의 상대적 크기를 쉽게 확인할 수 있게 하였다. 불규칙 성분이 표시된 마지막 패널의 막대가 가장 크다는 것은 불규칙 성분의 크기가 가장 작다는 의미가 된다. 또한 추세 성분의 처음과 마지막 6개월 자료는 NA가 되기 때문에 해당 기간에는 결과가 표시 되지 않았음을 알 수 있으고, 계절 성분이 동일한 형태를 취하고 있음도 확인할 수 있다.\n\n\n\n\nSTL 분해 기법 적용 예제: fpp2::elecequip\n\n\nlibrary(patchwork)\np1 <- stl(elecequip, s.window = \"periodic\") %>% \n  autoplot() + labs(title = \"s.window = 'periodic'\")\np2 <- stl(elecequip, s.window = 5) %>% \n  autoplot() + labs(title = \"s.window = 5\")\np1 + p2\n\n\n\n\nFigure 5: elecequip 자료에 대한 STL 분해 기법 적용 결과: s.window의 효과\n\n\n\n\n\nlibrary(patchwork)\np3 <- stl(elecequip, s.window = \"periodic\", t.window = 7) %>% \n  autoplot() + labs(title = \"t.window = 7\")\np4 <- stl(elecequip, s.window = \"periodic\", t.window = 11) %>% \n  autoplot() + labs(title = \"t.window = 11\")\np3 + p4\n\n\n\n\nFigure 6: elecequip 자료에 대한 STL 분해 기법 적용 결과: t.window의 효과"
  },
  {
    "objectID": "3-ets.html",
    "href": "3-ets.html",
    "title": "",
    "section": "",
    "text": "Simple exponential smoothing 예제: fpp2::oil\n\nfpp2::oil은 1965년부터 2013년까지 Saudi Arabia의 연간 원유 생산량 자료이다. 1996년 이후 자료에 대해 simple exponential smoothing을 적용해 보자.\n\noil_1996 <- window(oil, start = 1996)\n\n1996년 이후 연간 원유 생산량 자료의 시계열 그래프를 Figure 1 에 작성해 보자.\n\nautoplot(oil_1996) + \n  labs(title = \"Annual oil production in Saudi Arabia\", \n       y = NULL)\n\n\n\n\nFigure 1: 1996년 이후 Saudi Arabia 연간 원유 생산량\n\n\n\n\n함수 ses()를 사용하여 2014년 ~ 2016년의 원유 생산량을 예측해 보자.\n\nses(oil_1996, h = 3) %>% \n  summary()\n## \n## Forecast method: Simple exponential smoothing\n## \n## Model Information:\n## Simple exponential smoothing \n## \n## Call:\n##  ses(y = oil_1996, h = 3) \n## \n##   Smoothing parameters:\n##     alpha = 0.8339 \n## \n##   Initial states:\n##     l = 446.5868 \n## \n##   sigma:  29.8282\n## \n##      AIC     AICc      BIC \n## 178.1430 179.8573 180.8141 \n## \n## Error measures:\n##                    ME     RMSE     MAE      MPE     MAPE      MASE        ACF1\n## Training set 6.401975 28.12234 22.2587 1.097574 4.610635 0.9256774 -0.03377748\n## \n## Forecasts:\n##      Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\n## 2014       542.6806 504.4541 580.9070 484.2183 601.1429\n## 2015       542.6806 492.9073 592.4539 466.5589 618.8023\n## 2016       542.6806 483.5747 601.7864 452.2860 633.0752\n\nLevel에 대한 평활상수가 \\(\\alpha =\\) 0.8339으로 추정되었다는 것은 level에 큰 변화가 있는 자료를 의미한다. 이제 예측 결과를 Figure 2 의 그래프로 나타내 보자.\n\nses(oil_1996, h = 3) %>% \n  autoplot() + \n  labs(y = NULL)\n\n\n\n\nFigure 2: 1996년 이후 Saudi Arabia 연간 원유 생산량 및 2014년 이후 예측 결과\n\n\n\n\n파란 실선으로 표시된 예측값은 마지막 level 추정값으로써, 모든 h에 대하여 동일하다는 것을 알 수 있다. 예측값을 표시한 실선을 포함하고 있는 짙은 파란 색 영역은 80% 예측 구간을 표시한 것이고, 옅은 파란 색 영역은 95% 예측 구간을 표시한 것이다. 예측 시차가 증가함에 따라 예측 구간의 폭은 계속 넓어지고 있음을 알 수 있다.\n\nTrend method 예제: fpp2::ausair\n\nfpp2::ausair는 1970년부터 2016년까지 호주의 연간 항공기 승객 수 자료이다. Holt’s linear trend와 damped Holt’s trend 모형을 이용해서 예측을 실시해 보자.\n먼저 시계열 그래프를 Figure 3 에 작성해 보자. 상승 추세가 있는 것을 확인할 수 있다.\n\nautoplot(ausair) +\n  labs(title = \"Air Transport Passengers Australia\", \n       y = NULL)\n\n\n\n\nFigure 3: 1970년부터 2016년까지 호주의 연간 항공기 승객 수\n\n\n\n\nHolt’s linear trend 모형을 함수 holt()를 사용해서 적합시키고, 15 시차에 대한 예측 결과를 Figure 4 에 나타내 보자.\n\nholt(ausair, h = 15) %>% \n  autoplot()\n\n\n\n\nFigure 4: ausair 자료에 대한 Holt’s linear trend method의 예측 결과\n\n\n\n\nDamped Holt’s trend 모형에 의한 예측 결과도 그래프로 나타내 보자. 결과는 Figure 5 에서 볼 수 있다.\n\nholt(ausair, h = 15, damped = TRUE) %>% \n  autoplot()\n\n\n\n\nFigure 5: ausair 자료에 대한 damped Holt’s trend method의 예측 결과\n\n\n\n\nFigure 4 에서 볼 수 있듯이 Holt’s linear trend method에 의한 예측 결과는 지속적으로 증가하고 있으며, 반면에 damped Holt’s trend method에 의한 예측 결과는 상승 기울기가 점점 줄어들고 있다는 것을 Figure 5 에서 볼 수 있다.\n\nHolt-Winters’ seasonal method 예제: fpp2::austourists\n\naustourists는 199년부터 2015년까지 분기별 호주에 입국한 외국인 관광객 수 자료이다. 시계열 그래프는 Figure 6 에서 볼 수 있다.\n\nautoplot(austourists) +\n  labs(y = NULL, title = \"International Tourists to Australia\")\n\n\n\n\nFigure 6: 199년부터 2015년까지 분기별 호주에 입국한 외국인 관광객 수\n\n\n\n\nHolt-Winters’ seasonal 모형을 이용해서 예측을 실시해 보자. 먼저 가법 모형으로 예측을 실시하고 결과를 Figure 7 에 그래프로 나타내 보자.\n\nhw(austourists) %>% \n  autoplot() + labs(y = NULL)\n\n\n\n\nFigure 7: austourists 자료에 대한 Holt-Winters’ additive seasonal method의 예측 결과\n\n\n\n\n이번에는 승법 모형으로 예측을 실시하고 결과를 Figure 8 에 그래프로 나타내 보자.\n\nhw(austourists, seasonal = \"multiplicative\") %>% \n  autoplot() + labs(y = NULL)\n\n\n\n\nFigure 8: austourists 자료에 대한 Holt-Winters’ multiplicative seasonal method의 예측 결과\n\n\n\n\n\n\n\n\n예제 1: 1970년부터 2016년까지 연간 항공기 이용객 수 (fpp2::ausair)\n\nfpp2::ausair는 1970년부터 2016년까지 호주의 연간 항공기 승객 수 자료이다. 먼저 전체 자료 중 1970년부터 2011년까지의 자료를 training data로 하고, 2012년 이후 자료를 test data로 분리하자.\n\ntrain_air <- window(ausair, end = 2011)\ntest_air <- window(ausair, start = 2012)\n\ntrain_air와 test_air의 시계열 그래프는 Figure 9 과 같다. test_air는 빨간 선으로 나타냈다.\n\nautoplot(window(ausair, end = 2012)) +\n  autolayer(window(ausair, start = 2012), size = .8) +\n  labs(y = NULL, x = NULL) +\n  theme(legend.position = \"none\")\n\n\n\n\nFigure 9: ausair 자료의 시계열그래프\n\n\n\n\n함수 ets()로 ETS 모형을 적합하고, 그 결과를 확인해 보자.\n\nfit_air <- ets(train_air)\nfit_air\n## ETS(M,A,N) \n## \n## Call:\n##  ets(y = train_air) \n## \n##   Smoothing parameters:\n##     alpha = 0.9999 \n##     beta  = 0.024 \n## \n##   Initial states:\n##     l = 6.5399 \n##     b = 0.7358 \n## \n##   sigma:  0.08\n## \n##      AIC     AICc      BIC \n## 206.1828 207.8495 214.8712\n\n최적 모형은 ETS(M,A,N)으로 선정되었다. 즉, 추세는 additive이고 오차는 multiplicative이며, 계절요소가 없는 모형이 적합되었다. 평활모수는 \\(\\alpha=\\) 0.9999 , \\(\\beta=\\) 0.024 로 추정되었다. 따라서 시계열자료의 level에는 큰 변화가 있으나, 추세의 기울기에는 큰 변화 없이 일정하다는 것을 알 수 있다.\nETS 모형의 각 요소에 대한 추정 결과를 Figure 10 의 그래프로 나타내 보자. 관측된 자료의 시계열 그래프, 그리고 level의 추정 결과와 추세 기울기의 추정 결과의 시계열 그래프가 함께 작성되어 있다. 그래프 오른쪽 끝에 있는 동일한 높이의 막대가 표시되어 있어서 각 요소의 스케일을 비교할 수 있다.\n\nautoplot(fit_air)  \n\n\n\n\nFigure 10: ETS 모형의 각 요소에 대한 추정 결과 그래프\n\n\n\n\n모형의 가정 만족 여부를 함수 checkresiduals()로 확인해 보자. 특별히 문제가 되는 가정 사항은 없는 것으로 보인다.\n\ncheckresiduals(fit_air)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ETS(M,A,N)\n## Q* = 3.5236, df = 4, p-value = 0.4743\n## \n## Model df: 4.   Total lags used: 8\n\n이제 예측을 실시하고 예측 오차에 대한 평가를 실시해 보자.\n\nfc_air <- forecast(fit_air, h = length(test_air))\naccuracy(fc_air, test_air)\n##                     ME     RMSE     MAE       MPE     MAPE      MASE\n## Training set 0.5550369 2.138179 1.31460 0.7893247 5.399428 0.7649321\n## Test set     1.7629504 1.888573 1.76295 2.5419343 2.541934 1.0258159\n##                     ACF1 Theil's U\n## Training set -0.09163575        NA\n## Test set     -0.22513230  1.034042\n\n예측 결과를 그래프로 나타내 보자. 함수 autoplot()에 함수 forecast()의 결과인 객체 fc_air를 입력하면 training data와 예측 결과를 함께 나타낸다. 옵션 include는 그래프에 포함시킬 training data의 개수를 지정하는 것이다. 따라서 include = 0을 입력하면 예측 부분만을 확대한 효과를 볼 수 있다. 작성 결과는 Figure 11 에서 볼 수 있다.\n\nlibrary(patchwork)\np1 <- autoplot(fc_air) + \n  autolayer(test_air, color = \"red\", size = .8) +\n  labs(y = NULL, x = NULL) \np2 <- autoplot(fc_air, include = 0) + \n  autolayer(test_air, color = \"red\", size=.8) +\n  labs(y = NULL, x = NULL) \np1 + p2\n\n\n\n\nFigure 11: fpp2::ausair 자료에 대한 ETS 모형의 예측 결과\n\n\n\n\n\n예제 2: 1999년부터 2015년까지 분기별 호주 입국 외국인 관광객 수 (fpp2::austourists)\n\naustourists는 1999년부터 2015년까지 분기별로 호주에 입국한 외국인 관광객 수 자료이다. 2013년 4분기까지를 training data로 분리하고 2014년 1분기부터를 test data로 분리하자.\n\ntrain_tour <- window(austourists, end = c(2013, 4))\ntest_tour <- window(austourists, start = c(2014, 1))\n\n두 자료의 시계열 그래프는 Figure 12 과 같다. Test data는 빨간 선으로 표시했다. 상승 추세가 있으며, 명확한 계절요소가 있는 것을 알 수 있다. 또한 계절요소의 진폭이 추세가 상승함에 따라 다소 증가하고 있는 것을 볼 수 있다.\n\nautoplot(window(austourists, end = c(2014,1))) +\n  autolayer(window(austourists, start = c(2014,1)), size = .8) +\n  labs(y = NULL) +\n  theme(legend.position = \"none\")\n\n\n\n\nFigure 12: austourists 자료의 시계열 그래프\n\n\n\n\n함수 ets()로 최적 모형을 적합해 보자.\n\nfit_tour <- ets(train_tour)\nfit_tour\n## ETS(M,A,M) \n## \n## Call:\n##  ets(y = train_tour) \n## \n##   Smoothing parameters:\n##     alpha = 0.4189 \n##     beta  = 1e-04 \n##     gamma = 1e-04 \n## \n##   Initial states:\n##     l = 24.2672 \n##     b = 0.5179 \n##     s = 1.0367 0.9578 0.7697 1.2358\n## \n##   sigma:  0.0612\n## \n##      AIC     AICc      BIC \n## 353.3882 356.9882 372.2373\n\nETS(M,A,M) 모형이 선택되었다. 승법 계절 성분이 선택되었다는 것은 계절 요소의 변동 폭이 증가한다는 의미가 된다. 이런 경우에 시계열자료를 로그변환 시킨 후 다시 ETS 모형을 적합시키면 가법 계절 모형이 선택될 것이다. 함수 ets()의 Box_Cox 변환 모수인 옵션 lambda에 0을 입력하면 로그변환된 자료를 대상으로 모형 적합이 이루어진다.\n\nfit_lntour <- ets(train_tour, lambda = 0)\nfit_lntour\n## ETS(A,A,A) \n## \n## Call:\n##  ets(y = train_tour, lambda = 0) \n## \n##   Box-Cox transformation: lambda= 0 \n## \n##   Smoothing parameters:\n##     alpha = 0.337 \n##     beta  = 1e-04 \n##     gamma = 0.0137 \n## \n##   Initial states:\n##     l = 3.2161 \n##     b = 0.0122 \n##     s = 0.055 -0.0254 -0.2477 0.2181\n## \n##   sigma:  0.0639\n## \n##       AIC      AICc       BIC \n## -75.06808 -71.46808 -56.21898\n\n모형 fit_tour의 가정 만족 여부를 확인해 보자.\n\ncheckresiduals(fit_tour)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ETS(M,A,M)\n## Q* = 5.3591, df = 3, p-value = 0.1473\n## \n## Model df: 8.   Total lags used: 11\n\n모형 fit_lntour의 가정 만족 여부도 확인해 보자.\n\ncheckresiduals(fit_lntour)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ETS(A,A,A)\n## Q* = 7.2993, df = 3, p-value = 0.06294\n## \n## Model df: 8.   Total lags used: 11\n\n두 모형 모두 가정은 만족시키는 것으로 보인다. 이제 두 모형의 예측을 실시하고, 그 결과를 비교해 보자.\n\nfc_tour <- forecast(fit_tour, h = length(test_tour)) \nfc_lntour <- forecast(fit_lntour, h = length(test_tour))\n\n\naccuracy(fc_tour, test_tour)\n##                       ME     RMSE      MAE        MPE     MAPE      MASE\n## Training set 0.004642325 1.966538 1.474615 -0.4054666 4.196005 0.5206241\n## Test set     1.541295202 2.989673 2.414226  2.6022154 3.958845 0.8523613\n##                    ACF1 Theil's U\n## Training set -0.0243205        NA\n## Test set      0.5001355 0.2077632\naccuracy(fc_lntour, test_tour)\n##                     ME     RMSE      MAE        MPE     MAPE      MASE\n## Training set 0.1640202 2.014686 1.562901 0.04389638 4.399828 0.5517943\n## Test set     0.6115065 2.128486 1.722829 1.03590923 2.853023 0.6082580\n##                    ACF1 Theil's U\n## Training set 0.01619145        NA\n## Test set     0.47705974 0.1348746\n\n모형 ETS(A,A,A)인 fit_lntour의 test data에 대한 예측 오차가 조금 더 작은 것을 볼 수 있다. 두 모형의 예측 결과를 Figure 13 의 그래프로 비교해 보자. 함수 autolayer()에 PI = FALSE를 입력하면 예측 구간이 생략된다. 이것은 두 모형의 예측 구간이 함께 표시되면 서로 겹쳐지는 현상이 발생하기 때문에 생략한 것이다. 두 모형의 예측에는 큰 차이가 없음을 알 수 있다.\n\nlibrary(patchwork)\np1 <- autoplot(train_tour) +\n  autolayer(test_tour, series = \"Test data\") +\n  autolayer(fc_tour, PI = FALSE, series = \"ETS(M,A,M)\") +\n  autolayer(fc_lntour, PI = FALSE, series = \"ETS(A,A,A)\") +\n  labs(y = NULL, x = NULL, color = NULL) +\n  theme(legend.position = \"top\")\n\np2 <- autoplot(test_tour, series = \"Test data\", size = .8) +\n  autolayer(fc_tour, PI = FALSE, series = \"ETS(M,A,M)\", \n            size = .8) +\n  autolayer(fc_lntour, PI = FALSE, series = \"ETS(A,A,A)\", \n            size = .8) +\n  labs(y = NULL, x = NULL, color = NULL) +\n  theme(legend.position = \"top\")\n\np1 + p2\n\n\n\n\nFigure 13: austourists 자료에 대한 예측 결과 비교\n\n\n\n\n모형 ETS(A,A,A)인 fit_lntour의 test data에 대한 예측 결과를 예측 구간과 함께 Figure 14 의 그래프로 나타내 보자.\n\nlibrary(patchwork)\np1 <- autoplot(fc_lntour) +\n  autolayer(test_tour, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL) \np2 <- autoplot(fc_lntour, include = 0) +\n  autolayer(test_tour, color = \"red\", size = .8) +\n  labs(y = NULL, x = NULL) +\n  scale_x_continuous(breaks = c(2014.0, 2014.5, 2015.0, 2015.5),\n                     labels = c(\"2014.Q1\", \"2014.Q3\", \"2015.Q1\",\n                                \"2015.Q3\"))\np1 + p2\n\n\n\n\nFigure 14: austourists 자료에 대한 예측 결과\n\n\n\n\n\n예제 3: 1965년 1월부터 1992년 7월까지 월별 실업 급여 수급 인원 수 (fma::dole)\n\nfma::dole은 1965년 1월부터 1992년 7월까지 월별로 실업 급여를 받아간 인원 수 자료이다. 마지막 2년 자료를 test data로 분리해 보자.\n\ntrain_d <- window(dole, end = c(1990, 7))\ntest_d <- window(dole, start = c(1990, 8))\n\n두 자료에 대한 시계열 그래프는 Figure 15 과 같다. Test data는 빨간 선으로 표시했다. 1990년부터 갑작스런 증가세를 보이고 있으며, test data가 대부분 그 시기에 관측된 것이다. 따라서 예측이 상당히 어려운 것으로 보이는 상황이다.\n\nautoplot(train_d) + \n  autolayer(test_d, show.legend=FALSE, size = .8) +\n  labs(y = NULL, x = NULL)\n\n\n\n\nFigure 15: dole 자료의 시계열그래프\n\n\n\n\nETS 모형을 적합해 보자.\n\nfit_d <- ets(train_d)\nfit_d\n## ETS(M,Ad,M) \n## \n## Call:\n##  ets(y = train_d) \n## \n##   Smoothing parameters:\n##     alpha = 0.7057 \n##     beta  = 0.1262 \n##     gamma = 0.2942 \n##     phi   = 0.8701 \n## \n##   Initial states:\n##     l = 2693.6084 \n##     b = 838.4198 \n##     s = 1.0776 0.9108 0.9286 0.9993 1.0254 1.0275\n##            1.0028 0.9466 1.0225 0.9982 1.0038 1.0568\n## \n##   sigma:  0.0965\n## \n##       AIC      AICc       BIC \n##  9930.864  9932.591 10003.373\n\n가정 만족 여부를 확인해 보니, 독립성 가정에 문제가 있는 것을 볼 수 있다. 이런 경우, 점 예측값 (point forecast)에는 별다른 문제가 없겠지만, 예측 구간을 신뢰하기 어렵다고 할 수 있다.\n\ncheckresiduals(fit_d)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ETS(M,Ad,M)\n## Q* = 270.13, df = 7, p-value < 2.2e-16\n## \n## Model df: 17.   Total lags used: 24\n\n예측을 실시하고 평가해 보자.\n\nfc_d <- forecast(fit_d, h = length(test_d))\naccuracy(fc_d, test_d)\n##                      ME      RMSE        MAE        MPE      MAPE      MASE\n## Training set    307.438  16094.96   9474.828  0.5940649  6.112239 0.2965093\n## Test set     208048.806 234353.38 208048.806 28.7917875 28.791788 6.5107678\n##                   ACF1 Theil's U\n## Training set 0.5103798        NA\n## Test set     0.8895083  8.715368\n\nMASE 값이 지나치게 큰 값이라는 것을 알 수 있다. 예측 결과를 Figure 16 의 그래프로 나타내 보자.\n\nautoplot(fc_d) +\n  autolayer(test_d, color = \"red\", size = .8) +\n  labs(y = NULL, x = NULL) \n\n\n\n\nFigure 16: dole 자료에 대한 예측 결과\n\n\n\n\n예측이 완벽하게 벗어난 것을 볼 수 있다. 이와 같이 실업자 수가 갑작스럽게 증가하는 상황에서는 과거 자료만을 이용하는 시계열 모형으로는 효율적인 예측이 불가능하다고 하겠다.\nTest data에서 발생한 갑작스런 변화의 충격을 완화시키는 방법으로 test data의 기간 축소를 생각할 수 있다. 이렇게 되면, 증가 추세가 training data에도 어느 정도 반영될 수 있을 것이다. 하지만 이 방법은 자료의 추세를 먼저 확인하고 test data의 기간을 변경하는 것이어서 정당한 자료 분리 방법은 아니라고 할 수 있다. 마지막 1년만을 test data로 남겨 놓고 모형 적합을 시도해 보자. 자료분리는 함수 subset()으로도 진행할 수 있다. 옵션 end와 start에 벡터에서 적용되는 방식의 인덱스를 지정할 수 있다.\n\ntrain_d_1 <- subset(dole, end = length(dole) - 12)\ntest_d_1 <- subset(dole, start = length(dole) - 11)\n\n변경된 training data를 사용해서 적합된 모형으로 마지막 1년 자료에 대한 예측을 실시해 보자. 훨씬 개선된 결과를 볼 수 있다.\n\nfc_d_1 <- train_d_1 %>% \n  ets() %>% \n  forecast(h = length(test_d_1))\n\n\naccuracy(fc_d_1, test_d_1)\n##                     ME     RMSE      MAE       MPE     MAPE      MASE      ACF1\n## Training set  419.4624 18184.20 10856.63 0.5111136 6.268750 0.3014767 0.5191139\n## Test set     5143.1303 46330.29 40948.53 1.0361996 5.319935 1.1370959 0.8678915\n##              Theil's U\n## Training set        NA\n## Test set      2.792915\n\n이제 예측 결과를 그림 Figure 17)의 그래프로 나타내 보자.\n\nlibrary(patchwork)\np1 <- autoplot(fc_d_1) + \n  autolayer(test_d_1, color = \"red\", size = .8) +\n  labs(y = NULL, x = NULL) \np2 <- autoplot(fc_d_1, include = 0) +\n  autolayer(test_d_1, color = \"red\", size = .8) +\n  labs(y = NULL, x = NULL) \np1 + p2\n\n\n\n\nFigure 17: dole 자료에 대한 예측 결과\n\n\n\n\n\n예제 4: 2014년 4월 30일부터 1년간 Hyndsight 블로그 일일 방문자 수 (fpp2::hyndsight)\n\nhyndsight는 2014년 4월 30일부터 1년간 Hyndman이 운영하는 블로그에 방문한 일일 방문자 수 자료이다. 자료의 시계열그래프는 Figure 18 에서 볼 수 있다.\n\nautoplot(hyndsight) + labs(x = NULL, y = NULL)\n\n\n\n\nFigure 18: hyndsight 자료의 시계열그래프\n\n\n\n\n일일 자료의 경우에 요일의 영향을 받는 자료라면 \\(m=7\\)의 계절 주기를 갖게 된다. 자료 분리를 위해 2014년 4월 30일이 무슨 요일인지 확인해 보자.\n\nlubridate::wday(as.Date(\"2014-4-30\"), label = TRUE)\n## [1] 수\n## Levels: 일 < 월 < 화 < 수 < 목 < 금 < 토\n\n\nstart(hyndsight); end(hyndsight)\n## [1] 1 4\n## [1] 53  4\n\n2014년 4월 30일은 수요일이며, 자료의 시작 시점은 1주 4일 (수)이고 종료 시점은 53주 4일 (수)이 된다. Training data는 1주 4일부터 48주 4일까지로 하고, test data는 48주 5일부터 53주 4일까지 5주간으로 설정하자.\n자료 분리는 함수 window()로 보통 진행하지만, 이렇게 자료의 개수로 분리하는 것이 더 편리한 경우에는 함수 subset()으로 진행 할 수 있다. 즉, 마지막 35일 자료를 test data로 분리해 보자.\n\ntrain_hyn <- subset(hyndsight, end = length(hyndsight)-35)\ntest_hyn <- subset(hyndsight, start = length(hyndsight)-34)\n\nETS 모형을 적합해 보자. 추세는 없고, 오차와 계절 성분이 모두 가법 형태인 모형이 선택되었다.\n\nfit_hyn <- ets(train_hyn)\nfit_hyn\n## ETS(A,N,A) \n## \n## Call:\n##  ets(y = train_hyn) \n## \n##   Smoothing parameters:\n##     alpha = 0.4426 \n##     gamma = 1e-04 \n## \n##   Initial states:\n##     l = 1173.6676 \n##     s = 296.9907 -34.3415 -457.6839 -271.7606 63.9589 172.9509\n##            229.8854\n## \n##   sigma:  232.0085\n## \n##      AIC     AICc      BIC \n## 5519.446 5520.136 5557.437\n\n이제 예측을 진행해 보자.\n\nfc_hyn <- forecast(fit_hyn, h = length(test_hyn))\naccuracy(fc_hyn, test_hyn)\n##                      ME     RMSE      MAE       MPE     MAPE      MASE\n## Training set   3.727848 228.8229 164.1102 -2.026679 13.86475 0.7404020\n## Test set     -73.167844 231.3494 180.9392 -8.044075 13.09378 0.8163279\n##                   ACF1 Theil's U\n## Training set 0.1874059        NA\n## Test set     0.3712518 0.5878683\n\n예측 결과를 Figure 19 의 그래프와 같이 작성해 보자. 빨간 실선은 test data이고, 파란 실선이 예측 결과이다. 예측 구간은 80%와 95% 수준에서 각각 계산되는 것이 디폴트이며, 80% 예측 구간은 짙은 색으로 표시되고, 95% 예측 구간은 옅은 색으로 표시된다.\n\nautoplot(fc_hyn, include = 0) +\n  autolayer(test_hyn, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL) \n\n\n\n\nFigure 19: hynsight 자료에 대한 예측 결과"
  },
  {
    "objectID": "4-arima.html",
    "href": "4-arima.html",
    "title": "",
    "section": "",
    "text": "분산 안정화 변환 예제: 호주의 1956년 1월부터 1995년 8월까지 월별 전기 생산량 자료 (fma::elec)\n\n분산 안정화 변환이 필요한 자료의 예로써 1956년 1월부터 1995년 8월까지 호주의 월별 전기 생산량 자료인 fma::elec을 살펴보자. 시계열 그래프는 Figure 1 에서 볼 수 있다.\n\nautoplot(elec) + \n  labs(x = NULL, y = NULL)\n\n\n\n\nFigure 1: elec 자료의 시계열 그래프\n\n\n\n\n증가하는 추세가 있으며, 명확한 계절 성분이 있는 자료임을 알 수 있다. 또한 계절 성분의 변동 폭이 추세가 증가함에 따라 함께 증가하는 현상도 볼 수 있다.\nBox-Cox 변환을 위한 함수에는 패키지 forecast의 함수 BoxCox.lambda()와 BoxCox()가 있다. 함수 BoxCox.lambda()는 주어진 자료에 대한 변환 모수 \\(\\lambda\\) 의 적정 값을 추정하고, 함수 BoxCox()는 입력된 \\(\\lambda\\) 값으로 자료의 변환을 실시한다.\n이제 elec 자료에 대해 Box-Cox 변화을 실시해 보자.\n\n(lambda <- BoxCox.lambda(elec))\n## [1] 0.2654076\n\n변환된 자료의 시계열 그래프를 Figure 2 에 작성해 보자.\n\nautoplot(BoxCox(elec, lambda)) + \n  labs(x = NULL, y = NULL)\n\n\n\n\nFigure 2: elec 자료에 Box-Cox 변환 실시\n\n\n\n\nFigure 2 에서 볼 수 있듯이 Box-Cox 변환된 자료는 전체적으로 일정한 변동 폭을 유지하고 있음을 알 수 있다. 그러나 변환된 자료인 \\(y_{t}^{0.2654}\\) 에 대한 의미가 명확하지 않아서 해석에 문제가 있을 수 있다. 비교 차원에서 로그 변환을 실시해 보고, 결과를 비교해 보자.\n\nlibrary(patchwork)\n\n\np1 <- autoplot(BoxCox(elec, BoxCox.lambda(elec))) + \n  labs(x = NULL, y = NULL, title = \"Box-Cox transformation\")\np2 <- autoplot(log(elec)) + \n  labs(x = NULL, y = NULL, title = \"log transformation\")\np1 + p2\n\n\n\n\nFigure 3: elec 자료에 대한 분산안정화 변환의 비교\n\n\n\n\n두 변환 결과에는 큰 차이가 없다는 것을 Figure 3 에서 확인 할 수 있다. 따라서 이 경우에는 승법 모형을 가법 모형으로 변환한다는 의미를 갖고 있어서 해석이 비교적 용이한 로그 변환을 사용하는 것이 더 좋을 것으로 보인다.\n\n차분 예제 : Google 주가 자료 (fpp2::goog200)\n\nGoogle 주가 자료인 goog200의 시계열 그래프와 표본 ACF를 작성해 보자. 대체적으로 증가하는 추세가 있으며, 표본 ACF가 매우 천천히 감소하고 있다.\n\np1 <- autoplot(goog200) + \n  labs(x = NULL, y = NULL, title = \"Google stock price\")\np2 <- ggAcf(goog200) + ggtitle(\"\")\np1 + p2\n\n\n\n\nFigure 4: goog200 자료의 시계열 그래프와 ACF\n\n\n\n\n이제 goog200 자료를 1차 차분하고 결과를 확인해 보자.\n\ngoog200_1 <- diff(goog200)\np3 <- autoplot(goog200_1) + \n  labs(x = NULL, y = NULL, title = \"Google stock price\")\np4 <- ggAcf(goog200_1) + ggtitle(\"\")\np3 + p4\n\n\n\n\nFigure 5: goog200의 1차 차분된 자료의 시계열 그래프와 ACF\n\n\n\n\n차분된 자료는 하나의 이상값을 제외하면 일정한 level을 유지하고 있으며, 표본 ACF의 모든 값들이 신뢰구간 안에 존재하고 있음을 알 수 있다. 따라서 차분된 자료는 백색잡음 자료로 보이며, 이것은 원자료가 확률보행 자료임을 나타내는 것이 된다.\ngoog200 자료를 대상으로 단위근 검정을 실시해 보자. 단위근 검정은 urca::ur.kpss()로 실시할 수 있지만, 함수 forecast::ndiffs()를 사용하면 정상성을 만족시키기 위한 차분의 횟수를 단위근 검정에 근거를 두고 추정해 준다.\n\nndiffs(goog200)\n## [1] 1\n\n즉, 1차 차분을 실시하면 정상성을 만족시킬 수 있다고 제안하는 것이다. 물론 urca::ur.kpss()로 단위근 검정을 실시해서 주어진 자료의 정상성 여부를 확인할 수 있다. |> 기호는 base R의 pipe 연산자이며, 기본적인 사용법은 %>%와 동일하다.\n\nlibrary(urca)\ngoog200  |> \n  ur.kpss() |>  \n  summary()\n## \n## ####################### \n## # KPSS Unit Root Test # \n## ####################### \n## \n## Test is of type: mu with 4 lags. \n## \n## Value of test-statistic is: 2.7441 \n## \n## Critical value for a significance level of: \n##                 10pct  5pct 2.5pct  1pct\n## critical values 0.347 0.463  0.574 0.739\n\n계산된 검정 통계량 값이 1% 유의수준의 임계값보다 크기 때문에 정상이라는 귀무가설을 기각할 수 있다. 1차 차분을 실시한 자료를 대상으로 단위근 검정을 실시해 보면, 귀무가설을 기각할 수 없기 때문에 1차 차분으로 정상성을 확보했다고 볼 수 있다.\n\ngoog200 |>  \n  diff() |>  \n  ur.kpss() |>  \n  summary()\n## \n## ####################### \n## # KPSS Unit Root Test # \n## ####################### \n## \n## Test is of type: mu with 4 lags. \n## \n## Value of test-statistic is: 0.1163 \n## \n## Critical value for a significance level of: \n##                 10pct  5pct 2.5pct  1pct\n## critical values 0.347 0.463  0.574 0.739\n\n\n예제 : 호주의 1956년 1월부터 1995년 8월까지 월별 전기 생산량 자료 (fma::elec)\n\nFigure 1 에서 살펴본 elec는 증가하는 추세와 뚜렷한 계절 성분이 있으며, 분산이 시간이 흐름에 따라 증가하는 자료이다. 정상성을 만족시키기 위한 변환 절차에서 분산 안정화는 항상 가장 먼저 시행해야 한다. 로그 변환을 시행해서 분산을 안정화 시킨 자료의 시계열 그래프와 ACF는 Figure 6 에서 볼 수 있다.\n\nln_elec <- log(elec)\np1 <- autoplot(ln_elec) + \n  labs(x = NULL, y = NULL, title = \"log transformed data\")\np2 <-  ggAcf(ln_elec) + ggtitle(\"\")\np1 + p2\n\n\n\n\nFigure 6: elec에 로그 변환한 자료의 시계열 그래프와 ACF\n\n\n\n\n뚜렷하게 존재하는 계절 성분을 제거하기 위해 계절 차분을 실시할 필요가 있는 것으로 보인다. 계절 차분의 경우에는 함수 forecast::nsdiffs()를 사용하면 계절 단위근 검정을 근거로 하여 계절 차분 횟수를 추정할 수 있다. 함수 nsdiffs()는 seasonal strength를 측정하는 통계량을 근거로 하여 차분 횟수를 추정하는 것이 디폴트이다.\n\nelec |>  \n  log() |>  \n  nsdiffs()\n## [1] 1\n\n계절 차분을 실시한 자료를 대상으로 시계열 그래프와 ACF를 작성해 보자. 작성된 그래프는 Figure 7 에서 확인할 수 있다.\n\nln_elec_m <- log(elec) %>% \n  diff(lag = 12)\np3 <- autoplot(ln_elec_m) + \n  labs(x = NULL, y = NULL, title = \"log transformed and seasonally differenced data\")\np4 <-  ggAcf(ln_elec_m) + ggtitle(\"\")\np3 + p4\n\n\n\n\nFigure 7: 로그 변환된elec에 계절차분을 실시한 자료의 시계열 그래프와 ACF\n\n\n\n\nFigure 7 에서 볼 수 있듯이 추세 성분이 아직 남아 있는 것으로 보인다. 이제 계절 차분된 자료에 1차 차분을 더 실시한 결과를 살펴보자. Figure 8 에 나타난 패턴을 보면, 비정상 요소가 모두 제거되었음을 알 수 있다.\n\nln_elec_m_1 <- log(elec) %>% \n  diff(lag = 12) %>% \n  diff()\np5 <- autoplot(ln_elec_m_1) + \n  labs(x = NULL, y = NULL, title = \"log transformed and doubly differenced data\")\np6 <-  ggAcf(ln_elec_m_1) + ggtitle(\"\")\np5 + p6\n\n\n\n\nFigure 8: 로그 변환된 elec에 계절차분과 1차 차분을 실시한 자료의 시계열 그래프와 ACF\n\n\n\n\n\n\n\n\n예제 1: gas 자료\n\n자료 파일 gas.csv에는 9초 간격으로 측정된 입력 가스 비율 (rate)에 따른 이산화탄소 배출 농도 (co2)가 입력되어 있다. 먼저 자료를 입력해 보자.\n\ngas <- readr::read_csv(\"https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/gas.csv\")\ngas %>% \n  print(n = 5)\n## # A tibble: 296 × 2\n##     rate   co2\n##    <dbl> <dbl>\n## 1 -0.109  53.8\n## 2  0      53.6\n## 3  0.178  53.5\n## 4  0.339  53.5\n## 5  0.373  53.4\n## # … with 291 more rows\n\n데이터 프레임 gas에는 변수 rate와 co2가 있는 것을 알 수 있다. 변수 rate를 ts 객체로 변환해야 하는데 시작 시점과 종료 시점에 대한 정보가 없는 상태이어서, 시점을 \\(t=1, 2, 3, \\ldots\\) 로 지정하고 주기도 1로 지정하도록 하자. 이런 작업은 함수 as.ts()를 사용하면 간편하게 할 수 있다. 이어서 시계열 그래프도 Figure 9 에 작성해 보자.\n\nrate.ts <- as.ts(gas$rate)\nautoplot(rate.ts) + labs(y = NULL)\n\n\n\n\nFigure 9: gas 자료의 시계열 그래프\n\n\n\n\nrate.ts에 대한 ARIMA 모형을 적합해 보자. 먼저 전체 자료를 training data와 test data로 분리하자. Test data는 마지막 10개 자료로 한다.\n\ntrain_r <- window(rate.ts, end = length(rate.ts) - 10)\ntest_r <- window(rate.ts, start = length(rate.ts) - 9)\n\nTraining data를 대상으로 최적의 모형을 적합해 보자. 먼저 자료의 정상성 여부를 시계열 그래프와 ACF로 확인해 보자. 필요한 그래프는 Figure 10 에서 볼 수 있다.\n\nggtsdisplay(train_r)\n\n\n\n\nFigure 10: 자료 train_r의 정상성 여부 확인을 위한 그래프\n\n\n\n\nFigure 10 의 시계열 그래프에는 명확한 추세가 없는 것으로 보이지만, 표본 ACF가 비교적 천천히 모습이 보인다. 단위근 검정 결과는 차분이 필요한 것으로 나온다.\n\nndiffs(train_r)\n## [1] 1\n\n단위근 검정 결과에 따라 정상성이 만족되지 않는 것으로 보고 차분을 실시할 수 있지만, 시계열 그래프와 ACF를 근거로 정상성이 만족된 것으로 볼 수도 있기 때문에, 차분을 실시하는 것과 실시하지 않는 두 가지 상황을 모두 고려해서 모형 식별을 진행하는 것이 좋을 것으로 보인다.\n먼저 차분을 실시하지 않는 경우에 대해서 모형 적합을 진행해 보자. 차분을 실시하지 않기 위해서 d = 0을 입력하고, 이어서 stepwise, approximation, seasonal을 모두 FALSE로 지정하자. trace = TRUE를 추가하면 비교 대상 모형의 AICc 값이 출력된다.\n\nfit1 <- auto.arima(train_r, d = 0, stepwise = FALSE, \n                   approximation = FALSE, seasonal = FALSE, \n                   trace = TRUE)\n## \n##  ARIMA(0,0,0) with zero mean     : 862.9984\n##  ARIMA(0,0,0) with non-zero mean : 864.2264\n##  ARIMA(0,0,1) with zero mean     : 502.5603\n##  ARIMA(0,0,1) with non-zero mean : 503.849\n##  ARIMA(0,0,2) with zero mean     : 245.7837\n##  ARIMA(0,0,2) with non-zero mean : 247.1783\n##  ARIMA(0,0,3) with zero mean     : 81.487\n##  ARIMA(0,0,3) with non-zero mean : 83.02667\n##  ARIMA(0,0,4) with zero mean     : -20.65077\n##  ARIMA(0,0,4) with non-zero mean : -19.01766\n##  ARIMA(0,0,5) with zero mean     : -84.62715\n##  ARIMA(0,0,5) with non-zero mean : -82.85418\n##  ARIMA(1,0,0) with zero mean     : 184.3482\n##  ARIMA(1,0,0) with non-zero mean : 186.3166\n##  ARIMA(1,0,1) with zero mean     : -16.72114\n##  ARIMA(1,0,1) with non-zero mean : -14.73886\n##  ARIMA(1,0,2) with zero mean     : -74.34891\n##  ARIMA(1,0,2) with non-zero mean : -72.35703\n##  ARIMA(1,0,3) with zero mean     : -115.7122\n##  ARIMA(1,0,3) with non-zero mean : -113.7137\n##  ARIMA(1,0,4) with zero mean     : -133.8983\n##  ARIMA(1,0,4) with non-zero mean : -131.9025\n##  ARIMA(2,0,0) with zero mean     : -89.86221\n##  ARIMA(2,0,0) with non-zero mean : -88.00051\n##  ARIMA(2,0,1) with zero mean     : -113.8044\n##  ARIMA(2,0,1) with non-zero mean : -111.8785\n##  ARIMA(2,0,2) with zero mean     : -116.6196\n##  ARIMA(2,0,2) with non-zero mean : -114.6669\n##  ARIMA(2,0,3) with zero mean     : -130.7106\n##  ARIMA(2,0,3) with non-zero mean : -128.7274\n##  ARIMA(3,0,0) with zero mean     : -123.114\n##  ARIMA(3,0,0) with non-zero mean : -121.1507\n##  ARIMA(3,0,1) with zero mean     : -125.3355\n##  ARIMA(3,0,1) with non-zero mean : -123.3294\n##  ARIMA(3,0,2) with zero mean     : -123.8663\n##  ARIMA(3,0,2) with non-zero mean : -121.8527\n##  ARIMA(4,0,0) with zero mean     : -125.2705\n##  ARIMA(4,0,0) with non-zero mean : -123.2711\n##  ARIMA(4,0,1) with zero mean     : -123.4833\n##  ARIMA(4,0,1) with non-zero mean : -121.4641\n##  ARIMA(5,0,0) with zero mean     : -124.0066\n##  ARIMA(5,0,0) with non-zero mean : -121.9828\n## \n## \n## \n##  Best model: ARIMA(1,0,4) with zero mean\n\n적합 결과를 확인해 보면, ARMA(1,4) 모형이 선택된 것을 알 수 있다.\n\nfit1\n## Series: train_r \n## ARIMA(1,0,4) with zero mean \n## \n## Coefficients:\n##          ar1     ma1     ma2     ma3     ma4\n##       0.7769  1.1456  1.0384  0.7892  0.3022\n## s.e.  0.0450  0.0657  0.0922  0.0880  0.0627\n## \n## sigma^2 = 0.03511:  log likelihood = 73.1\n## AIC=-134.2   AICc=-133.9   BIC=-112.26\n\n이번에는 차분을 실시하는 경우에 대한 모형 적합을 진행해 보면, ARIMA(3,1,1) 모형이 선택된 것을 볼 수 있다.\n\nfit2 <- auto.arima(train_r, stepwise = FALSE, \n                   approximation = FALSE, seasonal = FALSE)\n\n\nfit2\n## Series: train_r \n## ARIMA(3,1,1) \n## \n## Coefficients:\n##          ar1      ar2     ar3      ma1\n##       1.9589  -1.3503  0.3304  -0.9855\n## s.e.  0.0580   0.1032  0.0576   0.0148\n## \n## sigma^2 = 0.03717:  log likelihood = 65.4\n## AIC=-120.81   AICc=-120.59   BIC=-102.55\n\n차분을 실시하지 않은 모형 fit1의 모형 진단을 실시해 보자. 모든 가정을 만족하는 것으로 보인다.\n\ncheckresiduals(fit1)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(1,0,4) with zero mean\n## Q* = 1.5628, df = 5, p-value = 0.9057\n## \n## Model df: 5.   Total lags used: 10\n\n차분을 실시한 모형 fit2의 모형 진단을 실시해 보자. 가정 만족에는 문제가 없는 것으로 보인다.\n\ncheckresiduals(fit2)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(3,1,1)\n## Q* = 11.352, df = 6, p-value = 0.07809\n## \n## Model df: 4.   Total lags used: 10\n\n두 모형 모두 예측모형으로 사용이 가능한 모형으로 보인다. 이제 두 모형 중 한 모형을 최종 예측모형으로 선택하는 것이 필요한데, 모형 fit1은 차분을 하지 않은 자료를 사용한 것이고, 모형 fit2는 차분을 실시한 자료를 사용한 것이다. 즉, 서로 다른 자료를 사용하여 적합한 모형이기 때문에, 두 모형의 AICc 등의 값을 비교하는 것은 의미가 없다. 이런 경우, 최종 예측모형 선택에 사용할 수 있는 방법은 test data에 대한 예측 결과를 근거로 하는 것이다. 두 모형을 사용하여 예측을 실시하고 test data와 비교해 보자.\n\nfc1 <- forecast(fit1)\nfc2 <- forecast(fit2)\n\n\naccuracy(fc1, test_r)\n##                        ME      RMSE       MAE      MPE     MAPE      MASE\n## Training set -0.003485182 0.1857419 0.1308396      NaN      Inf 0.5071232\n## Test set      0.197714969 0.2984918 0.2589217 261.7854 282.7786 1.0035587\n##                    ACF1 Theil's U\n## Training set 0.01278907        NA\n## Test set     0.63693511  1.231509\n\n\naccuracy(fc2, test_r)\n##                        ME      RMSE       MAE      MPE     MAPE      MASE\n## Training set -0.008064075 0.1911149 0.1333927      NaN      Inf 0.5170188\n## Test set      0.325580419 0.3713446 0.3255804 390.3076 437.7347 1.2619224\n##                     ACF1 Theil's U\n## Training set -0.03694615        NA\n## Test set      0.57275035  1.400976\n\n함수 accuracy()의 결과를 보면, ARMA(1,4) 모형인 fit1의 예측 오차가 조금 더 작은 것으로 보인다. 따라서 이 모형을 최종 예측모형으로 선택하기로 하자. 최종 예측모형의 모형식은 다음과 같다.\n\\[\n(1-0.7769B)~y_{t} = (1+1.145B+1.038B^{2}+0.789B^{3}+0.302B^{4})~\\varepsilon_{t}\n\\]\n예측 결과를 그래프로 나타내 보자. Test data와 함께 표시하는 것이 비교하기 좋을 것이며, 작성된 그래프는 Figure 11 에서 확인할 수 있다.\n\nautoplot(fc1, include = 20) + \n  autolayer(test_r, color = \"red\", size = .8) +\n  labs(y = \"rate\")\n\n\n\n\nFigure 11: rate 자료에 대한 예측 결과 그래프\n\n\n\n\n\n예제 2 : 1996년 1월부터 2012년 3월까지 Euro 지역에서의 월별 전자 제품 생산량 자료 (fpp2::elecequip)\n\n자료 elecequip은 계절 요인이 존재하는 월별 자료이다. 비계절형 ARIMA 모형을 적합하기 위해서는 계절 요소를 자료에서 제거해야 한다. 함수 stl()로 자료를 분해하고, 이어서 함수 forecast::seasadj()를 적용해서 계절 요소를 제거해 보자.\n\nelecequip_desea <- stl(elecequip, s.window=\"periodic\") %>% \n  seasadj()\n\n원자료와 계절 조정된 자료의 시계열 그래프를 Figure 12 에서 비교해 보자.\n\nautoplot(elecequip, series = \"Monthly data\") + \n  autolayer(elecequip_desea, \n            series = \"Seasonally adjusted\", size = .8) +\n  scale_color_manual(values = c(\"Monthly data\" = \"blue\", \n                                \"Seasonally adjusted\" = \"red\")) +\n  theme(legend.position = \"top\") +\n  labs(y = NULL, color = NULL)\n\n\n\n\nFigure 12: elecequip 원자료와 계절 조정된 자료의 비교\n\n\n\n\n계절 조정된 자료를 대상으로 자료 분리를 실시해 보자. Test data는 마지막 2년 자료로 한다.\n\ntrain_eq <- window(elecequip_desea, end = c(2010,3))\ntest_eq <- window(elecequip_desea, start = c(2010,4))\n\n정상성 판단을 위한 그래프를 Figure 13 에 작성해 보자.\n\nggtsdisplay(train_eq)\n\n\n\n\nFigure 13: train_eq의 정상성 여부 확인을 위한 그래프\n\n\n\n\n시간에 따른 level의 변화가 보이고, 표본 ACF가 매우 천천히 감소하는 것도 알 수 있다. 단위근 검정에서도 차분이 필요한 것으로 나타난다.\n\nndiffs(train_eq)\n## [1] 1\n\n차분된 자료를 대상으로 시계열 그래프와 ACF를 Figure 14 에 작성해 보자.\n\ntrain_eq %>% \n  diff() %>% \n  ggtsdisplay()\n\n\n\n\nFigure 14: train_eq의 차분한 자료의 정상성 여부 확인을 위한 그래프\n\n\n\n\n차분된 자료는 정상성을 만족하는 것으로 보인다. 또한 ACF는 지수적 감소, PACF는 3시차 이후 절단으로 볼 수 있기 때문에 차분된 자료는 AR(3) 모형으로 식별할 수 있고, 따라서 원자료는 ARIMA(3,1,0) 모형으로 식별할 수 있다.\n함수 auto.arima()에 의한 모형 선택을 실시해 보자.\n\nfit1 <- auto.arima(train_eq, stepwise = FALSE, \n                   approximation = FALSE, seasonal = FALSE)\nfit1\n## Series: train_eq \n## ARIMA(3,1,0) \n## \n## Coefficients:\n##           ar1      ar2     ar3\n##       -0.2922  -0.0635  0.3710\n## s.e.   0.0713   0.0748  0.0718\n## \n## sigma^2 = 9.169:  log likelihood = -428.36\n## AIC=864.73   AICc=864.97   BIC=877.27\n\nACF와 PACF에 의해 선택한 결과와 동일하게 ARIMA(3,1,0) 모형이 선택되었다. 모형식은 다음과 같다.\n\\[\n(1+0.292B+0.064B^{2}-0.371B^{3})(1-B)~y_{t}=\\varepsilon_{t}\n\\]\n적합된 모형의 검진을 실시해 보자. 잔차는 백색잡음 자료라고 할 수 있으며, 정규분포 가정에도 문제가 없는 것으로 보인다.\n\ncheckresiduals(fit1)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(3,1,0)\n## Q* = 20.702, df = 21, p-value = 0.4772\n## \n## Model df: 3.   Total lags used: 24\n\n예측을 실시하고, 예측 오차를 확인해 보자.\n\nfc1 <- forecast(fit1)\n\n\naccuracy(fc1, test_eq)\n##                        ME     RMSE      MAE         MPE     MAPE      MASE\n## Training set -0.002219982 2.992424 2.301026 -0.05081691 2.411491 0.2786977\n## Test set      8.727507127 9.330976 8.727507  9.28015517 9.280155 1.0570657\n##                     ACF1 Theil's U\n## Training set -0.03178277        NA\n## Test set      0.38874430  2.481532\n\n예측 결과를 Figure 15 에 그래프로 나타내 보자. 예측 결과가 test data와는 차이가 있음을 알 수 있다.\n\nautoplot(fc1, include = 20) + \n  autolayer(test_eq, color = \"red\", size = .8) +\n  ylab(\"Electrical equipment manufactured\")\n\n\n\n\nFigure 15: elecequip 자료에 대한 예측 결과\n\n\n\n\n\n\n\n\n예제 1 : 1984년 1월부터 1988년 12월 국내 백화점 매출액\n\n1984년 1월부터 1988년 12월까지 국내 어떤 백화점의 매출액 자료를 계절형 ARIMA 모형으로 적합하고 예측을 실시해 보자. 비교적 소규모 자료이기 때문에 자료를 training data와 test data로 분리하지 않고 전체 자료를 모두 사용하여 모형 적합을 진행하기로 하자. 먼저 자료를 불러오고 ts 객체로 변환시키자.\n\ndepart <- scan(\"https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/depart.txt\")\ndepart.ts <- ts(depart, start = 1984, freq = 12)\n\n시계열 객체 depart.ts의 시계열 그래프를 작성해 보자. Figure 16 의 시계열 그래프에서 뚜렷한 증가 추세와 계절 요소가 있음을 확인할 수 있다. 또한 계절 요소의 변동 폭이 증가 추세에 따라 함께 증가하고 있는 것도 볼 수 있다.\n\nautoplot(depart.ts) + \n  ylab(NULL)\n\n\n\n\nFigure 16: 국내 백화점 매출액 자료\n\n\n\n\n따라서 백화점 매출액 자료는 분산이 동일하지 않고, 추세와 계절 요소가 모두 있는 비정상 시계열자료임을 알 수 있다. 우선 로그변환을 실시한 자료의 시계열 그래프를 Figure 17 에 작성해서 분산이 일정하게 되었는지 확인해 보자.\n\nlndepart <- log(depart.ts)\nautoplot(lndepart) + \n  labs(title = \"log(depart.ts)\", y = NULL)\n\n\n\n\nFigure 17: 로그 변환된 백화점 매출액 자료\n\n\n\n\n계절 요소의 변동 폭이 일정하게 유지되고 있음을 알 수 있다. 이제 추세와 계절 요소를 제거하기 위한 차분 차수를 결정해 보자. 차분 차수는 시계열 그래프와 표본 ACF, 그리고 단위근 검정 결과를 모두 반영해서 결정하는 것이 좋다. 먼저 단위근 검정 결과를 확인해 보자. 1차 차분과 계절 차분이 모두 필요한 것으로 나타났다.\n\nndiffs(lndepart)\n## [1] 1\nnsdiffs(lndepart)\n## [1] 1\n\n이제 시계열 그래프와 표본 ACF의 형태를 Figure 17 에서 확인해 보자.\n\nggtsdisplay(lndepart, lag.max = 36, \n            main = \"lndepart: log transformed data\")\n\n\n\n\nFigure 18: lndepart의 시계열 그래프, ACF와 PACF\n\n\n\n\n차분과 계절 차분이 모두 필요한 것으로 보이는 경우에는 계절 차분을 먼저 실시하는 것이 좋다. 계절차분을 실시한 자료를 대상으로 시계열 그래프와 ACF를 작성해 보자. Figure 19 에서 표본 ACF가 1시차에서 6시차까지 매우 천천히 감소하는 것을 볼 수 있고, 따라서 일반 차분도 필요한 것으로 보인다.\n\nlndepart_12 <- diff(lndepart, lag = 12)\nggtsdisplay(lndepart_12, lag.max = 36, \n            main = \"Seasonally differenced lndepart\")\n\n\n\n\nFigure 19: 계절 차분을 실시한 lndepart의 시계열 그래프, ACF와 PACF\n\n\n\n\n1차 차분과 계절 차분을 모두 실시한 자료의 시계열 그래프와 ACF를 작성해 보자. 더 이상 비정상성 요소가 남아 있지 않다는 것을 Figure 20 에서 확인할 수 있다. 즉, 단위근 검정과 시계열 그래프, 그리고 표본 ACF를 근거로 계절 차분과 1차 차분이 모두 필요한 것으로 결정할 수 있다.\n\nlndepart_12_1 <- diff(lndepart_12)\nggtsdisplay(lndepart_12_1, lag.max = 36, \n            main = \"Doubly differenced lndepart\")\n\n\n\n\nFigure 20: 계절 차분과 1차 차분을 실시한 lndepart의 시계열 그래프, ACF와 PACF\n\n\n\n\n로그 변환과 계절 차분 및 1차 차분으로 비장상성을 모두 제거한 후에는 변환된 자료에 가장 적합한 모형을 식별해야 한다. Figure 20 에서 볼 수 있는 표본 ACF와 PACF를 근거로 모형을 식별해 보자. 비계절형 AR 차수와 MA 차수는 시차 1에서 시차 6까지의 패턴을 보고 결정해야 하는데, 표본 ACF는 1 시차만 유의한 값이고, 이후 시차는 모두 파란 점선 안으로 들어와 있음을 알 수 있고, 표본 PACF는 1, 2 시차가 비교적 큰 값이고, 이후 시차는 모두 점선 안으로 확실하게 들어와 있는 작은 값이다. 따라서 ACF는 1시차 이후 절단, PACF는 감소 형태로 판단할 수 있어서, 비계절형은 p=0, q=1인 MA(1)으로 식별할 수 있다.\n계절형 요소는 시차 12, 24, 36의 패턴으로 판단해야 하는데, ACF와 PACF가 12, 24, 36 시차에서 모두 작은 값을 보이고 있는 것을 볼 수 있다. 이러한 경우에는 P=0, Q=0으로 식별할 수도 있지만, P=1, Q=0 또는 P=0, Q=1으로 식별하는 것도 가능하다.\n따라서 표본 ACF와 PACF를 근거로 식별을 시도한다면, ARIMA(0,1,1)(0,1,0)12 모형과 ARIMA(0,1,1)(1,1,0)12 모형, 그리고 ARIMA(0,1,1)(0,1,1)12 모형으로 식별할 수 있다.\n이제 함수 auto.arima()를 사용하여 최적 모형을 식별해 보자. 함수 auto.arima()에서는 차분 차수를 단위근 검정에 의해 결정하는 것이 디폴트이며, 백화점 자료의 경우에는 가장 적절한 차분 차수가 단위근 검정 결과와 일치하기 때문에, d와 D에 다른 값을 지정할 필요는 없다. 또한 분산 안정화를 위해 로그 변환을 시행해야 하기 때문에 lambda에 로그변환에 해당하는 값인 0을 지정해야 한다.\n\nfit_d <- auto.arima(depart.ts, lambda = 0, \n                    stepwise = FALSE, approximation = FALSE)\n\n\nsummary(fit_d)\n## Series: depart.ts \n## ARIMA(0,1,1)(0,1,1)[12] \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##           ma1     sma1\n##       -0.5840  -0.4159\n## s.e.   0.1093   0.1946\n## \n## sigma^2 = 0.0005401:  log likelihood = 110.29\n## AIC=-214.59   AICc=-214.03   BIC=-209.04\n## \n## Training set error measures:\n##                     ME    RMSE      MAE       MPE    MAPE      MASE       ACF1\n## Training set -1.937472 16.9307 11.60509 -0.200563 1.36766 0.1084166 0.04358066\n\nACF와 PACF를 근거로 식별한 후보 모형 중 하나인 ARIMA(0,1,1)(0,1,1)12가 선택되었음을 알 수 있다.\n추정된 모형식은 다음과 같다.\n\\[\n(1-B^{12})(1-B)~\\log y_{t} = (1-0.584B)(1-0.4159B^{12})~\\varepsilon_{t}\n\\] 적합된 모형 fit_d의 모형의 진단을 실시해 보자. 잔차가 정규분포 백색잡음을 하는 것으로 보여서, 가정이 만족된다고 할 수 있다.\n\ncheckresiduals(fit_d)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(0,1,1)(0,1,1)[12]\n## Q* = 12.817, df = 10, p-value = 0.2341\n## \n## Model df: 2.   Total lags used: 12\n\n예측 결과를 Figure 21 에 그래프로 나타내보자. 예측 결과는 정상성 확보 과정에서 이루어진 변환의 역변환을 실시해서 얻어진 것이다.\n\nforecast(fit_d) %>% \n  autoplot() + ylab(NULL)\n\n\n\n\nFigure 21: 백화점 자료 예측 결과\n\n\n\n\n\n예제 2 : 1981년 1월부터 1992년 12월까지 국내에 입국한 월별 관광객 수\n\n1981년 1월부터 1992년 12월까지 12년 동안 국내에 입국한 월별 관광객 수 자료를 대상으로 ARIMA 모형과 ETS 모형으로 예측 모형을 각각 적합하고, 예측 결과를 비교해 보자. 예측 결과의 비교를 위해 마지막 2년 자료를 test data로 남겨두고, 이전 10년 동안의 자료를 이용하여 모형 적합을 실시해 보자.\n\ntour <- scan(\"https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/Ktour.txt\")\ntour.ts <- ts(tour, start = 1981, freq = 12)\ntrain_K <- window(tour.ts, end = c(1990,12))\ntest_K <- window(tour.ts, start = c(1991,1))\n\nTraining data에 대한 시계열 그래프를 Figure 22 에 작성해 보자.\n\nautoplot(train_K) +\n  ylab(NULL)\n\n\n\n\nFigure 22: 국내 입국 관광객 수 자료\n\n\n\n\n계절형 ARIMA 모형을 먼저 적합시켜 보자. 시계열자료가 증가하는 추세가 있고, 뚜렷한 계절 요소가 있으며, 계절 변동 폭이 점차 증가하는 모습을 보이는 비정상 시계열자료이다. 분산 안정화 변화가 필요한 것으로 보이며, 적절한 변환 형태를 결정하기 위해 Box-Cox 변환 모수 \\(\\lambda\\) 의 값을 추정해 보자.\n\nBoxCox.lambda(train_K) \n## [1] 0.09573094\n\n\n\n\n\\(\\hat{\\lambda}=\\) 0.096 로 추정되었는데, 이 결과를 그대로 적용해서 \\(y_{t}^{0.09}\\) 로 변환시키는 것보다는 변환의 해석이 가능하면서 추정된 \\(\\lambda\\) 값과 큰 차이가 없는 \\(\\hat{\\lambda}=0\\) 에 해당하는 로그 변환을 선택하는 것이 더 좋을 듯 하다.\n로그 변환된 자료에 대한 차분 차수를 결정해 보자. 먼저 로그 변환된 시계열자료의 시계열 그래프와 ACF를 Figure 23 에 작성해 보자.\n\nlntrain_K <- log(train_K)\nggtsdisplay(lntrain_K, \n            main = \"log transformed:lntrain_K\")\n\n\n\n\nFigure 23: lntrain_K의 시계열 그래프, ACF와 PACF\n\n\n\n\n계절 차분을 먼저 실시해 보고, 그 결과를 살펴보자. Figure 24 의 시계열 그래프에서 추세 성분이 남아 있는 것을 볼 수 있고, ACF의 1~6시차에서 상당히 큰 값을 볼 수 있다. 1차 차분이 필요한 것으로 보인다.\n\nlntrain_K_12 <- diff(lntrain_K, lag = 12)\nggtsdisplay(lntrain_K_12, \n            main = \"Seasonally differenced\")\n\n\n\n\nFigure 24: 계절 차분된 lntrain_K의 시계열 그래프, ACF와 PACF\n\n\n\n\n계절 차분된 자료에 다시 1차 차분을 실시하고, 그 결과를 살펴보자. Figure 25 의 그래프에서 비정상 요소가 모두 사라진 것을 알 수 있다.\n\nlntrain_K_12_1 <- diff(lntrain_K_12)\nggtsdisplay(lntrain_K_12_1, \n            main = \"Doubly differenced\")\n\n\n\n\nFigure 25: 계절 차분과 1차 차분된 lntrain_K의 시계열 그래프, ACF와 PACF\n\n\n\n\n단위근 검정에서도 일치된 결과를 볼 수 있다.\n\nndiffs(lntrain_K)\n## [1] 1\nnsdiffs(lntrain_K)\n## [1] 1\n\n로그변환과 차분을 통해 정산성을 만족한 자료의 ACF와 PACF인 Figure 25 를 이용하여 모형 식별을 시도해 보자. 1시차에서 6시차까지의 패턴으로 비계절 ARIMA 성분을 파악해 보자. ACF는 2시차까지 유의한 값을 보이고 있고, PACF는 1시차는 유의하고, 2시차의 값은 기준이 되는 파란 점선보다 약간 작은 값으로 보인다. 이런 경우에는 둘 중 하나를 절단으로 보든지, 아니면 둘 다 감소로 보는 것이 가능하기 떄문에 AR(1), AR(2), MA(2), 또는 ARMA(1,1) 등이 가능한 것으로 보인다.\n계절형 ARIMA 성분은 ACF와 PACF 모두 12시차에서 유의한 값을 보이지만, 24시차와 36시차에서는 매우 작은 값을 보이고 있기 때문에 ACF와 PACF 중 하나를 절단으로 보든지, 둘 다 감소로 보는 것이 가능하며, AR(1)12, MA(1)12, 또는 ARMA(1,1)12 등이 가능한 것으로 보인다.\n식별된 비계절형과 계절형을 조합해서 보면, 많은 모형이 가능한 것으로 보인다. ARIMA(1,1,0)(1,1,0)12모형, ARIMA(1,1,0)(0,1,1)12모형, ARIMA(1,1,0)(1,1,1)12모형과 ARIMA(2,1,0)(1,1,0)12모형, ARIMA(2,1,0)(0,1,1)12모형, ARIMA(2,1,0)(1,1,1)12모형, 그리고 ARIMA(1,1,1)(1,1,0)12모형, ARIMA(1,1,1)(0,1,1)12모형, ARIMA(1,1,1)(1,1,1)12모형 등이 가능한 모형으로 보인다.\nACF와 PACF를 근거로 직접 모형 식별하는 것은 이렇듯 명확한 결과가 나오는 것이 아니어서, 많은 후보 모형을 식별하고 이어서 그 모형들을 비교하는 과정을 거쳐서 최종 모형을 선택해야 하는 어렵고 긴 작업 절차가 필요한 방법임을 알 수 있다. 따라서 이 과정이 모든 분석에서 반드시 필요하다고 생각하지는 않지만, 함수 auto.arima()로 선택된 모형이 ACF와 PACF를 근거로 식별된 후보 모형 중에 포함되는지 여부는 확인하는 것이 필요하다고 본다.\n이제 함수 auto.arima()로 모형을 선택해 보자.\n\nfit_K <- auto.arima(train_K, lambda = 0, \n                    stepwise = FALSE, approximation = FALSE)\n\n\nsummary(fit_K)\n## Series: train_K \n## ARIMA(2,1,0)(1,1,1)[12] \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##           ar1      ar2     sar1     sma1\n##       -0.6995  -0.2496  -0.2892  -0.3817\n## s.e.   0.0956   0.0947   0.1695   0.1736\n## \n## sigma^2 = 0.002917:  log likelihood = 159.82\n## AIC=-309.63   AICc=-309.04   BIC=-296.27\n## \n## Training set error measures:\n##                     ME     RMSE      MAE        MPE     MAPE      MASE\n## Training set -117.8446 8079.833 5752.686 -0.1325567 3.815935 0.3223641\n##                   ACF1\n## Training set 0.1387895\n\nARIMA(2,1,0)(1,1,1)12모형이 선택되었고, 이 모형은 ACF와 PACF를 근거로 선택한 후보 모형 중에 하나이다. 적합된 모형식은 다음과 같다.\n\\[\n(1+0.69B+0.25B^{2})(1+0.29B^{12})(1-B)(1-B^{12})~\\log y_{t} = (1-0.382^{12})~\\varepsilon_{t}\n\\]\n이제는 ETS 모형을 적합해 보자. ETS 모형에서는 승법모형이 가능하기 때문에 분산안정화를 위한 변환이 반드시 필요한 것은 아니다. 따라서 원자료에 의한 ETS 모형과 로그 변환된 자료의 ETS 모형을 모두 적합시켜 보자.\n먼저 로그 변환된 자료를 대상으로 모형을 적합해 보자.\n\nfit_K_ets1 <- ets(train_K, lambda = 0)\n\n\nsummary(fit_K_ets1)\n## ETS(A,Ad,A) \n## \n## Call:\n##  ets(y = train_K, lambda = 0) \n## \n##   Box-Cox transformation: lambda= 0 \n## \n##   Smoothing parameters:\n##     alpha = 0.3998 \n##     beta  = 0.0242 \n##     gamma = 1e-04 \n##     phi   = 0.978 \n## \n##   Initial states:\n##     l = 11.3617 \n##     b = 0.0098 \n##     s = -0.2089 -0.0012 0.1585 0.0577 0.1123 0.035\n##            0.0516 0.1154 0.0989 0.0121 -0.2092 -0.2221\n## \n##   sigma:  0.0548\n## \n##        AIC       AICc        BIC \n## -104.72171  -97.94943  -54.54685 \n## \n## Training set error measures:\n##                    ME     RMSE      MAE       MPE     MAPE      MASE       ACF1\n## Training set 1116.089 8322.678 5764.589 0.4909287 3.788076 0.3230311 0.09314822\n\nETS(A,Ad,A) 모형이 선택되었다.\n이제 원자료를 대상으로 모형을 적합해 보자.\n\nfit_K_ets2 <- ets(train_K)\n\n\nsummary(fit_K_ets2)\n## ETS(M,Ad,M) \n## \n## Call:\n##  ets(y = train_K) \n## \n##   Smoothing parameters:\n##     alpha = 0.4275 \n##     beta  = 0.0306 \n##     gamma = 1e-04 \n##     phi   = 0.9799 \n## \n##   Initial states:\n##     l = 89459.3204 \n##     b = 291.8495 \n##     s = 0.808 0.9953 1.172 1.0557 1.1073 1.0353\n##            1.0453 1.1046 1.0949 0.9939 0.7992 0.7886\n## \n##   sigma:  0.0562\n## \n##      AIC     AICc      BIC \n## 2738.255 2745.028 2788.430 \n## \n## Training set error measures:\n##                    ME     RMSE      MAE       MPE     MAPE      MASE       ACF1\n## Training set 1147.204 8155.819 5774.677 0.5763675 3.839131 0.3235964 0.02357097\n\nETS(M,Ad,M) 모형이 선택되었다. 두 ETS 모형 모두 추세는 ’damped additive’가 선택되었지만, 로그 변환된 자료에 대해서는 계절 요소와 오차항이 모두 ’additive’이고, 원자료에 대해서는 계절 요소와 오차항이 모두 ’multiplicative’임을 알 수 있다.\n이제 적합된 ARIMA 모형과 ETS 모형의 모형 진단을 각각 실시해 보자. 먼저 ARIMA 모형의 경우에는 오차에 대한 가정이 모두 만족되는 것으로 보인다.\n\ncheckresiduals(fit_K)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(2,1,0)(1,1,1)[12]\n## Q* = 27.495, df = 20, p-value = 0.1219\n## \n## Model df: 4.   Total lags used: 24\n\nETS 모형의 경우에는 Ljung-Box 검정의 p-value가 매우 작은 값으로 계산되었고, 따라서 오차의 독립성은 만족되지 않았다. 이런 경우에는 ETS 모형으로 예측된 결과에 대한 신빙성이 떨어진다고 볼 수 있는데, 점 예측값보다는 예측 구간에 대한 신뢰도에 더 큰 손상이 있었다고 할 수 있다.\n구제적인 검진 결과를 살펴보자. 우선 ETS(A,Ad,A) 모형인 fit_K_ets1 모형의 검진 결과이다.\n\ncheckresiduals(fit_K_ets1)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ETS(A,Ad,A)\n## Q* = 36.158, df = 7, p-value = 6.769e-06\n## \n## Model df: 17.   Total lags used: 24\n\nETS(M,Ad,M) 모형인 fit_K_ets2 모형의 검진 결과도 살펴보자.\n\ncheckresiduals(fit_K_ets2)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ETS(M,Ad,M)\n## Q* = 34.451, df = 7, p-value = 1.418e-05\n## \n## Model df: 17.   Total lags used: 24\n\n이제 test data에 대한 예측을 실시하고 예측 오차를 비교해 보자.\n\nfc_K <- forecast(fit_K)\naccuracy(fc_K, test_K)\n##                       ME      RMSE       MAE         MPE      MAPE      MASE\n## Training set   -117.8446  8079.833  5752.686  -0.1325567  3.815935 0.3223641\n## Test set     -33473.2740 45118.350 37348.980 -12.4581745 13.967241 2.0929303\n##                   ACF1 Theil's U\n## Training set 0.1387895        NA\n## Test set     0.6467465   1.67741\n\n\nfc_K_ets1 <- forecast(fit_K_ets1)\naccuracy(fc_K_ets1, test_K)\n##                      ME      RMSE       MAE        MPE      MAPE      MASE\n## Training set   1116.089  8322.678  5764.589  0.4909287  3.788076 0.3230311\n## Test set     -26763.496 38813.714 33571.599 -9.9007782 12.507782 1.8812566\n##                    ACF1 Theil's U\n## Training set 0.09314822        NA\n## Test set     0.55156580  1.469369\n\n\nfc_K_ets2 <- forecast(fit_K_ets2)\naccuracy(fc_K_ets2, test_K)\n##                      ME      RMSE       MAE        MPE      MAPE      MASE\n## Training set   1147.204  8155.819  5774.677  0.5763675  3.839131 0.3235964\n## Test set     -25539.311 37954.952 32640.675 -9.4299420 12.153867 1.8290903\n##                    ACF1 Theil's U\n## Training set 0.02357097        NA\n## Test set     0.54315176  1.439223\n\n큰 차이는 없지만 ETS(M,Ad,M) 모형인 fit_K_ets2 모형의 예측 오차가 조금 더 작은 것으로 나타났다. ARIMA 모형과 ETS(M,Ad,M) 모형의 예측 결과를 Figure 26 의 그래프로 비교해 보자.\n\np1 <- autoplot(fc_K, include = 24) +\n  autolayer(test_K, color = \"red\", size = .8) +\n  ylab(NULL)\n\np2 <- autoplot(fc_K_ets2, include = 24) +\n  autolayer(test_K, color = \"red\", size = .8) +\n  ylab(NULL)\np1 / p2\n\n\n\n\nFigure 26: 국내 입국 관광객 수 자료에 대한 예측 결과\n\n\n\n\n\n\n\n\n다음에 주어지는 시계열 그래프와 ACF를 근거로 해당 시계열 자료의 정상성 만족 여부를 확인하고, 정상성이 만족되다고 판단되면 ACF 및 PACF를 이용하여 모형식별을 진행해 보자.\n\n\n\n\n\n\nFigure 27: EX 1)\n\n\n\n\n\n\n\n\n\nFigure 28: Ex 2)\n\n\n\n\n\n\n\n\n\nFigure 29: Ex 3)\n\n\n\n\n\n\n\n\n\nFigure 30: Ex 4)\n\n\n\n\n\n다음의 자료에 대하여 ARIMA 모형과 ETS 모형에 의한 예측을 실시하고 예측 오차를 비교해 보자. Test data는 마지막 10개 시점으로 한다. 처음 4개 자료는 웹 서버 https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/ 에서 불러올 수 있다.\n\n\narima_ex2_1.txt\narima_ex2_2.txt\narima_ex2_3.txt\narima_ex2_4.txt\nfpp2::ausair"
  },
  {
    "objectID": "5-regression.html",
    "href": "5-regression.html",
    "title": "",
    "section": "",
    "text": "예제 : 분기별 호주 맥주 생산량 자료 (fpp2::ausbeer)\n\n1. 백색잡음오차 시계열 회귀모형 적합\nausbeer는 1956년 1분기부터 2010년 2분기까지 호주의 분기별 맥주 생산량이다. 전체 기간 중 1975년 1분기 이후 자료에 대한 회귀모형을 적합시켜보자. 마지막 2년 자료는 test data로 남겨두자.\n\ntrain_b <- window(ausbeer, start = 1975, end = c(2008, 2))\ntest_b <- window(ausbeer, start = c(2008, 3))\n\nFigure 1 은 전체 자료의 시계열 그래프이다. Test data는 빨간 색으로 구분했다.\n\nautoplot(train_b) + \n  autolayer(test_b, color = \"red\", size = 0.8) + \n  labs(y = NULL, x = NULL)\n\n\n\n\nFigure 1: 자료 ausbeer의 시계열 그래프\n\n\n\n\n시계열자료에 대한 회귀모형의 적합은 함수 tslm()으로 할 수 있다. 함수 tslm()은 lm()과 실질적으로 동일한 함수지만, ts 객체에 대한 회귀모형 적합을 위한 함수이다. 잔차 및 적합값이 ts 객체로 생성되고, 결측값 처리 방식이 시계열자료에 적합하도록 설정되었다.\n추세 변수와 계절 변수를 시점 \\(t\\)를 이용하여 생성하는 방법을 살펴보자. 먼저 추세 변수는 함수 time()으로 자료가 관측된 시점을 생성할 수 있다. 자료 train_b에 대해 함수 time()을 적용한 결과를 살펴보자. 1975년 1분기 값을 1975.00으로 두고, 1/4 간격으로 다음 분기의 관측 시점을 생성하고 있다.\n\ntime(train_b)[1:9]\n## [1] 1975.00 1975.25 1975.50 1975.75 1976.00 1976.25 1976.50 1976.75 1977.00\n\n관측 시점을 \\(t = 1, 2, 3, \\ldots\\) 로 하여 사용하고자 한다면, 1:length(train_b)를 추세 변수로 사용하거나, 함수 tslm()에서 trend를 추세 변수로 사용하면 된다.\n계절 변수로 dummy 변수를 사용한다면 함수 forecast::seasonaldummy()를 사용하거나, 함수 tslm()에서 season을 변수로 사용하면 된다. 계절 주기에 맞추어 필요한 dummy 변수를 생성한다.\n\nseasonaldummy(train_b)[1:5,]\n##      Q1 Q2 Q3\n## [1,]  1  0  0\n## [2,]  0  1  0\n## [3,]  0  0  1\n## [4,]  0  0  0\n## [5,]  1  0  0\n\nFourier series 변수를 사용한다면 함수 forecast::fourier()를 사용하면 된다. 모형에 포함되는 fourier series 변수들의 최대 주기는 옵션 K에 지정하면 된다.\n\nfourier(train_b, K = 2)[1:5,]\n##      S1-4 C1-4 C2-4\n## [1,]    1    0   -1\n## [2,]    0   -1    1\n## [3,]   -1    0   -1\n## [4,]    0    1    1\n## [5,]    1    0   -1\n\nS1-4와 C1-4는 \\(K=1\\) 에 해당하는 \\(\\sin(2\\pi t/4)\\) 와 \\(\\cos(2\\pi t/4)\\) 를 의미하고, C2-4는 \\(K=2\\) 에 해당하는 \\(\\cos(2\\pi 2t/4)\\) 를 나타내고 있다.\n함수 time()에 의한 추세 변수와 seasonaldummy()에 의한 계절 변수를 사용하여 회귀모형을 적합해 보고, 그 결과를 확인해 보자.\n\nfit1 <- tslm(train_b ~ time(train_b) + seasonaldummy(train_b))\n\n\nsummary(fit1)\n## \n## Call:\n## tslm(formula = train_b ~ time(train_b) + seasonaldummy(train_b))\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -47.776 -11.771  -0.738  10.842  63.468 \n## \n## Coefficients:\n##                           Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)              5335.5613   325.0641   16.41   <2e-16 ***\n## time(train_b)              -2.4112     0.1632  -14.78   <2e-16 ***\n## seasonaldummy(train_b)Q1  -74.4299     4.4641  -16.67   <2e-16 ***\n## seasonaldummy(train_b)Q2 -118.3271     4.4639  -26.51   <2e-16 ***\n## seasonaldummy(train_b)Q3 -105.7240     4.4973  -23.51   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 18.27 on 129 degrees of freedom\n## Multiple R-squared:  0.8911, Adjusted R-squared:  0.8877 \n## F-statistic: 263.9 on 4 and 129 DF,  p-value: < 2.2e-16\n\n이번에는 변수 trend와 season을 사용해서 적합해 보고, 결과를 확인해 보자.\n\nfit2 <- tslm(train_b ~ trend + season)\n\n\nsummary(fit2)\n## \n## Call:\n## tslm(formula = train_b ~ trend + season)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -47.776 -11.771  -0.738  10.842  63.468 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 499.6812     4.1577 120.181  < 2e-16 ***\n## trend        -0.6028     0.0408 -14.775  < 2e-16 ***\n## season2     -43.8972     4.4306  -9.908  < 2e-16 ***\n## season3     -31.2941     4.4639  -7.011 1.19e-10 ***\n## season4      74.4299     4.4641  16.673  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 18.27 on 129 degrees of freedom\n## Multiple R-squared:  0.8911, Adjusted R-squared:  0.8877 \n## F-statistic: 263.9 on 4 and 129 DF,  p-value: < 2.2e-16\n\nfit1과 fit2의 적합 결과가 서로 다른 것처럼 보인다. 그러나 추세의 기울기가 다른 것은 모형에서 사용된 추세 변수의 간격이 다르기 때문이다. 즉, 두 모형의 추세 기울기가 4배 차이 나는 이유는 모형 fit1에서 사용된 추세 변수의 간격이 1/4인 반면에 모형 fit2에서 사용된 추세 변수의 간격은 1이기 때문이다.\n또한 절편이 다른 것은 두 모형의 기준 범주가 다르며, 사용된 추세 변수의 범위가 다르기 때문이다. 즉, fit1에서 사용된 추세 변수는 1975.00부터 값을 갖고 있지만, fit2에서는 추세 변수가 1부터 값을 갖고 있으며, 함수 seasonaldummy()는 마지막 범주를 기준 범주로 설정하는데, 변수 season은 첫 번째 범주를 기준 범주로 설정하고 있어서, dummy 변수의 구성도 다르게 된다.\n두 모형의 적합값을 비교해 보면 실질적으로 같은 모형임을 알 수 있다.\n\ntibble(fit1 = fit1$fitted, fit2 = fit2$fitted)\n## # A tibble: 134 × 2\n##     fit1  fit2\n##    <dbl> <dbl>\n##  1  499.  499.\n##  2  455.  455.\n##  3  467.  467.\n##  4  572.  572.\n##  5  497.  497.\n##  6  452.  452.\n##  7  464.  464.\n##  8  569.  569.\n##  9  494.  494.\n## 10  450.  450.\n## # … with 124 more rows\n\n이번에는 함수 time()에 의한 추세 변수와 fourier()에 의한 Fourier series 변수를 사용하여 회귀모형을 적합해 보고, 그 결과를 확인해 보자. 분기별 자료의 최대 주기인 K=2를 지정해서 확인해 보자.\n\nfit3 <- tslm(train_b ~ time(train_b) + fourier(train_b, K=2))\n\n\nsummary(fit3)\n## \n## Call:\n## tslm(formula = train_b ~ time(train_b) + fourier(train_b, K = 2))\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -47.776 -11.771  -0.738  10.842  63.468 \n## \n## Coefficients:\n##                              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                 5260.9410   325.0320  16.186  < 2e-16 ***\n## time(train_b)                 -2.4112     0.1632 -14.775  < 2e-16 ***\n## fourier(train_b, K = 2)S1-4   15.6471     2.2319   7.011 1.19e-10 ***\n## fourier(train_b, K = 2)C1-4   59.1635     2.2319  26.508  < 2e-16 ***\n## fourier(train_b, K = 2)C2-4   15.4567     1.5784   9.793  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 18.27 on 129 degrees of freedom\n## Multiple R-squared:  0.8911, Adjusted R-squared:  0.8877 \n## F-statistic: 263.9 on 4 and 129 DF,  p-value: < 2.2e-16\n\nFourier series의 모든 변수를 사용한 모형은 dummy 변수를 사용한 모형과 실질적으로 동일한 모형이 된다. fit1과 fit3의 적합값을 비교해 보자.\n\ntibble(fit1 = fit1$fitted, fit3 = fit3$fitted)\n## # A tibble: 134 × 2\n##     fit1  fit3\n##    <dbl> <dbl>\n##  1  499.  499.\n##  2  455.  455.\n##  3  467.  467.\n##  4  572.  572.\n##  5  497.  497.\n##  6  452.  452.\n##  7  464.  464.\n##  8  569.  569.\n##  9  494.  494.\n## 10  450.  450.\n## # … with 124 more rows\n\n시계열자료 회귀모형의 모형 진단을 실시해서, 가정 만족에 문제가 있는지 확인해 보자. 함수 checkresiduals()는 lm() 또는 tslm()으로 생성된 객체에 대해서 Breusch-Godfrey 검정으로 독립성을 확인한다. 검정 결과는 오차가 독립이 아니라는 결론이며, 잔차의 시계열 그래프와 ACF에서도 같은 모습을 확인할 수 있다. 시계열자료에 회귀모형을 적합해 생성된 잔차 사이에는 강한 상관 관계가 존재하고 있음을 확인할 수 있었다. 이것은 설명이 안 된 패턴이 남아 있음을 의미하는 것이며, 따라서 추가적인 작업이 필요한 것이다.\n\ncheckresiduals(fit1)\n\n\n\n## \n##  Breusch-Godfrey test for serial correlation of order up to 8\n## \n## data:  Residuals from Linear regression model\n## LM test = 30.158, df = 8, p-value = 0.0001982\n\n2. ARMA 오차 시계열 회귀모형 적합\n자료 ausbeer에 대해 적합된 백색잡음 회귀모형은 잔차가 독립성을 만족하지 못하는 문제가 발견되었다. 잔차에 남아 있는 패턴을 ARMA 모형으로 설명하기 위해 ARMA 오차 회귀모형을 적합시켜보자.\n\ntrain_b <- window(ausbeer, start = 1975, end = c(2008, 2))\ntest_b <- window(ausbeer, start = c(2008, 3))\n\n\nfit4 <- auto.arima(train_b,\n                   xreg = cbind(Time = time(train_b), \n                                Qtr = seasonaldummy(train_b)),\n                   stepwise = FALSE)\n\n\nsummary(fit4)\n## Series: train_b \n## Regression with ARIMA(3,0,0)(1,0,0)[4] errors \n## \n## Coefficients:\n##           ar1     ar2     ar3    sar1  intercept     Time    Qtr.Q1     Qtr.Q2\n##       -0.1233  0.1645  0.2440  0.4155  5227.3160  -2.3573  -73.4170  -117.2944\n## s.e.   0.0852  0.0831  0.0849  0.0817   611.6432   0.3071    6.0565     5.2917\n##          Qtr.Q3\n##       -105.5713\n## s.e.     6.0999\n## \n## sigma^2 = 264.2:  log likelihood = -559.59\n## AIC=1139.19   AICc=1140.97   BIC=1168.16\n## \n## Training set error measures:\n##                     ME     RMSE      MAE         MPE     MAPE      MASE\n## Training set 0.1677325 15.69822 12.11679 -0.07293605 2.618274 0.7416116\n##                     ACF1\n## Training set 0.004529308\n\n잔차에 가장 적합한 모형은 ARIMA(3,0,0)(1,0,0)4가 선택되었다. 즉, 잔차에 비계절형 요소 뿐 아니라 계절형 요소도 남아 있다는 것이다.\nARMA 오차 회귀모형 fit4에 대한 모형 진단을 실시해 보자. 모든 가정이 만족되고 있음을 알 수 있다.\n\ncheckresiduals(fit4)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from Regression with ARIMA(3,0,0)(1,0,0)[4] errors\n## Q* = 0.64935, df = 4, p-value = 0.9574\n## \n## Model df: 4.   Total lags used: 8\n\nARMA 오차 회귀모형의 예측은 함수 forecast()로 할 수 있다. 사용법은 forecast(object, xreg, ...)가 되는데, object에는 함수 Arima() 혹은 auto.arima()로 생성된 객체를 지정하고, xreg에는 예측 시점에 대한 설명변수의 자료를 벡터 또는 행렬의 형태로 지정하면 된다.\nTest data인 test_b에 대한 예측을 실시해 보자.\n\nfc4 <- forecast(fit4, \n                xreg = cbind(Time = time(test_b), \n                             Qtr = seasonaldummy(test_b))\n                )\n\nARMA 오차 회귀모형의 예측 결과와 백색잡음 회귀모형의 예측 결과를 비교해 보자. 함수 tslm()에 변수 trend와 season을 사용한 fit2에 대한 예측은 다음과 같이 실시할 수 있다.\n\nfit2 <- tslm(train_b ~ trend + season)\nfc2 <- forecast(fit2, h = length(test_b))\n\n점 예측 결과는 fc2$mean과 fc4$mean에 할당되어 있다. 두 결과를 비교해 보자. 큰 차이는 없는 것으로 보인다.\n\ntibble(fc2 = fc2$mean, fc4 = fc4$mean)\n## # A tibble: 8 × 2\n##     fc2   fc4\n##   <dbl> <dbl>\n## 1  387.  383.\n## 2  492.  485.\n## 3  417.  420.\n## 4  373.  378.\n## 5  385.  384.\n## 6  490.  487.\n## 7  415.  416.\n## 8  370.  373.\n\n95% 예측 구간의 폭을 비교해 보자. 예측 구간의 상한은 fc2$upper과 fc4$upper에 할당되었고, 하한은 fc2$lower과 fc4$lower에 각각 할당되어 있다. 예측 구간의 신뢰수준으로 80%와 95%가 사용되는 것이 디폴트이며, 따라서 다음과 같이 95% 예측 구간의 폭을 계산할 수 있다. ARMA 오차 회귀모형의 예측 구간인 fc4의 폭이 더 좁은 것을 확인할 수 있다.\n\ntibble(fc2 = fc2$upper[,2] - fc2$lower[,2], \n       fc4 = fc4$upper[,2] - fc4$lower[,2])\n## # A tibble: 8 × 2\n##     fc2   fc4\n##   <dbl> <dbl>\n## 1  74.2  63.7\n## 2  74.2  64.2\n## 3  74.2  65.2\n## 4  74.2  66.5\n## 5  74.3  71.0\n## 6  74.3  71.0\n## 7  74.3  71.3\n## 8  74.3  71.5\n\n예측 오차의 크기를 비교해 보자. 예측 오차의 크기에는 큰 차이가 없음을 알 수 있다.\n\naccuracy(fc2, test_b)\n##                        ME     RMSE      MAE        MPE     MAPE      MASE\n## Training set 8.491860e-16 17.92314 13.57971 -0.1317235 2.924979 0.8311500\n## Test set     9.745836e+00 17.30833 11.90530  2.4185316 2.886254 0.7286673\n##                     ACF1 Theil's U\n## Training set 0.007149994        NA\n## Test set     0.048860146 0.3056324\n\n\naccuracy(fc4, test_b)\n##                      ME     RMSE      MAE         MPE     MAPE      MASE\n## Training set  0.1677325 15.69822 12.11679 -0.07293605 2.618274 0.7416116\n## Test set     10.0161277 17.40591 11.67960  2.42511984 2.826267 0.7148528\n##                     ACF1 Theil's U\n## Training set 0.004529308        NA\n## Test set     0.049644862 0.2895782\n\n예측 결과를 그래프로 나타내서 비교해 보자.\n\nlibrary(patchwork)\n\n\np1 <- autoplot(fc2, include=8) +\n  autolayer(test_b, color = \"red\", size=.8) +\n  labs(y = NULL, x = NULL)\n\np2 <- autoplot(fc4, include=8) +\n  autolayer(test_b, color = \"red\", size=.8) +\n  labs(y = NULL, x = NULL)\np1 + p2\n\n\n\n\nFigure 2: ausbeer 자료에 대한 예측 결과\n\n\n\n\n\n예제: 1970년 1월부터 2005년 12월까지 지구 기온 자료 (global.txt)\n\nglobal.txt는 1856년 1월부터 2005년 12월까지의 지구 기온 자료 자료인데, 그 중 1970년 이후 자료만을 대상으로 ARMA 오차 회귀모형과 ARIMA 모형, 그리고 ETS 모형으로 예측 모형을 각각 적합시키고 예측 결과를 비교해 보자.\n자료를 불러 들이고 training data와 test data로 분리시키자.\n\nglobal <- scan(\"https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/global.txt\")\nglobal.ts <- ts(global, start = c(1856, 1), frequency = 12)\ntrain_g <- window(global.ts, start = 1970, end = c(2003,12))\ntest_g <- window(global.ts, start = 2004)\n\nFigure 3 은 1970년부터 자료의 시계열 그래프이다. Test data는 빨간 색으로 구분했다.\n\nautoplot(train_g) + \n  autolayer(test_g, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL)\n\n\n\n\nFigure 3: 자료 global.txt의 training data와 test data의 시계열 그래프\n\n\n\n\n1. ARMA 오차 회귀모형 적합\n계절 성분이 있는 시계열자료에 회귀모형을 적용할 때에는 계절 성분을 dummy 변수로 나타낼 것인지, Fourier series 변수로 나타낼 것인지를 선택해야 한다. 먼저 선형 추세와 dummy 변수를 사용한 회귀모형을 적합시켜 보자. 추세 변수는 함수 time()으로 생성하고, 계절 변수는 함수 seasonaldummy()로 생성한다.\n\nTime <- time(train_g)\nMonth <- seasonaldummy(train_g)\n\n모형 fit1의 적합 과정에서 stepwise = FASLE와 approximation = FALSE를 제외했는데, 두 옵션을 추가해도 같은 결과를 얻게 된다.\n\nfit1 <- auto.arima(train_g, xreg = cbind(Time, Month))\n\n\nsummary(fit1)\n## Series: train_g \n## Regression with ARIMA(2,0,0) errors \n## \n## Coefficients:\n##          ar1     ar2  intercept    Time  Month.Jan  Month.Feb  Month.Mar\n##       0.4932  0.3204   -34.5510  0.0175     0.0409     0.0522     0.0268\n## s.e.  0.0469  0.0472     4.2613  0.0021     0.0161     0.0171     0.0195\n##       Month.Apr  Month.May  Month.Jun  Month.Jul  Month.Aug  Month.Sep\n##          0.0250     0.0093     0.0162     0.0137     0.0151     0.0002\n## s.e.     0.0204     0.0211     0.0213     0.0211     0.0204     0.0194\n##       Month.Oct  Month.Nov\n##          -0.015    -0.0304\n## s.e.      0.017     0.0160\n## \n## sigma^2 = 0.007112:  log likelihood = 437.21\n## AIC=-842.41   AICc=-841.02   BIC=-778.23\n## \n## Training set error measures:\n##                         ME       RMSE        MAE      MPE     MAPE      MASE\n## Training set -0.0007778394 0.08276884 0.06379682 22.62755 81.57672 0.4285951\n##                     ACF1\n## Training set 0.006984407\n\n잔차는 AR(2) 모형으로 적합되었다.\n이번에는 선형 추세와 Fourier series 변수를 사용한 회귀모형을 적합시켜 보자. Fourier series 변수를 사용하기 위해서는 최적 주기를 결정해야 한다.\n\nTime <- time(train_g)\nres <- vector(\"numeric\", 6)\nfor(i in seq(res)){\n  xreg <- cbind(Time, fourier(train_g, K = i))\n  fit <- auto.arima(train_g, xreg = xreg)\n  res[i] <- fit$aicc\n}\n\n객체 res에는 6개 모형의 AICc가 입력되어 있다. 그 중 두 번째 모형의 AICc가 가장 작은 값임을 확인할 수 있다.\n\nres\n## [1] -840.8765 -851.6310 -850.3429 -846.7538 -842.5771 -841.0206\n\n\n(k_min <- which.min(res))\n## [1] 2\n\n이제 \\(K=2\\) 를 최적 주기로 하는 Fourier series 변수를 사용한 회귀모형을 적합시켜 보자.\n\nFourier <- fourier(train_g, K = k_min)\nfit2 <- auto.arima(train_g, xreg = cbind(Time, Fourier))\n\n\nsummary(fit2)\n## Series: train_g \n## Regression with ARIMA(2,0,0) errors \n## \n## Coefficients:\n##          ar1     ar2  intercept    Time  Fourier.S1-12  Fourier.C1-12\n##       0.4919  0.3200   -34.4729  0.0174         0.0210        -0.0047\n## s.e.  0.0469  0.0472     4.2484  0.0021         0.0088         0.0087\n##       Fourier.S2-12  Fourier.C2-12\n##              0.0192        -0.0054\n## s.e.         0.0051         0.0051\n## \n## sigma^2 = 0.007062:  log likelihood = 435.04\n## AIC=-852.08   AICc=-851.63   BIC=-815.98\n## \n## Training set error measures:\n##                         ME       RMSE       MAE      MPE     MAPE      MASE\n## Training set -0.0007984029 0.08320983 0.0640202 22.23643 80.56552 0.4300958\n##                     ACF1\n## Training set 0.004973903\n\nfit1의 경우와 동일하게 fit2에서도 잔차는 AR(2) 모형으로 적합되었다.\n두 모형의 검진을 실시해 보자. 먼저 선형 추세와 dummy 변수를 사용한 회귀모형인 모형 fit1의 모형 검진을 진행해 보자. 모형 fit1의 경우에는 가정 만족에 큰 문제가 없는 것으로 보인다.\n\ncheckresiduals(fit1)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from Regression with ARIMA(2,0,0) errors\n## Q* = 27.817, df = 22, p-value = 0.1818\n## \n## Model df: 2.   Total lags used: 24\n\n선형 추세와 Fourier series 변수를 사용한 회귀모형인 모형 fit2의 모형 검진도 진행해 보자. 모형 fit2에도 큰 문제 없이 가정을 만족하고 있음을 알 수 있다.\n\ncheckresiduals(fit2)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from Regression with ARIMA(2,0,0) errors\n## Q* = 27.53, df = 22, p-value = 0.1918\n## \n## Model df: 2.   Total lags used: 24\n\n이제 두 회귀모형 중 한 모형을 선택해 보자. 선택 기준으로는 AICc를 사용해 보자.\n\nc(fit1$aicc, fit2$aicc)\n## [1] -841.0206 -851.6310\n\n모형 fit2의 AICc가 더 작게 계산되었고, 따라서 최종 예측 모형으로 선택하자.\n\nfit_reg <- fit2\n\n2. ARIMA 모형의 적합\n차분 및 계절 차분이 필요한지 여부를 확인해 보자.\n\nggtsdisplay(train_g)\n\n\n\n\n뚜렷한 추세가 시계열 그래프에서 보이며, 표본 ACF 그래프에서 매우 큰 값의 \\(r_{1}\\) 과 천천히 감소하는 모습에서 1차 차분이 필요한 것을 알 수 있다. 그러나 계절 차분이 필요한지 여부는 명확하게 보이지 않는다. 단위근 검정 결과를 확인해 보자.\n\nndiffs(train_g)\n## [1] 1\nnsdiffs(train_g)\n## [1] 0\n\n1차 차분은 필요하지만, 계절 차분은 필요 없는 것로 나타났다. 이제 1차 차분을 실시한 자료를 대상으로 시계열 그래프와 ACF, PACF를 작성해 보자. 정상성이 만족된 것으로 보인다.\n\ntrain_g %>% \n  diff() %>% \n  ggtsdisplay()\n\n\n\n\n이제 잔차의 표본 ACF와 PACF를 이용해서 모형 식별을 시도해 보자. 비계절 요소는 1시차에서 6시차까지의 패턴으로 인식하게 되는데, ACF는 3시차까지 모두 유의하고, PACF는 1시차와 3시차가 유의한 것으로 나타났다. 이러한 경우에는 ACF를 감소, PACF는 감소 또는 3시차에서 절단으로 볼 수 있으며, 따라서 ARMA 모형이나 AR 모형이 가능할 것으로 보인다. 계절형 요소는 12, 24, 36시차에서 ACF와 PACF가 모두 매우 작은 값을 갖고 있기 때문에, 계절형 요소가 없는 것으로 볼 수도 있고, AR(1)12 또는 MA(1)12로 볼 수도 있는 상황이다.\n함수 auto.arima()를 사용해서 AICc가 가장 작은 모형을 찾아 보자.\n\nfit_arima <- auto.arima(train_g,\n                        stepwise = FALSE,\n                        approximation = FALSE)\n\n적합 결과는 비계절형 요소만 있는 ARIMA(2,1,1)이 선택된 것을 알 수 있다.\n\nfit_arima\n## Series: train_g \n## ARIMA(2,1,1) \n## \n## Coefficients:\n##          ar1     ar2      ma1\n##       0.5198  0.3008  -0.9703\n## s.e.  0.0498  0.0492   0.0132\n## \n## sigma^2 = 0.007576:  log likelihood = 417.27\n## AIC=-826.55   AICc=-826.45   BIC=-810.51\n\n모형 fit_arima에 대한 검진을 실시해 보자. 모든 가정이 만족되고 있음을 볼 수 있다.\n\ncheckresiduals(fit_arima)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(2,1,1)\n## Q* = 30.228, df = 21, p-value = 0.08751\n## \n## Model df: 3.   Total lags used: 24\n\n3. ETS 모형의 적합\n함수 ets()로 AICc가 최소인 모형을 선택해 보자.\n\nfit_ets <- ets(train_g)\n\n최적 모형은 ETS(A,N,N)이 선택되었다.\n\nfit_ets\n## ETS(A,N,N) \n## \n## Call:\n##  ets(y = train_g) \n## \n##   Smoothing parameters:\n##     alpha = 0.5868 \n## \n##   Initial states:\n##     l = 0.0782 \n## \n##   sigma:  0.0885\n## \n##      AIC     AICc      BIC \n## 478.0785 478.1379 490.1123\n\n모형 fit_ets에 대한 검진을 실시해 보자.\n\ncheckresiduals(fit_ets)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ETS(A,N,N)\n## Q* = 39.376, df = 22, p-value = 0.01277\n## \n## Model df: 2.   Total lags used: 24\n\n독립성 가정에 문제가 있는 것으로 나타났다. 독립성 가정을 만족시키지 못하는 모형의 경우에는 예측의 신빙성에 문제가 있을 수 있는데, 점 예측 (point forecast) 결과보다 예측 구간에 더 큰 문제가 있을 수 있다. 간혹 모든 가정을 만족시키는 모형을 찾지 못하는 경우도 있는데, 이런 경우에는 예측 결과를 적용할 때 조심할 필요가 있다.\n이제 세 가지 모형인 fit_reg, fit_arima, fit_ets에 의한 예측을 실시하고, 결과를 비교해 보자.\n\nnew_reg <- cbind(Time = time(test_g), \n                Fourier = fourier(test_g, K = k_min)) \nfc_reg <- forecast(fit_reg, xreg = new_reg)\nfc_arima <- forecast(fit_arima, h = length(test_g))\nfc_ets <- forecast(fit_ets, h = length(test_g))\n\n예측 오차를 비교해 보자.\n\naccuracy(fc_reg, test_g)\n##                         ME       RMSE        MAE       MPE     MAPE      MASE\n## Training set -0.0007984029 0.08320983 0.06402020 22.236428 80.56552 0.4300958\n## Test set     -0.0266870191 0.09047869 0.06864433 -9.691571 17.39724 0.4611613\n##                     ACF1 Theil's U\n## Training set 0.004973903        NA\n## Test set     0.300995351  1.015694\n\n\naccuracy(fc_arima, test_g)\n##                       ME       RMSE        MAE       MPE     MAPE      MASE\n## Training set 0.006369769 0.08661271 0.06601014 24.330149 79.34066 0.4434645\n## Test set     0.004650257 0.08557693 0.07319499 -2.829173 17.33066 0.4917332\n##                     ACF1 Theil's U\n## Training set 0.003457635        NA\n## Test set     0.335253668 0.9396727\n\n\naccuracy(fc_ets, test_g)\n##                        ME       RMSE        MAE       MPE     MAPE      MASE\n## Training set  0.001901676 0.08829198 0.06862716  20.00303 84.32056 0.4610460\n## Test set     -0.062218811 0.10436651 0.07564587 -17.55797 19.80559 0.5081986\n##                     ACF1 Theil's U\n## Training set -0.01131321        NA\n## Test set      0.26877094  1.191604\n\nTest data에 대한 예측 결과를 비교해 보면, 전체적으로 큰 차이는 없는 것으로 보인다. MASE로는 ARMA 오차 회귀모형이 ARIMA 모형 보다 조금 작은 값을 보이고 있으나, RMSE와 MAPE로는 ARIMA 모형이 조금 작은 값을 보이고 있다. 예측 결과를 test data와 함께 표시한 그래프는 Figure 4 에서 볼 수 있다. 예측 구간의 폭을 비교할 수 있도록 세 그래프의 Y축 구간은 동일하게 설정하였다.\n\ny_lim <- c(-.06, 1.06)\np1 <- autoplot(fc_reg, include = 12) + \n  autolayer(test_g, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2])\np2 <- autoplot(fc_arima, include = 12) + \n  autolayer(test_g, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2])\np3 <- autoplot(fc_ets, include=12) + \n  autolayer(test_g, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2])\n\np1 / p2 / p3\n\n\n\n\nFigure 4: 자료 global.txt에 대한 세 모형의 예측 결과\n\n\n\n\n\n예제: 1949년부터 1960년 월별 국제선 탑승자 수 자료 (AirPassengers)\n\nAirPassengers는 1949년 1월부터 1960년 12월까지 월별 국제선 탑승자 수 자료이다. ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형에 의한 예측 모형을 적합시키고, 예측 결과를 비교해 보자. 예측 결과의 평가를 위해 마지막 2년 자료는 test data로 남겨두자.\n\ntrain_AP <- window(AirPassengers, end = c(1958, 12))\ntest_AP <- window(AirPassengers, start = c(1959, 1))\n\n전체 기간에 대한 시계열 그래프를 Figure 5 에 작성해 보자. Test data는 빨간 색으로 구분하였다.\n\nautoplot(train_AP) + \n  autolayer(test_AP, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL)\n\n\n\n\nFigure 5: 자료 AirPassengers의 시계열 그래프\n\n\n\n\n증가 추세가 있고, 명확한 계절 성분이 있는 자료이다. 또한 계절 변동 폭이 추세가 증가함에 따라 점점 커지고 있음도 알 수 있다. 따라서 분산 안정화가 필요한 자료이다. 분산 안정화를 위해 Box-Cox 변환 모수를 추정해 보자.\n\n(lam <- BoxCox.lambda(train_AP))\n## [1] -0.3096628\n\n변환 모수가 \\(\\lambda=\\) -0.3096628 로 추정되었다. 추정된 변환 모수에 의한 변환 결과와 로그 변환에 의한 결과를 비교해 보자. Figure 6 에서 볼 수 있듯이 두 변환 결과는 크게 차이가 나지 않는 것으로 보인다. 이런 경우에는 변환 결과에 대한 해석이 가능한 로그 변환을 선택하는 것이 일반적이라고 하겠다.\n\np1 <- BoxCox(train_AP, lambda = lam) %>% \n  autoplot() + \n  labs(title = paste(\"Box-Cox\", \"lambda = \", signif(lam, 3)), x = NULL)\np2 <- train_AP %>% \n  log() %>% \n  autoplot() + labs(title = \"Log\", x = NULL)\np1+p2\n\n\n\n\nFigure 6: 분산 안정화 변환\n\n\n\n\n1. ETS 모형 적합\nETS 모형은 계절 성분을 승법 형태로 설명할 수 있는 모형이기 때문에, 계절 성분의 진폭 안정화가 반드시 필요한 모형은 아니다. 또한 모수에 대한 해석보다 예측이 주된 용도이기 때문에, 분산 안정화 변환 결과에 대한 해석이 그렇게 중요한 요소가 되지 않는다. 따라서 원자료에 대한 ETS 모형과 Box-Cox 변환 자료에 대한 ETS 모형, 그리고 로그 변환 자료에 대한 ETS 모형을 각각 적합하고 예측 결과를 비교해 보자.\n\nets_1 <- ets(train_AP, lambda = lam) \nets_fc1 <- forecast(ets_1, h = length(test_AP)) \n\nets_2 <- ets(train_AP, lambda = 0)\nets_fc2 <- forecast(ets_2, h = length(test_AP)) \n\nets_3 <- ets(train_AP)\nets_fc3 <- forecast(ets_3, h = length(test_AP)) \n\nFigure 7 는 세 가지 ETS 모형의 예측 결과를 test data와 함께 나타낸 그래프이다. Box-Cox 변환 자료에 대한 ETS 모형의 예측 결과가 test data와 가장 근접한 것으로 보인다. Test data를 이용해서 모형을 선택하는 것이 바람직한 방식은 아니지만, 모형 비교를 위한 다른 마땅한 방법이 없는 상황을 고려하였다.\n\np1 <- autoplot(ets_fc1, include = 0) +\n  autolayer(test_AP, color = \"red\", size = .8) + labs(y = NULL, subtitle = \"ets_fc1\")\np2 <- autoplot(ets_fc2, include = 0) +\n  autolayer(test_AP, color = \"red\", size = .8) + labs(y = NULL, subtitle = \"ets_fc2\")\np3 <- autoplot(ets_fc3, include = 0) +\n  autolayer(test_AP, color = \"red\", size = .8) + labs(y = NULL, subtitle = \"ets_fc3\")\np1/p2/p3\n\n\n\n\nFigure 7: AirPassengers 자료에 대한 ETS 모형의 예측 결과 비교\n\n\n\n\nBox-Cox 변환 자료에 대한 ETS 모형을 최적 ETS 모형으로 선택하고, 모형 진단을 실시해 보자. 독립성 가정을 위반하는 것으로 나타났다.\n\nfit_ets <- ets(train_AP, lambda = lam)\n\n\ncheckresiduals(fit_ets)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ETS(A,A,A)\n## Q* = 39.722, df = 8, p-value = 3.61e-06\n## \n## Model df: 16.   Total lags used: 24\n\n2. ARMA 오차 회귀모형 적합\n회귀모형은 분산 안정화가 필수적인 모형이며, 변환 결과에 대한 해석도 필요한 모형이다. 따라서 로그 변환된 자료를 대상으로 모형 적합을 진행해 보자.\n계절 성분을 dummy 변수로 나타내는 모형을 적합해 보자.\n\nTime <- time(train_AP)\nMonth <- seasonaldummy(train_AP)\nfit_r1 <- auto.arima(train_AP, xreg = cbind(Time, Month),\n                     lambda = 0) \n\nstepwise = FALSE를 포함시키면 실행 시간이 지나치게 오래 걸리기 때문에 제외했다. 적합 결과를 살펴보자.\n\nfit_r1\n## Series: train_AP \n## Regression with ARIMA(1,0,0)(0,0,1)[12] errors \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##          ar1    sma1  intercept   Time  Month.Jan  Month.Feb  Month.Mar\n##       0.7766  0.1651  -236.9229  0.124     0.0127     0.0017     0.1369\n## s.e.  0.0674  0.0994     9.7959  0.005     0.0133     0.0173     0.0198\n##       Month.Apr  Month.May  Month.Jun  Month.Jul  Month.Aug  Month.Sep\n##          0.0956     0.0872     0.2124     0.3096     0.3018     0.1660\n## s.e.     0.0212     0.0220     0.0223     0.0219     0.0211     0.0195\n##       Month.Oct  Month.Nov\n##          0.0254    -0.1166\n## s.e.     0.0170     0.0128\n## \n## sigma^2 = 0.001265:  log likelihood = 237.46\n## AIC=-442.92   AICc=-437.64   BIC=-398.32\n\n잔차에 계절형과 비계절형 요소가 모두 남아 있는 것을 알 수 있다. 모형 검진을 실시해 보자. 큰 문제는 없는 것으로 보인다.\n\ncheckresiduals(fit_r1)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from Regression with ARIMA(1,0,0)(0,0,1)[12] errors\n## Q* = 21.798, df = 22, p-value = 0.472\n## \n## Model df: 2.   Total lags used: 24\n\n이번에는 Fourier series 변수를 사용한 회귀모형을 적합해 보자. 먼저 최적 차수를 확인하자.\n\nTime <- time(train_AP)\nres <- vector(\"numeric\", 6)\nfor(i in seq(res)){\n  xreg <- cbind(Time, fourier(train_AP, K = i))\n  fit <- auto.arima(train_AP, xreg = xreg, \n                    lambda = 0)\n  res[i] <- fit$aicc\n}\n\n\n(min_k <- which.min(res))\n## [1] 5\n\n\\(K=5\\) 가 최적 차수로 확인되었다. 최적 차수에 의한 Fourier series 변수를 사용한 회귀모형을 적합하고 결과를 확인해 보자.\n\nTime <- time(train_AP)\nFourier <- fourier(train_AP, K = min_k)\nfit_r2 <- auto.arima(train_AP, xreg = cbind(Time, Fourier),\n                     lambda = 0)\n\n\nsummary(fit_r2)\n## Series: train_AP \n## Regression with ARIMA(2,0,0)(1,0,0)[12] errors \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##          ar1     ar2    sar1  intercept    Time  Fourier.S1-12  Fourier.C1-12\n##       0.6384  0.1782  0.2060  -233.8237  0.1224        -0.0464        -0.1379\n## s.e.  0.0910  0.0964  0.1057    12.3191  0.0063         0.0090         0.0090\n##       Fourier.S2-12  Fourier.C2-12  Fourier.S3-12  Fourier.C3-12  Fourier.S4-12\n##              0.0773        -0.0259        -0.0107         0.0264         0.0245\n## s.e.         0.0051         0.0051         0.0039         0.0039         0.0036\n##       Fourier.C4-12  Fourier.S5-12  Fourier.C5-12\n##              0.0261         0.0206         0.0060\n## s.e.         0.0036         0.0036         0.0036\n## \n## sigma^2 = 0.001256:  log likelihood = 237.75\n## AIC=-443.49   AICc=-438.21   BIC=-398.89\n## \n## Training set error measures:\n##                     ME     RMSE      MAE         MPE     MAPE      MASE\n## Training set 0.1302685 8.156184 6.052862 -0.05051831 2.597827 0.2118306\n##                    ACF1\n## Training set 0.09399082\n\n잔차에 계절형과 비계절형 요소가 모두 남아 있는 것을 알 수 있다. 모형 검진을 실시해 보자. 큰 문제가 없는 것으로 보인다.\n\ncheckresiduals(fit_r2)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from Regression with ARIMA(2,0,0)(1,0,0)[12] errors\n## Q* = 17.88, df = 21, p-value = 0.6566\n## \n## Model df: 3.   Total lags used: 24\n\n이제 두 모형 중 한 모형을 최적 모형으로 선택해야 한다. 사실 두 모형은 거의 동일한 모형이다. 두 번째 모형이 11개의 Fourier series 변수 중 10개 사용한 모형이기 때문인데, 만일 \\(K=6\\) 이 선택되어 11개의 Fourier series 변수를 모두 사용한다면 dummy 변수를 사용한 모형과 사실상 동일한 모형이 된다. 두 모형의 AICc를 근거로 한 모형을 선택해 보자.\n\nc(fit_r1$aicc, fit_r2$aicc)\n## [1] -437.6420 -438.2119\n\n두 번째 모형의 AICc가 조금 더 작은 값으로 계산되었다. 따라서 Fourier series 변수를 사용한 모형을 최적 회귀모형으로 선택하자.\n\nfit_reg <- fit_r2\n\n3. ARIMA 모형 적합\nARIMA 모형도 회귀모형의 경우처럼 분산 안정화가 필수적인 모형이며, 변환 결과에 대한 해석도 필요한 모형이다. 따라서 로그 변환된 자료를 대상으로 모형 적합을 진행해 보자. 우선 로그 변환된 자료에 대한 시계열 그래프와 표본 ACF를 작성해 보자.\n\ntrain_AP %>% \n  log() %>% \n  ggtsdisplay()\n\n\n\n\n뚜렷한 추세와 계절 성분이 있는 자료임을 알 수 있다. 계절 차분을 실시하고, 그 결과를 확인해 보자.\n\ntrain_AP %>% \n  log() %>% \n  diff(lag = 12) %>% \n  ggtsdisplay()\n\n\n\n\n시계열 그래프와 ACF로는 1차 차분이 더 필요한지 여부를 확실하게 결정하기 어려워 보인다. 이런 상황에서는 계절 차분만 실시한 자료에 대한 ARIMA 모형 적합도 시도해 볼 필요가 있는 것으로 보인다.\n계절 차분된 자료에 1차 차분을 추가로 실시하고, 그 결과를 확인해 보자. 비정상성 요소가 완전히 제거된 것을 볼 수 있다.\n\ntrain_AP %>% \n  log() %>% \n  diff(lag = 12) %>% \n  diff() %>% \n  ggtsdisplay()\n\n\n\n\n단위근 검정 결과를 확인해 보자. 계절 차분과 1차 차분이 모두 필요한 것으로 나타난다.\n\ntrain_AP %>% \n  log() %>% \n  ndiffs()\n## [1] 1\n\n\ntrain_AP %>% \n  log() %>% \n  nsdiffs()\n## [1] 1\n\n단위근 검정 결과에도 불구하고 1차 차분이 명확하게 필요한 상황으로 판단하기 어렵다고 보고, 계절 차분만 실시한 경우와 계절 차분과 1차 차분을 모두 실시한 경우에 대해서 각각 ARIMA 모형을 적합시켜 보자. 먼저 계절 차분과 1차 차분을 모두 실시한 자료를 대상으로 ARIMA 모형을 적합해 보자.\n\nfit_a1 <- auto.arima(train_AP, lambda = 0, \n                    stepwise = FALSE)\n\n적합 결과는 다음과 같다.\n\nsummary(fit_a1)\n## Series: train_AP \n## ARIMA(0,1,1)(0,1,1)[12] \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##           ma1     sma1\n##       -0.3424  -0.5405\n## s.e.   0.1009   0.0877\n## \n## sigma^2 = 0.001432:  log likelihood = 197.51\n## AIC=-389.02   AICc=-388.78   BIC=-381\n## \n## Training set error measures:\n##                      ME     RMSE     MAE         MPE     MAPE      MASE\n## Training set -0.2372088 8.835339 6.51704 -0.07508532 2.637955 0.2280753\n##                    ACF1\n## Training set 0.04249699\n\n모형 검진 결과에서는 어떤 문제도 발견되지 않았다.\n\ncheckresiduals(fit_a1)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(0,1,1)(0,1,1)[12]\n## Q* = 20.34, df = 22, p-value = 0.5618\n## \n## Model df: 2.   Total lags used: 24\n\n이번에는 계절 차분만을 실시한 자료를 대상으로 ARIMA 모형을 적합해 보자.\n\nfit_a2 <- auto.arima(train_AP, d = 0, lambda = 0, \n                     stepwise = FALSE)\n\n적합 결과는 다음과 같다.\n\nfit_a2\n## Series: train_AP \n## ARIMA(2,0,0)(0,1,1)[12] with drift \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##          ar1     ar2     sma1   drift\n##       0.6159  0.2356  -0.5562  0.0101\n## s.e.  0.0944  0.0965   0.0898  0.0010\n## \n## sigma^2 = 0.001382:  log likelihood = 201.77\n## AIC=-393.53   AICc=-392.95   BIC=-380.12\n\n모형 검진을 실시해 보면, 모든 가정이 만족되는 것으로 보인다.\n\ncheckresiduals(fit_a2)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(2,0,0)(0,1,1)[12] with drift\n## Q* = 20.83, df = 21, p-value = 0.4694\n## \n## Model df: 3.   Total lags used: 24\n\n이제 두 모형 중 하나의 모형을 선택해 보자. 두 모형은 차분을 실시한 횟수가 각기 다른 자료를 사용한 것이기 때문에 AICc 등의 비교는 의미가 없다. 따라서 Test data를 대상으로 더 근접한 예측 결과를 산출하는 모형을 선택하기로 하자.\n\nfc_a1 <- forecast(fit_a1, h = length(test_AP))\nfc_a2 <- forecast(fit_a2, h = length(test_AP))\n\n\np1 <- autoplot(fc_a1, include = 0) +\n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(y = NULL, subtitle = \"fc_a1\")\np2 <- autoplot(fc_a2, include = 0) +\n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(y = NULL, subtitle = \"fc_a2\")\n\np1 + p2\n\n\n\n\nFigure 8: ARIMA 모형의 예측 결과\n\n\n\n\n두 번째 모형인 ARIMA(2,0,0)(0,1,1)12의 예측 결과가 test data에 더 근접한 것으로 보인다.\n\nfit_arima <- fit_a2\n\n이제는 ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형의 예측 결과를 비교해 보자.\n\nnew_t <- cbind(Time = time(test_AP), \n               Fourier = fourier(test_AP, K = min_k))\nfc_reg <- forecast(fit_r2, xreg = new_t)\n\nfc_ets <- forecast(fit_ets, h = length(test_AP))\nfc_arima <- forecast(fit_arima, h = length(test_AP))\n\n\naccuracy(fc_reg, test_AP)\n##                       ME      RMSE       MAE         MPE     MAPE      MASE\n## Training set   0.1302685  8.156184  6.052862 -0.05051831 2.597827 0.2118306\n## Test set     -10.8769172 22.234136 15.437231 -2.58040950 3.488570 0.5402531\n##                    ACF1 Theil's U\n## Training set 0.09399082        NA\n## Test set     0.39683635 0.4785114\n\n\naccuracy(fc_ets, test_AP)\n##                      ME      RMSE       MAE        MPE     MAPE      MASE\n## Training set  0.1851383  9.164883  6.647767  0.1873228 2.862835 0.2326503\n## Test set     -6.3756691 19.752432 14.199026 -1.4099460 3.219620 0.4969199\n##                   ACF1 Theil's U\n## Training set 0.3728555        NA\n## Test set     0.1682524 0.4355005\n\n\naccuracy(fc_arima, test_AP)\n##                       ME      RMSE       MAE         MPE     MAPE      MASE\n## Training set  0.05350955  8.616827  6.212913  0.05341167 2.560180 0.2174318\n## Test set     -3.33508240 14.125641 10.626775 -0.66418334 2.356519 0.3719027\n##                    ACF1 Theil's U\n## Training set 0.04419876        NA\n## Test set     0.14856147 0.2945598\n\nARIMA 모형의 예측 오차가 가장 작은 것으로 나타났다. 예측 결과를 그래프로 비교해 보자.\n\np1 <- autoplot(fc_reg, include = 0) + \n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(x=NULL, y=NULL) \np2 <- autoplot(fc_arima, include = 0) + \n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(x=NULL, y=NULL) \np3 <- autoplot(fc_ets, include = 0) + \n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(x=NULL, y=NULL)\n\np1 + p2 + p3\n\n\n\n\nFigure 9: AirPassengers 자료에 대한 예측 결과 비교\n\n\n\n\n\n\n\n\n예제 : 2014년 호주 빅토리아주의 일일 전기 수요량 자료 (fpp2::elecdaily)\n\nelecdaily는 \\(365 \\times 3\\) 의 ts 객체 행렬이다. 처음 3개 행을 출력해 보자.\n\nelecdaily[1:3,]\n##        Demand WorkDay Temperature\n## [1,] 174.8963       0        26.0\n## [2,] 188.5909       1        23.0\n## [3,] 188.9169       1        22.2\n\n첫 번째 열인 Demand는 일일 전기 수요량이고, 두 번째 열인 WorkDay는 휴일이면 0, 근무일이면 1을 값으로 갖고 있으며, 세 번째 열인 Temperature는 당일 최고 기온이다. 세 변수의 시계열 그래프를 Figure 10 에 작성해 보자.\n\nautoplot(elecdaily, facets = TRUE)\n\n\n\n\nFigure 10: 자료 elecdaily를 구성하고 있는 세 변수의 시계열 그래프\n\n\n\n\n시계열자료 행렬 elecdaily의 각 열을 개별 시계열자료로 분리해 보자.\n\nDemand <- elecdaily[,1]\nWork <- elecdaily[,2]\nTemp <- elecdaily[,3]\n\n세 시계열자료는 동일한 기간과 주기를 갖고 있는데, 변수 Demand로 확인해 보자.\n\nstart(Demand); end(Demand); frequency(Demand)\n## [1] 1 4\n## [1] 53  4\n## [1] 7\n\n시작 시점은 2014년 첫 번째 주 네 번째 날이고, 종료 시점은 2014년 53번째 주 네 번째 날이다. 일일 자료이므로 주기는 7로 설정되어 있다. 주 중 네 번째 날의 요일은 다음과 같이 패키지 lubridate의 함수 wday()로 할 수 있다.\n\nlibrary(lubridate)\nwday(ymd(\"2014-1-1\"), label = TRUE)\n## [1] 수\n## Levels: 일 < 월 < 화 < 수 < 목 < 금 < 토\n\n반응변수인 Demand와 셜명변수인 Temp의 정상성 만족 여부를 확인해 보자. 두 변수 모두 차분이 필요한 것으로 보인다.\n\nDemand %>% \n  ggtsdisplay(main = \"Demand\")\n\n\n\n\n\nTemp %>% \n  ggtsdisplay(main = \"Temperature\")\n\n\n\n\n단위근 검정 결과도 확인해 보자.\n\nndiffs(Demand)\n## [1] 1\nndiffs(Temp)\n## [1] 1\n\n이제 두 변수의 관계를 산점도를 이용해서 살펴보자. Figure 11 에서 두 변수 사이에 2차 함수의 관계가 있음을 볼 수 있다. 회귀모형에 변수 Temp의 제곱항도 포함시켜야 할 것으로 보인다.\n\ntibble(Demand, Temp) %>% \n  ggplot(aes(x = as.numeric(Temp), y = as.numeric(Demand))) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  labs(x = \"Temperature\", y = \"Demand\")\n\n\n\n\nFigure 11: Demand와 Temperature의 산점도\n\n\n\n\nDynamic 회귀모형을 적합시켜보자. 함수 auto.arima()에 설명변수 Temp와 Temp^2, Work를 행렬 형태로 xreg에 지정해 보자.\n\nxreg <- cbind(Temp, Temp2 = Temp^2, Work)\nfit <- auto.arima(Demand, xreg = xreg, stepwise = FALSE)\n\n적합 결과를 확인해 보자.\n\nsummary(fit)\n## Series: Demand \n## Regression with ARIMA(2,1,1)(2,0,0)[7] errors \n## \n## Coefficients:\n##          ar1      ar2      ma1    sar1    sar2     Temp   Temp2     Work\n##       0.8247  -0.0225  -0.9806  0.2216  0.4008  -7.8847  0.1849  30.3192\n## s.e.  0.0700   0.0666   0.0203  0.0552  0.0566   0.4457  0.0088   1.3390\n## \n## sigma^2 = 44.7:  log likelihood = -1205.77\n## AIC=2429.54   AICc=2430.04   BIC=2464.61\n## \n## Training set error measures:\n##                      ME     RMSE      MAE         MPE     MAPE      MASE\n## Training set 0.01290229 6.602876 4.767955 -0.09519977 2.159123 0.3273729\n##                      ACF1\n## Training set -0.000989946\n\n적합된 회귀모형에 절편이 없는 것을 볼 수 있는데, 이것은 차분을 실시한 자료를 대상으로 회귀모형을 적합시켰기 때문이다.\n적합된 모형의 진단을 실시해 보자. 독립성 가정에는 문제가 있는 것으로 보인다.\n\ncheckresiduals(fit)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from Regression with ARIMA(2,1,1)(2,0,0)[7] errors\n## Q* = 36.219, df = 9, p-value = 3.625e-05\n## \n## Model df: 5.   Total lags used: 14\n\n이제 적합된 Dynamic 회귀모형을 이용해서 2015년 1월 1이부터 1월 10일까지의 전력 수요량을 예측해 보자. 이 때 문제가 되는 것은 해당 기간에 대한 변수 Temp의 값도 미리 알 수 없다는 것이다. 이 문제는 변수 Temp의 미래 값을 다른 방법으로 예측해서 사용하거나, 특정한 값으로 가정하고 Demand의 미래 값을 예측해야 한다.\n여기에서는 2014년 1월 1일부터 1월 10일까지의 Temp 값을 그대로 사용해서 예측을 실시해 보자. 변수 Work의 값은 2015년 1월 1일 목요일부터 1월 10일 토요일까지 휴일과 근무일을 구분해서 입력할 수 있다.\n\nold_T <- Temp[1:10]\nnew_x <- cbind(Temp = old_T, Temp2 = old_T^2,\n               Work = c(0,1,0,0,1,1,1,1,1,0))\nfc <- forecast(fit, xreg = new_x)\n\n예측 결과에 대한 그래프를 작성해 보자.\n\nautoplot(fc)\n\n\n\n\nFigure 12: Demand의 예측 결과\n\n\n\n\n\n예제: 미국 소득, 소비 등의 1970년 1분기부터 2016년 3분기까지 분기별 변화 비율 (fpp2::uschange)\n\nuschange는 \\(187 \\times 5\\) 의 ts 객체 행렬이다.\n\nuschange[1:3,]\n##      Consumption   Income Production  Savings Unemployment\n## [1,]   0.6159862 0.972261 -2.4527003 4.810312          0.9\n## [2,]   0.4603757 1.169085 -0.5515251 7.287992          0.5\n## [3,]   0.8767914 1.553271 -0.3587079 7.289013          0.5\n\n다섯 개 시계열자료는 동일한 시작 시점, 종료 시점과 주기를 갖고 있는데, 첫 번째 시계열자료를 이용해서 확인해 보자. 분기별 자료이므로 주기는 4이고, 시작 시점은 1970년 1분기이며, 종료 시점은 2016년 3분기이다.\n\nstart(uschange[,1])\n## [1] 1970    1\nend(uschange[,1])\n## [1] 2016    3\nfrequency(uschange[,1])\n## [1] 4\n\n첫 번째 시계열자료인 Consumption에 대한 예측 모형을 적합해 보자. ARIMA 모형과 ETS 모형에 의한 예측 모형, ARMA 오차 회귀모형, 그리고 행렬 uschange의 다른 시계열자료를 설명변수로 사용하는 dynamic 회귀모형에 의한 예측 모형을 적합해 보자.\nuschange를 구성하고 있는 다섯 변수의 시계열 그래프를 Figure 13 에 작성해 보자. 뚜렷한 추세나 계절 성분이 있는 시계열자료는 없는 것으로 보인다.\n\nautoplot(uschange, facets=TRUE) + \n  labs(y = NULL, x = NULL)\n\n\n\n\nFigure 13: uschange의 다섯 시계열자료의 그래프\n\n\n\n\n다섯 시계열자료의 ACF는 함수 ggAcf()에 개별 시계열자료를 각각 입력해서 작성할 수도 있지만, 조금은 번거로운 작업이 된다. 대신 함수 ggAcf()에 행렬 uschange를 그대로 입력하면 두 변수씩의 모든 조합에 대한 상관 행렬이 작성되는데, 그 중 대각 패널에 각 변수의 ACF가 작성된다.\n\nggAcf(uschange)\n\n\n\n\nFigure 14: uschange의 다섯 시계열자료의 표본 ACF\n\n\n\n\nFigure 13 과 Figure 14 을 근거로 다섯 시계열자료는 모두 정상성을 만족하고 있는 것으로 보인다.\nDynamic 회귀모형에서 설명변수로 사용할 수 있는 시계열자료는 Income, Production, Savings, 그리고 Unemployment이다. 함수 GGally::ggpairs()로 다섯 변수의 산점도 행렬을 작성해 보자.\n\nGGally::ggpairs(as_tibble(uschange) %>% \n                  relocate(Consumption, .after=last_col()),\n                lower=list(continuous=\"smooth_loess\"))\n\n\n\n\nFigure 15: uschange의 다섯 시계열자료의 산점도 행렬\n\n\n\n\n변수 (Income, Savings)과 (Production, Uneployment) 사이에 높은 관련성이 있는 것으로 보여서, 변수 Income과 Production만을 설명변수로 포함시키고자 한다. 엄격하고 타당한 변수 선택 방식은 아니지만 가능하면 간단한 모형을 구성하고자 한다.\n이제 자료를 분리하고 예측 모형을 적합시켜보자.\n\nuschange_te <- tail(uschange, n = 8)\nuschange_tr <- head(uschange, n = nrow(uschange)-8)\n\nARIMA 모형을 적합하고, 결과를 확인해 보자.\n\nfit_arima <- auto.arima(uschange_tr[,1], \n                   stepwise = FALSE, approximation = FALSE)\n\n\nfit_arima\n## Series: uschange_tr[, 1] \n## ARIMA(3,0,0)(2,0,0)[4] with non-zero mean \n## \n## Coefficients:\n##          ar1     ar2     ar3     sar1     sar2    mean\n##       0.2267  0.1771  0.2218  -0.0351  -0.1792  0.7482\n## s.e.  0.0739  0.0738  0.0726   0.0774   0.0745  0.0951\n## \n## sigma^2 = 0.3544:  log likelihood = -158.39\n## AIC=330.78   AICc=331.44   BIC=353.09\n\nETS 모형을 적합하고, 결과를 확인해 보자.\n\nfit_ets <- ets(uschange_tr[,1])\n\n\nfit_ets\n## ETS(A,N,N) \n## \n## Call:\n##  ets(y = uschange_tr[, 1]) \n## \n##   Smoothing parameters:\n##     alpha = 0.3315 \n## \n##   Initial states:\n##     l = 0.6877 \n## \n##   sigma:  0.633\n## \n##      AIC     AICc      BIC \n## 768.8004 768.9376 778.3626\n\n관측 시점만을 설명변수로 사용하는 ARMA 오차 회귀모형을 적합해 보자. 추세 변수는 함수 time()으로 생성하고, 계절 성분은 dummy 변수로 표현해 보자.\n\nTime <-  time(uschange_tr[,1])\nQtr <-  seasonaldummy(uschange_tr[,1])\n\n\nfit_reg <- auto.arima(uschange_tr[,1],\n                      xreg = cbind(Time, Qtr),\n                      stepwise = FALSE, approximation = FALSE)\n\n\nfit_reg\n## Series: uschange_tr[, 1] \n## Regression with ARIMA(3,0,0)(0,0,2)[4] errors \n## \n## Coefficients:\n##          ar1     ar2     ar3     sma1     sma2   Time  Qtr.Q1  Qtr.Q2  Qtr.Q3\n##       0.2564  0.1608  0.2482  -0.1066  -0.1942  3e-04  0.0554  0.0122   0.172\n## s.e.  0.0742  0.0737  0.0729   0.0773   0.0707  1e-04  0.0700  0.0748   0.070\n## \n## sigma^2 = 0.349:  log likelihood = -155.52\n## AIC=331.03   AICc=332.34   BIC=362.91\n\nDynamic 회귀모형도 적합해 보자.\n\nfit_dyn <- auto.arima(uschange_tr[,1], d = 0,     \n                   xreg = uschange_tr[,c(2,3)], \n                   stepwise = FALSE, approximation = FALSE)\n\n\nfit_dyn\n## Series: uschange_tr[, 1] \n## Regression with ARIMA(3,0,0) errors \n## \n## Coefficients:\n##          ar1     ar2     ar3  intercept  Income  Production\n##       0.0060  0.1960  0.1890     0.5288  0.1741      0.1758\n## s.e.  0.0813  0.0734  0.0735     0.0708  0.0457      0.0262\n## \n## sigma^2 = 0.2696:  log likelihood = -133.71\n## AIC=281.41   AICc=282.07   BIC=303.72\n\n적합시킨 네 모형에 대한 모형 검진도 실시해 보자. 다른 가정 사항에는 모든 모형에 문제가 없는 것으로 나타났지만, Ljung-Box 검정 결과에서 ETS 모형이 독립성 가정을 위반하고 있는 것으로 보인다.\n\ncheckresiduals(fit_arima)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(3,0,0)(2,0,0)[4] with non-zero mean\n## Q* = 0.6507, df = 3, p-value = 0.8847\n## \n## Model df: 5.   Total lags used: 8\n\n\ncheckresiduals(fit_ets)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from ETS(A,N,N)\n## Q* = 15.865, df = 6, p-value = 0.0145\n## \n## Model df: 2.   Total lags used: 8\n\n\ncheckresiduals(fit_reg)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from Regression with ARIMA(3,0,0)(0,0,2)[4] errors\n## Q* = 0.32544, df = 3, p-value = 0.9552\n## \n## Model df: 5.   Total lags used: 8\n\n\ncheckresiduals(fit_dyn)\n\n\n\n## \n##  Ljung-Box test\n## \n## data:  Residuals from Regression with ARIMA(3,0,0) errors\n## Q* = 1.5616, df = 5, p-value = 0.9059\n## \n## Model df: 3.   Total lags used: 8\n\n이제 test data에 대한 예측을 실시해 보자. 모형 fit_dyn의 경우에는 test data 시점에서 설명변수의 관측 문제가 있지만, 다른 모형과의 비교를 위해서 설명변수의 값이 알려져 있다고 가정하겠다. 이 가정으로 모형 fit_dyn의 예측은 결과가 더 좋게 나올 수 있다.\n\nfc_arima <- forecast(fit_arima, h = 8)\nfc_ets <- forecast(fit_ets, h = 8)\nfc_dyn <- forecast(fit_dyn, \n                   xreg = uschange_te[,c(2,3)])\n\n\nTime <-  time(uschange_te[,1])\nQtr <-  seasonaldummy(uschange_te[,1])\nfc_reg <- forecast(fit_reg, \n                   xreg = cbind(Time, Qtr))\n\n예측 결과를 test data와 비교해 보자. 모형 fit_dyn의 예측 오류가 가장 작은 것으로 나타났다. ETS 모형도 예측 오류가 다른 모형보다 비교적 작은 것으로 나타났다.\n\naccuracy(fc_arima, uschange_te[,1])\n##                         ME      RMSE       MAE       MPE      MAPE     MASE\n## Training set  0.0002559072 0.5852267 0.4396851  65.90037 189.15841 0.670526\n## Test set     -0.0475341277 0.2500710 0.2185770 -17.75795  33.64265 0.333333\n##                     ACF1 Theil's U\n## Training set  0.00952753        NA\n## Test set     -0.21075717 0.6797118\n\n\naccuracy(fc_ets, uschange_te[,1])\n##                         ME      RMSE       MAE       MPE      MAPE      MASE\n## Training set  0.0008292707 0.6294144 0.4622752  15.94476 163.66594 0.7049764\n## Test set     -0.0071405456 0.2275948 0.1819332 -11.07730  27.12135 0.2774507\n##                      ACF1 Theil's U\n## Training set -0.004088847        NA\n## Test set     -0.208694082 0.5901059\n\n\naccuracy(fc_reg, uschange_te[,1])\n##                         ME      RMSE       MAE       MPE      MAPE      MASE\n## Training set  0.0008586772 0.5757214 0.4336545  62.73093 184.11947 0.6613293\n## Test set     -0.0460208936 0.2877620 0.2542229 -18.22233  37.33168 0.3876936\n##                      ACF1 Theil's U\n## Training set  0.003604112        NA\n## Test set     -0.360236167 0.7215638\n\n\naccuracy(fc_dyn, uschange_te[,1])\n##                         ME      RMSE       MAE       MPE     MAPE      MASE\n## Training set -0.0006526438 0.5104141 0.3844923 43.024517 189.5903 0.5863563\n## Test set      0.1004867937 0.2061923 0.1498566  8.058113  18.8564 0.2285334\n##                      ACF1 Theil's U\n## Training set  0.002548898        NA\n## Test set     -0.413909940 0.6493148\n\n예측 결과를 그래프로 나타내서 비교해 보자. ETS 모형의 경우 비교적 작은 예측 오류가 나왔지만 모든 시점에서 동일한 예측 결과을 보이는 모형이 선택되었고, 예측 구간의 폭이 가장 넓다는 점을 고려한다면, 바람직한 예측 모형은 아니라고 하겠다.\n\ny_lim <- c(-1, 2.5)\np1 <- autoplot(fc_arima, include = 8) + \n  autolayer(uschange_te[,1], color = \"red\", size = .8) + \n  ylab(NULL) + ylim(y_lim[1], y_lim[2])\np2 <- autoplot(fc_ets, include = 8) + \n  autolayer(uschange_te[,1], color = \"red\", size = .8) + \n  ylab(NULL) + ylim(y_lim[1], y_lim[2])\np3 <- autoplot(fc_reg, include = 8) + \n  autolayer(uschange_te[,1], color = \"red\", size = .8) + \n  ylab(NULL) + ylim(y_lim[1], y_lim[2])\np4 <- autoplot(fc_dyn, include = 8) + \n  autolayer(uschange_te[,1], color = \"red\", size = .8) + \n  ylab(NULL) + ylim(y_lim[1], y_lim[2])\n\n(p1 + p2) / (p3 + p4)\n\n\n\n\nFigure 16: uschange의 Consumption에 대한 예측 결과 비교"
  }
]