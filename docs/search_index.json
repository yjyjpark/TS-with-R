[["index.html", "R로 알아가는 시계열분석 머리말", " R로 알아가는 시계열분석 박동련 2022-11-11 머리말 시간의 흐름에 따라 관측되는 시계열자료는 경영\\(\\cdot\\)경제 분야 뿐 아니라 이제는 다른 많은 분야에서도 흔히 접할 수 있는 형태의 자료이다. 시계열자료의 가장 큰 특징은 자료들 사이에 강한 상관관계가 존재할 수 있다는 것인데, 이런 특징으로 인하여 선형회귀모형과 같이 자료의 독립성을 가정으로 하고 있는 모형으로는 시계열자료의 분석에 한계가 있다. 이 책에서는 시계열자료의 예측 모형으로 가장 많이 사용되는 ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형을 다루고 있으며, 특히 시계열분석에서 가장 많이 사용되는 R 패키지 중 하나인 패키지 forecast의 다양한 함수의 활용 방법을 소개하고 있다. 이 책은 교우사에서 출판한 “R로 알아가는 시계열분석”에서 사용된 실습 예제만을 추려서 독자들의 R 실습에 작은 도움이 되고자, 패키지 bookdown을 사용하여 Rstudio에서 작성되었다. 또한 이 책애서는 R의 기초적인 사용법 및 패키지 tidyverse에 대한 소개 없이 사용하고 있으며, R code에는 프롬프트(&gt; 또는 +)를 제거하였고, console 창에 출력되는 실행 결과물은 ##으로 시작되도록 하였다. 제공된 R code를 쉽게 복사하는 방법은 아래 그림과 같이 R code 블록에 마우스를 놓으면 우측 상단에 기호가 나타나는데, 그 기호를 클릭하는 것이다. 이 책을 작성할 때의 R 세션 정보는 다음과 같다. sessionInfo() ## R version 4.2.1 (2022-06-23 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Korean_Korea.utf8 ## [2] LC_CTYPE=Korean_Korea.utf8 ## [3] LC_MONETARY=Korean_Korea.utf8 ## [4] LC_NUMERIC=C ## [5] LC_TIME=Korean_Korea.utf8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets ## [6] methods base ## ## other attached packages: ## [1] expsmooth_2.3 fma_2.4 forecast_8.18 ## [4] fpp2_2.4 forcats_0.5.2 stringr_1.4.1 ## [7] dplyr_1.0.10 purrr_0.3.5 readr_2.1.3 ## [10] tidyr_1.2.1 tibble_3.1.8 ggplot2_3.3.6 ## [13] tidyverse_1.3.2 ## ## loaded via a namespace (and not attached): ## [1] tseries_0.10-52 httr_1.4.4 ## [3] sass_0.4.2 jsonlite_1.8.3 ## [5] modelr_0.1.9 bslib_0.4.0 ## [7] assertthat_0.2.1 TTR_0.24.3 ## [9] googlesheets4_1.0.1 cellranger_1.1.0 ## [11] yaml_2.3.6 pillar_1.8.1 ## [13] backports_1.4.1 lattice_0.20-45 ## [15] glue_1.6.2 quadprog_1.5-8 ## [17] digest_0.6.30 rvest_1.0.3 ## [19] colorspace_2.0-3 htmltools_0.5.3 ## [21] timeDate_4021.106 pkgconfig_2.0.3 ## [23] broom_1.0.1 haven_2.5.1 ## [25] bookdown_0.29 scales_1.2.1 ## [27] tzdb_0.3.0 googledrive_2.0.0 ## [29] generics_0.1.3 ellipsis_0.3.2 ## [31] cachem_1.0.6 withr_2.5.0 ## [33] urca_1.3-3 nnet_7.3-17 ## [35] quantmod_0.4.20 cli_3.4.1 ## [37] magrittr_2.0.3 crayon_1.5.2 ## [39] readxl_1.4.1 evaluate_0.17 ## [41] fs_1.5.2 fansi_1.0.3 ## [43] nlme_3.1-157 xts_0.12.2 ## [45] xml2_1.3.3 tools_4.2.1 ## [47] hms_1.1.2 gargle_1.2.1 ## [49] lifecycle_1.0.3 munsell_0.5.0 ## [51] reprex_2.0.2 compiler_4.2.1 ## [53] jquerylib_0.1.4 rlang_1.0.6 ## [55] grid_4.2.1 rstudioapi_0.14 ## [57] rmarkdown_2.17 gtable_0.3.1 ## [59] fracdiff_1.5-1 curl_4.3.3 ## [61] DBI_1.1.3 R6_2.5.1 ## [63] zoo_1.8-11 lubridate_1.8.0 ## [65] knitr_1.40 fastmap_1.1.0 ## [67] utf8_1.2.2 stringi_1.7.8 ## [69] parallel_4.2.1 Rcpp_1.0.9 ## [71] vctrs_0.5.0 dbplyr_2.2.1 ## [73] tidyselect_1.2.0 xfun_0.34 ## [75] lmtest_0.9-40 "],["chapter-ts-plot.html", "1 장 시계열 그래프 ts 객체 생성 시계열 그래프 작성 Seasonal 그래프 작성", " 1 장 시계열 그래프 library(fpp2) library(tidyverse) ts 객체 생성 예제: 백화점 매출액 자료 depart.txt는 어떤 백화점의 1984년 1월부터 1988년 12월까지의 월별 매출액이 입력되어 있다. 함수 scan()을 사용하여 자료를 R로 불러오자. 함수 scan()은 한 변수로 이루어진 텍스트 파일을 R로 불러올 때 사용할 수 있는 함수이다. depart &lt;- scan(&quot;https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/depart.txt&quot;) 이제 벡터 depart를 함수 ts()를 사용하여 ts 객체로 변환시켜보자. depart.ts &lt;- ts(depart, start = c(1984, 1), frequency = 12) depart.ts ## Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov ## 1984 423 458 607 564 536 536 804 540 488 627 672 ## 1985 514 518 699 654 612 612 884 605 547 705 698 ## 1986 561 564 773 717 665 667 994 661 616 786 806 ## 1987 622 636 874 831 769 779 1142 764 718 930 943 ## 1988 736 752 1057 947 868 931 1311 896 867 1073 1069 ## Dec ## 1984 1447 ## 1985 1555 ## 1986 1754 ## 1987 2039 ## 1988 2333 시계열 그래프 작성 예제: 백화점 매출액 자료 백화점 매출액 자료인 depart.ts의 시계열 그래프를 그림 1.1에 작성해 보자. autoplot(depart.ts) + labs(title = &quot;Monthly sales of a department store&quot;, x = &quot;Year&quot;, y = NULL) 그림 1.1: 백화점 월별 매출액 예제: 지구 온도 자료 1856년 1월부터 2005년 12월까지 지구 온도 자료가 global.txt에 입력되어 있다. 이 자료의 시계열 그래프를 그림 1.2에 작성해 보자. global &lt;- scan(&quot;https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/global.txt&quot;) global.ts &lt;- ts(global, start = c(1856, 1), frequency = 12) autoplot(global.ts) + labs(title = &quot;Global Temperature 1985 ~ 2005&quot;, x = &quot;Year&quot;, y = NULL) 그림 1.2: 1856년부터 2005년까지 지구 온도 시계열 그래프 그림 1.2에서 볼 수 있는 것은 대략 1970년 이후로 지속적인 상승 패턴이 있다는 점이다. 1970년 이후 자료에 대한 시계열 그래프를 다시 작성해 보자. 이것을 위해서는 이미 생성된 ts 객체에서 일부분을 선택해야 하는데, 이 작업은 함수 window()로 할 수 있다. global.1970 &lt;- window(global.ts, start = 1970) 이제 1970년 1월 이후 자료에 대한 시계열 그래프를 그림 1.3에 작성해 보자. autoplot(global.1970) + labs(title = &quot;Global Temperature 1970 ~ 2005&quot;, x = &quot;Year&quot;, y = NULL) 그림 1.3: 1970년부터 2005년까지 지구 온도 시계열 그래프 그림 1.3의 시계열 그래프에 회귀직선을 추가하면, 상승 추세를 조금 더 명확하게 확인할 수 있다. 회귀직선을 추가한 그래프를 그림 1.4에 작성해 보자. autoplot(global.1970) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + labs(title = &quot;Global Temperature 1970 ~ 2005&quot;, x = &quot;Year&quot;, y = NULL) 그림 1.4: 시계열 그래프에 회귀직선 추가 예제: 다중 시계열 그래프 cbe.txt에는 호주에서 1958년부터 생산된 초콜릿, 맥주 및 전기의 월별 생산량이 입력되어 있다. 파일은 행과 열의 구조를 갖고 있으며, 각 자료는 빈 칸으로 구분되어 있다. 이런 구조의 텍스트 파일을 불러오기 위해서 패키지 readr의 함수 read_table()을 사용하였다. library(readr) CBE &lt;- read_table(&quot;https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/cbe.txt&quot;) CBE %&gt;% print(n = 3) ## # A tibble: 396 × 3 ## choc beer elec ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1451 96.3 1497 ## 2 2037 84.4 1463 ## 3 2477 91.2 1648 ## # … with 393 more rows tibble로 입력된 자료를 ts 객체로 변환해 보자. 함수 ts()에 데이터 프레임을 입력하면 열을 구성하는 벡터를 각각 개별 ts 객체로 변환시킨다. cbe &lt;- ts(CBE, start = 1958, frequency = 12) head(CBE, n = 3) ## # A tibble: 3 × 3 ## choc beer elec ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1451 96.3 1497 ## 2 2037 84.4 1463 ## 3 2477 91.2 1648 cbe에는 시계열자료 choc, beer와 elec로 구성되어 있음을 알 수 있다. 이러한 다중 시계열 자료를 함수 autoplot()에 입력한 다중 시계열 그래프를 그림 1.5에 작성해 보자. autoplot(cbe) + ylab(NULL) 그림 1.5: 다중 시계열 그래프 만일 다중 시계열자료의 scale에 큰 차이가 있다면 하나의 그래프에 작성하는 것보다는 facet 그래프를 작성하는 것이 더 효과적이다. Facet 다중 시계열 그래프를 그림 1.6에 작성해 보자. autoplot(cbe, facets = TRUE) + ylab(NULL) 그림 1.6: 다중 시계열 그래프 Seasonal 그래프 작성 예제: AirPassengers 우선 함수 ggseasonplot()에 의한 seasonal 그래프를 그림 1.7에 작성해 보자. ggseasonplot(AirPassengers) 그림 1.7: 함수 ggseasonalplot()으로 작성된 seasonal 그래프 연도 범례를 포함시킨 seasonal 그래프를 그림 1.8에 작성해 보자. ggseasonplot(AirPassengers, year.labels = TRUE) 그림 1.8: 함수 ggseasonalplot()으로 작성된 seasonal 그래프 그래프 양쪽에 연도 범례를 포함시킨 seasonal 그래프를 그림 1.9에 작성해 보자. ggseasonplot(AirPassengers, year.labels = TRUE, year.labels.left = TRUE) 그림 1.9: 함수 ggseasonalplot()에서 year.labels.left = TRUE를 포함시킨 seasonal 그래프 극좌표 형태의 seasonal 그래프를 그림 1.10에 작성해 보자. ggseasonplot(AirPassengers, polar = TRUE) 그림 1.10: 함수 ggseasonalplot()에서 polar = TRUE를 포함시킨 seasonal 그래프 이번에는 함수 ggsubseriesplot()으로 그래프를 그림 1.11에 작성해 보자. 월별로 자료를 구분해서 선 그래프를 작성하고, 파란 선으로 월별 평균을 표시한 그래프이다. ggsubseriesplot(AirPassengers) 그림 1.11: 함수 ggsubseriesplot()으로 작성된 seasonal 그래프 월별로 구분된 자료를 대상으로 상자그림을 작성해서 보는 것도 의미있는 분석이 될 수 있을 것이다. 상자그림을 작성하기 위해서는 ts 객체인 AirPassengers를 숫자형 벡터로 변환시키고, 각 자료의 주기를 함수 cycle()로 추출해서 요인으로 변환시키는 것이 필요하다. 상자그림으로 계절 요소의 변동을 그림 1.12에 작성해 보자. tibble(AP = as.numeric(AirPassengers), mon = as.factor(cycle(AirPassengers))) %&gt;% ggplot(aes(x = mon, y = AP)) + geom_boxplot() + labs(x = &quot;Month&quot;, y = &quot;Air Passengers&quot;) 그림 1.12: 상자그림으로 나타낸 계절 변동 요소 "],["chapter-decomposition.html", "2 장 시계열 분해 전통적 시계열 분해 기법 STL 분해 기법", " 2 장 시계열 분해 library(fpp2) library(tidyverse) 전통적 시계열 분해 기법 이동평균법에서 차수 \\(m\\)의 효과: elecsales 이동평균법의 차수를 증가시키면, 더 많은 자료를 이용해서 평균값을 계산하게 되고, 따라서 더 매끄러운 추세 곡선을 얻게 된다. elecsales에 \\(m\\)-MA를 적용시켜 얻은 결과를 원자료와 함께 그래프로 나타내 보자. 우선 3-MA의 결과를 그림 2.1에 나타내 보자. autoplot(elecsales, series = &quot;Data&quot;) + autolayer(ma(elecsales, 3), series = &quot;3-MA&quot;) + scale_color_manual(values = c(&quot;Data&quot; = &quot;blue&quot;, &quot;3-MA&quot; = &quot;red&quot;)) + labs(title = &quot;3-MA&quot;, color = NULL, y = NULL) 그림 2.1: elecsales에 3-MA를 적용한 결과 3-MA의 결과는 원자료보다 매끄로운 형태를 보이고 있음을 알 수 있다. 이제 차수 \\(m\\)을 증가시키면 어떤 결과를 얻게 되는지 그림 2.2에서 살펴보자. library(patchwork) p1 &lt;- autoplot(elecsales) + autolayer(ma(elecsales, 3), size = .8, color = &quot;red&quot;) + labs(y = NULL, title = &quot;3-MA&quot;) p2 &lt;- autoplot(elecsales) + autolayer(ma(elecsales, 5), size = .8, color = &quot;red&quot;) + labs(y = NULL, title = &quot;5-MA&quot;) p3 &lt;- autoplot(elecsales) + autolayer(ma(elecsales, 7), size = .8, color = &quot;red&quot;) + labs(y = NULL, title = &quot;7-MA&quot;) p4 &lt;- autoplot(elecsales) + autolayer(ma(elecsales, 9), size = .8, color = &quot;red&quot;) + labs(y = NULL, title = &quot;9-MA&quot;) (p1+p2)/(p3+p4) 그림 2.2: elecsales 자료에 대한 차수 m의 효과 이번에는 호주에서 1956년부터 2010년까지 분기별 맥주 생산량 자료인 ausbeer에 대하여 \\(2 \\times m\\)-MA를 적용한 결과를 원자료와 함께 그림 2.3의 그래프로 나타내 보자. library(patchwork) p1 &lt;- autoplot(ausbeer) + autolayer(ma(ausbeer, 4), size = .8, color = &quot;red&quot;) + labs(y = NULL, title = &quot;4-MA&quot;) p2 &lt;- autoplot(ausbeer) + autolayer(ma(ausbeer, 8), size = .8, color = &quot;red&quot;) + labs(y = NULL, title = &quot;8-MA&quot;) p3 &lt;- autoplot(ausbeer) + autolayer(ma(ausbeer, 12), size = .8, color = &quot;red&quot;) + labs(y = NULL, title = &quot;12-MA&quot;) p4 &lt;- autoplot(ausbeer) + autolayer(ma(ausbeer, 24), size = .8, color = &quot;red&quot;) + labs(y = NULL, title = &quot;24-MA&quot;) (p1+p2)/(p3+p4) 그림 2.3: ausbeer 자료에 대한 차수 m의 효과 전통적 분해 기법 적용 예제: fpp2::elecequip decompose(elecequip) %&gt;% autoplot() 그림 2.4: elecequip 자료에 대한 전통적 분해 기법 적용 결과 각 패널의 오른쪽 끝에 높이가 동일한 막대를 배치하여, 각 성분의 상대적 크기를 쉽게 확인할 수 있게 하였다. 불규칙 성분이 표시된 마지막 패널의 막대가 가장 크다는 것은 불규칙 성분의 크기가 가장 작다는 의미가 된다. 또한 추세 성분의 처음과 마지막 6개월 자료는 NA가 되기 때문에 해당 기간에는 결과가 표시 되지 않았음을 알 수 있으고, 계절 성분이 동일한 형태를 취하고 있음도 확인할 수 있다. STL 분해 기법 STL 분해 기법 적용 예제: fpp2::elecequip library(patchwork) p1 &lt;- stl(elecequip, s.window = &quot;periodic&quot;) %&gt;% autoplot() + labs(title = &quot;s.window = &#39;periodic&#39;&quot;) p2 &lt;- stl(elecequip, s.window = 5) %&gt;% autoplot() + labs(title = &quot;s.window = 5&quot;) p1 + p2 그림 2.5: elecequip 자료에 대한 STL 분해 기법 적용 결과: s.window의 효과 library(patchwork) p3 &lt;- stl(elecequip, s.window = &quot;periodic&quot;, t.window = 7) %&gt;% autoplot() + labs(title = &quot;t.window = 7&quot;) p4 &lt;- stl(elecequip, s.window = &quot;periodic&quot;, t.window = 11) %&gt;% autoplot() + labs(title = &quot;t.window = 11&quot;) p3 + p4 그림 2.6: elecequip 자료에 대한 STL 분해 기법 적용 결과: t.window의 효과 "],["chapter-ets.html", "3 장 ETS 모형 전통적 지수평활법 ETS 모형", " 3 장 ETS 모형 library(fpp2) library(tidyverse) 전통적 지수평활법 Simple exponential smoothing 예제: fpp2::oil fpp2::oil은 1965년부터 2013년까지 Saudi Arabia의 연간 원유 생산량 자료이다. 1996년 이후 자료에 대해 simple exponential smoothing을 적용해 보자. oil_1996 &lt;- window(oil, start = 1996) 1996년 이후 연간 원유 생산량 자료의 시계열 그래프를 그림 3.1에 작성해 보자. autoplot(oil_1996) + labs(title = &quot;Annual oil production in Saudi Arabia&quot;, y = NULL) 그림 3.1: 1996년 이후 Saudi Arabia 연간 원유 생산량 함수 ses()를 사용하여 2014년 ~ 2016년의 원유 생산량을 예측해 보자. ses(oil_1996, h = 3) %&gt;% summary() ## ## Forecast method: Simple exponential smoothing ## ## Model Information: ## Simple exponential smoothing ## ## Call: ## ses(y = oil_1996, h = 3) ## ## Smoothing parameters: ## alpha = 0.8339 ## ## Initial states: ## l = 446.5868 ## ## sigma: 29.8282 ## ## AIC AICc BIC ## 178.1430 179.8573 180.8141 ## ## Error measures: ## ME RMSE MAE MPE MAPE ## Training set 6.401975 28.12234 22.2587 1.097574 4.610635 ## MASE ACF1 ## Training set 0.9256774 -0.03377748 ## ## Forecasts: ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 2014 542.6806 504.4541 580.9070 484.2183 601.1429 ## 2015 542.6806 492.9073 592.4539 466.5589 618.8023 ## 2016 542.6806 483.5747 601.7864 452.2860 633.0752 Level에 대한 평활상수가 \\(\\alpha =\\) 0.8339으로 추정되었다는 것은 level에 큰 변화가 있는 자료를 의미한다. 이제 예측 결과를 그림 3.2의 그래프로 나타내 보자. ses(oil_1996, h = 3) %&gt;% autoplot() + labs(y = NULL) 그림 3.2: 1996년 이후 Saudi Arabia 연간 원유 생산량 및 2014년 이후 예측 결과 파란 실선으로 표시된 예측값은 마지막 level 추정값으로써, 모든 h에 대하여 동일하다는 것을 알 수 있다. 예측값을 표시한 실선을 포함하고 있는 짙은 파란 색 영역은 80% 예측 구간을 표시한 것이고, 옅은 파란 색 영역은 95% 예측 구간을 표시한 것이다. 예측 시차가 증가함에 따라 예측 구간의 폭은 계속 넓어지고 있음을 알 수 있다. Trend method 예제: fpp2::ausair fpp2::ausair는 1970년부터 2016년까지 호주의 연간 항공기 승객 수 자료이다. Holt’s linear trend와 damped Holt’s trend 모형을 이용해서 예측을 실시해 보자. 먼저 시계열 그래프를 그림 3.3에 작성해 보자. 상승 추세가 있는 것을 확인할 수 있다. autoplot(ausair) + labs(title = &quot;Air Transport Passengers Australia&quot;, y = NULL) 그림 3.3: 1970년부터 2016년까지 호주의 연간 항공기 승객 수 Holt’s linear trend 모형을 함수 holt()를 사용해서 적합시키고, 15 시차에 대한 예측 결과를 그림 3.4에 나타내 보자. holt(ausair, h = 15) %&gt;% autoplot() 그림 3.4: ausair 자료에 대한 Holt’s linear trend method의 예측 결과 Damped Holt’s trend 모형에 의한 예측 결과도 그래프로 나타내 보자. 결과는 그림 3.5에서 볼 수 있다. holt(ausair, h = 15, damped = TRUE) %&gt;% autoplot() 그림 3.5: ausair 자료에 대한 damped Holt’s trend method의 예측 결과 그림 3.4에서 볼 수 있듯이 Holt’s linear trend method에 의한 예측 결과는 지속적으로 증가하고 있으며, 반면에 damped Holt’s trend method에 의한 예측 결과는 상승 기울기가 점점 줄어들고 있다는 것을 그림 3.5에서 볼 수 있다. Holt-Winters’ seasonal method 예제: fpp2::austourists austourists는 199년부터 2015년까지 분기별 호주에 입국한 외국인 관광객 수 자료이다. 시계열 그래프는 그림 3.6에서 볼 수 있다. autoplot(austourists) + labs(y = NULL, title = &quot;International Tourists to Australia&quot;) 그림 3.6: 199년부터 2015년까지 분기별 호주에 입국한 외국인 관광객 수 Holt-Winters’ seasonal 모형을 이용해서 예측을 실시해 보자. 먼저 가법 모형으로 예측을 실시하고 결과를 그림 3.7에 그래프로 나타내 보자. hw(austourists) %&gt;% autoplot() + labs(y = NULL) 그림 3.7: austourists 자료에 대한 Holt-Winters’ additive seasonal method의 예측 결과 이번에는 승법 모형으로 예측을 실시하고 결과를 그림 3.8에 그래프로 나타내 보자. hw(austourists, seasonal = &quot;multiplicative&quot;) %&gt;% autoplot() + labs(y = NULL) 그림 3.8: austourists 자료에 대한 Holt-Winters’ multiplicative seasonal method의 예측 결과 ETS 모형 예제 1: 1970년부터 2016년까지 연간 항공기 이용객 수 (fpp2::ausair) fpp2::ausair는 1970년부터 2016년까지 호주의 연간 항공기 승객 수 자료이다. 먼저 전체 자료 중 1970년부터 2011년까지의 자료를 training data로 하고, 2012년 이후 자료를 test data로 분리하자. train_air &lt;- window(ausair, end = 2011) test_air &lt;- window(ausair, start = 2012) train_air와 test_air의 시계열 그래프는 그림 3.9과 같다. test_air는 빨간 선으로 나타냈다. autoplot(window(ausair, end = 2012)) + autolayer(window(ausair, start = 2012), size = .8) + labs(y = NULL, x = NULL) + theme(legend.position = &quot;none&quot;) 그림 3.9: ausair 자료의 시계열그래프 함수 ets()로 ETS 모형을 적합하고, 그 결과를 확인해 보자. fit_air &lt;- ets(train_air) fit_air ## ETS(M,A,N) ## ## Call: ## ets(y = train_air) ## ## Smoothing parameters: ## alpha = 0.9999 ## beta = 0.024 ## ## Initial states: ## l = 6.5399 ## b = 0.7358 ## ## sigma: 0.08 ## ## AIC AICc BIC ## 206.1828 207.8495 214.8712 최적 모형은 ETS(M,A,N)으로 선정되었다. 즉, 추세는 additive이고 오차는 multiplicative이며, 계절요소가 없는 모형이 적합되었다. 평활모수는 \\(\\alpha=\\) 0.9999 , \\(\\beta=\\) 0.024 로 추정되었다. 따라서 시계열자료의 level에는 큰 변화가 있으나, 추세의 기울기에는 큰 변화 없이 일정하다는 것을 알 수 있다. ETS 모형의 각 요소에 대한 추정 결과를 그림 3.10의 그래프로 나타내 보자. 관측된 자료의 시계열 그래프, 그리고 level의 추정 결과와 추세 기울기의 추정 결과의 시계열 그래프가 함께 작성되어 있다. 그래프 오른쪽 끝에 있는 동일한 높이의 막대가 표시되어 있어서 각 요소의 스케일을 비교할 수 있다. autoplot(fit_air) 그림 3.10: ETS 모형의 각 요소에 대한 추정 결과 그래프 모형의 가정 만족 여부를 함수 checkresiduals()로 확인해 보자. 특별히 문제가 되는 가정 사항은 없는 것으로 보인다. checkresiduals(fit_air) ## ## Ljung-Box test ## ## data: Residuals from ETS(M,A,N) ## Q* = 3.5236, df = 4, p-value = 0.4743 ## ## Model df: 4. Total lags used: 8 이제 예측을 실시하고 예측 오차에 대한 평가를 실시해 보자. fc_air &lt;- forecast(fit_air, h = length(test_air)) accuracy(fc_air, test_air) ## ME RMSE MAE MPE MAPE ## Training set 0.5550369 2.138179 1.31460 0.7893247 5.399428 ## Test set 1.7629504 1.888573 1.76295 2.5419343 2.541934 ## MASE ACF1 Theil&#39;s U ## Training set 0.7649321 -0.09163575 NA ## Test set 1.0258159 -0.22513230 1.034042 예측 결과를 그래프로 나타내 보자. 함수 autoplot()에 함수 forecast()의 결과인 객체 fc_air를 입력하면 training data와 예측 결과를 함께 나타낸다. 옵션 include는 그래프에 포함시킬 training data의 개수를 지정하는 것이다. 따라서 include = 0을 입력하면 예측 부분만을 확대한 효과를 볼 수 있다. 작성 결과는 그림 3.11에서 볼 수 있다. library(patchwork) p1 &lt;- autoplot(fc_air) + autolayer(test_air, color = &quot;red&quot;, size = .8) + labs(y = NULL, x = NULL) p2 &lt;- autoplot(fc_air, include = 0) + autolayer(test_air, color = &quot;red&quot;, size=.8) + labs(y = NULL, x = NULL) p1 + p2 그림 3.11: fpp2::ausair 자료에 대한 ETS 모형의 예측 결과 예제 2: 1999년부터 2015년까지 분기별 호주 입국 외국인 관광객 수 (fpp2::austourists) austourists는 1999년부터 2015년까지 분기별로 호주에 입국한 외국인 관광객 수 자료이다. 2013년 4분기까지를 training data로 분리하고 2014년 1분기부터를 test data로 분리하자. train_tour &lt;- window(austourists, end = c(2013, 4)) test_tour &lt;- window(austourists, start = c(2014, 1)) 두 자료의 시계열 그래프는 그림 3.12과 같다. Test data는 빨간 선으로 표시했다. 상승 추세가 있으며, 명확한 계절요소가 있는 것을 알 수 있다. 또한 계절요소의 진폭이 추세가 상승함에 따라 다소 증가하고 있는 것을 볼 수 있다. 그림 3.12: austourists 자료의 시계열 그래프 함수 ets()로 최적 모형을 적합해 보자. fit_tour &lt;- ets(train_tour) fit_tour ## ETS(M,A,M) ## ## Call: ## ets(y = train_tour) ## ## Smoothing parameters: ## alpha = 0.4189 ## beta = 1e-04 ## gamma = 1e-04 ## ## Initial states: ## l = 24.2672 ## b = 0.5179 ## s = 1.0367 0.9578 0.7697 1.2358 ## ## sigma: 0.0612 ## ## AIC AICc BIC ## 353.3882 356.9882 372.2373 ETS(M,A,M) 모형이 선택되었다. 승법 계절 성분이 선택되었다는 것은 계절 요소의 변동 폭이 증가한다는 의미가 된다. 이런 경우에 시계열자료를 로그변환 시킨 후 다시 ETS 모형을 적합시키면 가법 계절 모형이 선택될 것이다. 함수 ets()의 Box_Cox 변환 모수인 옵션 lambda에 0을 입력하면 로그변환된 자료를 대상으로 모형 적합이 이루어진다. fit_lntour &lt;- ets(train_tour, lambda = 0) fit_lntour ## ETS(A,A,A) ## ## Call: ## ets(y = train_tour, lambda = 0) ## ## Box-Cox transformation: lambda= 0 ## ## Smoothing parameters: ## alpha = 0.337 ## beta = 1e-04 ## gamma = 0.0137 ## ## Initial states: ## l = 3.2161 ## b = 0.0122 ## s = 0.055 -0.0254 -0.2477 0.2181 ## ## sigma: 0.0639 ## ## AIC AICc BIC ## -75.06808 -71.46808 -56.21898 모형 fit_tour의 가정 만족 여부를 확인해 보자. checkresiduals(fit_tour) ## ## Ljung-Box test ## ## data: Residuals from ETS(M,A,M) ## Q* = 5.3591, df = 3, p-value = 0.1473 ## ## Model df: 8. Total lags used: 11 모형 fit_lntour의 가정 만족 여부도 확인해 보자. checkresiduals(fit_lntour) ## ## Ljung-Box test ## ## data: Residuals from ETS(A,A,A) ## Q* = 7.2993, df = 3, p-value = 0.06294 ## ## Model df: 8. Total lags used: 11 두 모형 모두 가정은 만족시키는 것으로 보인다. 이제 두 모형의 예측을 실시하고, 그 결과를 비교해 보자. fc_tour &lt;- forecast(fit_tour, h = length(test_tour)) fc_lntour &lt;- forecast(fit_lntour, h = length(test_tour)) accuracy(fc_tour, test_tour) ## ME RMSE MAE MPE ## Training set 0.004642325 1.966538 1.474615 -0.4054666 ## Test set 1.541295202 2.989673 2.414226 2.6022154 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 4.196005 0.5206241 -0.0243205 NA ## Test set 3.958845 0.8523613 0.5001355 0.2077632 accuracy(fc_lntour, test_tour) ## ME RMSE MAE MPE ## Training set 0.1640202 2.014686 1.562901 0.04389638 ## Test set 0.6115065 2.128486 1.722829 1.03590923 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 4.399828 0.5517943 0.01619145 NA ## Test set 2.853023 0.6082580 0.47705974 0.1348746 모형 ETS(A,A,A)인 fit_lntour의 test data에 대한 예측 오차가 조금 더 작은 것을 볼 수 있다. 두 모형의 예측 결과를 그림 3.13의 그래프로 비교해 보자. 함수 autolayer()에 PI = FALSE를 입력하면 예측 구간이 생략된다. 이것은 두 모형의 예측 구간이 함께 표시되면 서로 겹쳐지는 현상이 발생하기 때문에 생략한 것이다. 두 모형의 예측에는 큰 차이가 없음을 알 수 있다. library(patchwork) p1 &lt;- autoplot(train_tour) + autolayer(test_tour, series = &quot;Test data&quot;) + autolayer(fc_tour, PI = FALSE, series = &quot;ETS(M,A,M)&quot;) + autolayer(fc_lntour, PI = FALSE, series = &quot;ETS(A,A,A)&quot;) + labs(y = NULL, x = NULL, color = NULL) + theme(legend.position = &quot;top&quot;) p2 &lt;- autoplot(test_tour, series = &quot;Test data&quot;, size = .8) + autolayer(fc_tour, PI = FALSE, series = &quot;ETS(M,A,M)&quot;, size = .8) + autolayer(fc_lntour, PI = FALSE, series = &quot;ETS(A,A,A)&quot;, size = .8) + labs(y = NULL, x = NULL, color = NULL) + theme(legend.position = &quot;top&quot;) p1 + p2 그림 3.13: austourists 자료에 대한 예측 결과 비교 모형 ETS(A,A,A)인 fit_lntour의 test data에 대한 예측 결과를 예측 구간과 함께 그림 3.14의 그래프로 나타내 보자. library(patchwork) p1 &lt;- autoplot(fc_lntour) + autolayer(test_tour, color = &quot;red&quot;, size = .8) + labs(x = NULL, y = NULL) p2 &lt;- autoplot(fc_lntour, include = 0) + autolayer(test_tour, color = &quot;red&quot;, size = .8) + labs(y = NULL, x = NULL) + scale_x_continuous(breaks = c(2014.0, 2014.5, 2015.0, 2015.5), labels = c(&quot;2014.Q1&quot;, &quot;2014.Q4&quot;, &quot;2015.Q1&quot;, &quot;2015.Q4&quot;)) p1 + p2 그림 3.14: austourists 자료에 대한 예측 결과 예제 3: 1965년 1월부터 1992년 7월까지 월별 실업 급여 수급 인원 수 (fma::dole) fma::dole은 1965년 1월부터 1992년 7월까지 월별로 실업 급여를 받아간 인원 수 자료이다. 마지막 2년 자료를 test data로 분리해 보자. train_d &lt;- window(dole, end = c(1990, 7)) test_d &lt;- window(dole, start = c(1990, 8)) 두 자료에 대한 시계열 그래프는 그림 3.15과 같다. Test data는 빨간 선으로 표시했다. 1990년부터 갑작스런 증가세를 보이고 있으며, test data가 대부분 그 시기에 관측된 것이다. 따라서 예측이 상당히 어려운 것으로 보이는 상황이다. autoplot(train_d) + autolayer(test_d, show.legend=FALSE, size = .8) + labs(y = NULL, x = NULL) 그림 3.15: dole 자료의 시계열그래프 ETS 모형을 적합해 보자. fit_d &lt;- ets(train_d) fit_d ## ETS(M,Ad,M) ## ## Call: ## ets(y = train_d) ## ## Smoothing parameters: ## alpha = 0.7057 ## beta = 0.1262 ## gamma = 0.2942 ## phi = 0.8701 ## ## Initial states: ## l = 2693.6084 ## b = 838.4198 ## s = 1.0776 0.9108 0.9286 0.9993 1.0254 1.0275 ## 1.0028 0.9466 1.0225 0.9982 1.0038 1.0568 ## ## sigma: 0.0965 ## ## AIC AICc BIC ## 9930.864 9932.591 10003.373 가정 만족 여부를 확인해 보니, 독립성 가정에 문제가 있는 것을 볼 수 있다. 이런 경우, 점 예측값 (point forecast)에는 별다른 문제가 없겠지만, 예측 구간을 신뢰하기 어렵다고 할 수 있다. checkresiduals(fit_d) ## ## Ljung-Box test ## ## data: Residuals from ETS(M,Ad,M) ## Q* = 270.13, df = 7, p-value &lt; 2.2e-16 ## ## Model df: 17. Total lags used: 24 예측을 실시하고 평가해 보자. fc_d &lt;- forecast(fit_d, h = length(test_d)) accuracy(fc_d, test_d) ## ME RMSE MAE MPE ## Training set 307.438 16094.96 9474.828 0.5940649 ## Test set 208048.806 234353.38 208048.806 28.7917875 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 6.112239 0.2965093 0.5103798 NA ## Test set 28.791788 6.5107678 0.8895083 8.715368 MASE 값이 지나치게 큰 값이라는 것을 알 수 있다. 예측 결과를 그림 3.16의 그래프로 나타내 보자. autoplot(fc_d) + autolayer(test_d, color = &quot;red&quot;, size = .8) + labs(y = NULL, x = NULL) 그림 3.16: dole 자료에 대한 예측 결과 예측이 완벽하게 벗어난 것을 볼 수 있다. 이와 같이 실업자 수가 갑작스럽게 증가하는 상황에서는 과거 자료만을 이용하는 시계열 모형으로는 효율적인 예측이 불가능하다고 하겠다. Test data에서 발생한 갑작스런 변화의 충격을 완화시키는 방법으로 test data의 기간 축소를 생각할 수 있다. 이렇게 되면, 증가 추세가 training data에도 어느 정도 반영될 수 있을 것이다. 하지만 이 방법은 자료의 추세를 먼저 확인하고 test data의 기간을 변경하는 것이어서 정당한 자료 분리 방법은 아니라고 할 수 있다. 마지막 1년만을 test data로 남겨 놓고 모형 적합을 시도해 보자. 자료분리는 함수 subset()으로도 진행할 수 있다. 옵션end와start`에 벡터에서 적용되는 방식의 인덱스를 지정할 수 있다. train_d_1 &lt;- subset(dole, end = length(dole) - 12) test_d_1 &lt;- subset(dole, start = length(dole) - 11) 변경된 training data를 사용해서 적합된 모형으로 마지막 1년 자료에 대한 예측을 실시해 보자. 훨씬 개선된 결과를 볼 수 있다. fc_d_1 &lt;- train_d_1 %&gt;% ets() %&gt;% forecast(h = length(test_d_1)) accuracy(fc_d_1, test_d_1) ## ME RMSE MAE MPE MAPE ## Training set 419.4624 18184.20 10856.63 0.5111136 6.268750 ## Test set 5143.1303 46330.29 40948.53 1.0361996 5.319935 ## MASE ACF1 Theil&#39;s U ## Training set 0.3014767 0.5191139 NA ## Test set 1.1370959 0.8678915 2.792915 이제 예측 결과를 그림 3.17의 그래프로 나타내 보자. library(patchwork) p1 &lt;- autoplot(fc_d_1) + autolayer(test_d_1, color = &quot;red&quot;, size = .8) + labs(y = NULL, x = NULL) p2 &lt;- autoplot(fc_d_1, include = 0) + autolayer(test_d_1, color = &quot;red&quot;, size = .8) + labs(y = NULL, x = NULL) p1 + p2 그림 3.17: dole 자료에 대한 예측 결과 예제 4: 2014년 4월 30일부터 1년간 Hyndsight 블로그 일일 방문자 수 (fpp2::hyndsight) hyndsight는 2014년 4월 30일부터 1년간 Hyndman이 운영하는 블로그에 방문한 일일 방문자 수 자료이다. 자료의 시계열그래프는 그림 3.18에서 볼 수 있다. autoplot(hyndsight) + labs(x = NULL, y = NULL) 그림 3.18: hyndsight 자료의 시계열그래프 일일 자료의 경우에 요일의 영향을 받는 자료라면 \\(m=7\\)의 계절 주기를 갖게 된다. 자료 분리를 위해 2014년 4월 30일이 무슨 요일인지 확인해 보자. lubridate::wday(as.Date(&quot;2014-4-30&quot;), label = TRUE) ## [1] 수 ## Levels: 일 &lt; 월 &lt; 화 &lt; 수 &lt; 목 &lt; 금 &lt; 토 start(hyndsight); end(hyndsight) ## [1] 1 4 ## [1] 53 4 2014년 4월 30일은 수요일이며, 자료의 시작 시점은 1주 4일 (수)이고 종료 시점은 53주 4일 (수)이 된다. Training data는 1주 4일부터 48주 4일까지로 하고, test data는 48주 5일부터 53주 4일까지 5주간으로 설정하자. 자료 분리는 함수 window()로 보통 진행하지만, 이렇게 자료의 개수로 분리하는 것이 더 편리한 경우에는 함수 subset()으로 진행 할 수 있다. 즉, 마지막 35일 자료를 test data로 분리해 보자. train_hyn &lt;- subset(hyndsight, end = length(hyndsight)-35) test_hyn &lt;- subset(hyndsight, start = length(hyndsight)-34) ETS 모형을 적합해 보자. 추세는 없고, 오차와 계절 성분이 모두 가법 형태인 모형이 선택되었다. fit_hyn &lt;- ets(train_hyn) fit_hyn ## ETS(A,N,A) ## ## Call: ## ets(y = train_hyn) ## ## Smoothing parameters: ## alpha = 0.4426 ## gamma = 1e-04 ## ## Initial states: ## l = 1173.6676 ## s = 296.9907 -34.3415 -457.6839 -271.7606 63.9589 172.9509 ## 229.8854 ## ## sigma: 232.0085 ## ## AIC AICc BIC ## 5519.446 5520.136 5557.437 이제 예측을 진행해 보자. fc_hyn &lt;- forecast(fit_hyn, h = length(test_hyn)) accuracy(fc_hyn, test_hyn) ## ME RMSE MAE MPE ## Training set 3.727848 228.8229 164.1102 -2.026679 ## Test set -73.167844 231.3494 180.9392 -8.044075 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 13.86475 0.7404020 0.1874059 NA ## Test set 13.09378 0.8163279 0.3712518 0.5878683 예측 결과를 그림 3.19의 그래프와 같이 작성해 보자. 빨간 실선은 test data이고, 파란 실선이 예측 결과이다. 예측 구간은 80%와 95% 수준에서 각각 계산되는 것이 디폴트이며, 80% 예측 구간은 짙은 색으로 표시되고, 95% 예측 구간은 옅은 색으로 표시된다. autoplot(fc_hyn, include = 0) + autolayer(test_hyn, color = &quot;red&quot;, size = .8) + labs(x = NULL, y = NULL) 그림 3.19: hynsight 자료에 대한 예측 결과 "],["chapter-arima.html", "4 장 ARIMA 모형 시계열자료의 정상성 비계절형 ARIMA 모형 계절형 ARIMA 모형", " 4 장 ARIMA 모형 library(fpp2) library(tidyverse) 시계열자료의 정상성 분산 안정화 변환 예제: 호주의 1956년 1월부터 1995년 8월까지 월별 전기 생산량 자료 (fma::elec) 분산 안정화 변환이 필요한 자료의 예로써 1956년 1월부터 1995년 8월까지 호주의 월별 전기 생산량 자료인 fma::elec을 살펴보자. 시계열 그래프는 그림 4.1에서 볼 수 있다. autoplot(elec) + labs(x = NULL, y = NULL) 그림 4.1: elec 자료의 시계열 그래프 증가하는 추세가 있으며, 명확한 계절 성분이 있는 자료임을 알 수 있다. 또한 계절 성분의 변동 폭이 추세가 증가함에 따라 함께 증가하는 현상도 볼 수 있다. Box-Cox 변환을 위한 함수에는 패키지 forecast의 함수 BoxCox.lambda()와 BoxCox()가 있다. 함수 BoxCox.lambda()는 주어진 자료에 대한 변환 모수 \\(\\lambda\\) 의 적정 값을 추정하고, 함수 BoxCox()는 입력된 \\(\\lambda\\) 값으로 자료의 변환을 실시한다. 이제 elec 자료에 대해 Box-Cox 변화을 실시해 보자. (lambda &lt;- BoxCox.lambda(elec)) ## [1] 0.2654076 변환된 자료의 시계열 그래프를 그림 4.2에 작성해 보자. autoplot(BoxCox(elec, lambda)) + labs(x = NULL, y = NULL) 그림 4.2: elec 자료에 Box-Cox 변환 실시 그림 4.2에서 볼 수 있듯이 Box-Cox 변환된 자료는 전체적으로 일정한 변동 폭을 유지하고 있음을 알 수 있다. 그러나 변환된 자료인 \\(y_{t}^{0.2654}\\) 에 대한 의미가 명확하지 않아서 해석에 문제가 있을 수 있다. 비교 차원에서 로그 변환을 실시해 보고, 결과를 비교해 보자. library(patchwork) p1 &lt;- autoplot(BoxCox(elec, BoxCox.lambda(elec))) + labs(x = NULL, y = NULL, title = &quot;Box-Cox transformation&quot;) p2 &lt;- autoplot(log(elec)) + labs(x = NULL, y = NULL, title = &quot;log transformation&quot;) p1 + p2 그림 4.3: elec 자료에 대한 분산안정화 변환의 비교 두 변환 결과에는 큰 차이가 없다는 것을 그림 4.3에서 확인 할 수 있다. 따라서 이 경우에는 승법 모형을 가법 모형으로 변환한다는 의미를 갖고 있어서 해석이 비교적 용이한 로그 변환을 사용하는 것이 더 좋을 것으로 보인다. 차분 예제 : Google 주가 자료 (fpp2::goog200) Google 주가 자료인 goog200의 시계열 그래프와 표본 ACF를 작성해 보자. 대체적으로 증가하는 추세가 있으며, 표본 ACF가 매우 천천히 감소하고 있다. p1 &lt;- autoplot(goog200) + labs(x = NULL, y = NULL, title = &quot;Google stock price&quot;) p2 &lt;- ggAcf(goog200) + ggtitle(&quot;&quot;) p1 + p2 그림 4.4: goog200 자료의 시계열 그래프와 ACF 이제 goog200 자료를 1차 차분하고 결과를 확인해 보자. goog200_1 &lt;- diff(goog200) p3 &lt;- autoplot(goog200_1) + labs(x = NULL, y = NULL, title = &quot;Google stock price&quot;) p4 &lt;- ggAcf(goog200_1) + ggtitle(&quot;&quot;) p3 + p4 그림 4.5: goog200의 1차 차분된 자료의 시계열 그래프와 ACF 차분된 자료는 하나의 이상값을 제외하면 일정한 level을 유지하고 있으며, 표본 ACF의 모든 값들이 신뢰구간 안에 존재하고 있음을 알 수 있다. 따라서 차분된 자료는 백색잡음 자료로 보이며, 이것은 원자료가 확률보행 자료임을 나타내는 것이 된다. goog200 자료를 대상으로 단위근 검정을 실시해 보자. 단위근 검정은 urca::ur.kpss()로 실시할 수 있지만, 함수 forecast::ndiffs()를 사용하면 정상성을 만족시키기 위한 차분의 횟수를 단위근 검정에 근거를 두고 추정해 준다. ndiffs(goog200) ## [1] 1 즉, 1차 차분을 실시하면 정상성을 만족시킬 수 있다고 제안하는 것이다. 물론 urca::ur.kpss()로 단위근 검정을 실시해서 주어진 자료의 정상성 여부를 확인할 수 있다. |&gt; 기호는 base R의 pipe 연산자이며, 기본적인 사용법은 %&gt;%와 동일하다. library(urca) goog200 |&gt; ur.kpss() |&gt; summary() ## ## ####################### ## # KPSS Unit Root Test # ## ####################### ## ## Test is of type: mu with 4 lags. ## ## Value of test-statistic is: 2.7441 ## ## Critical value for a significance level of: ## 10pct 5pct 2.5pct 1pct ## critical values 0.347 0.463 0.574 0.739 계산된 검정 통계량 값이 1% 유의수준의 임계값보다 크기 때문에 정상이라는 귀무가설을 기각할 수 있다. 1차 차분을 실시한 자료를 대상으로 단위근 검정을 실시해 보면, 귀무가설을 기각할 수 없기 때문에 1차 차분으로 정상성을 확보했다고 볼 수 있다. goog200 |&gt; diff() |&gt; ur.kpss() |&gt; summary() ## ## ####################### ## # KPSS Unit Root Test # ## ####################### ## ## Test is of type: mu with 4 lags. ## ## Value of test-statistic is: 0.1163 ## ## Critical value for a significance level of: ## 10pct 5pct 2.5pct 1pct ## critical values 0.347 0.463 0.574 0.739 예제 : 호주의 1956년 1월부터 1995년 8월까지 월별 전기 생산량 자료 (fma::elec) 그림 4.1에서 살펴본 elec는 증가하는 추세와 뚜렷한 계절 성분이 있으며, 분산이 시간이 흐름에 따라 증가하는 자료이다. 정상성을 만족시키기 위한 변환 절차에서 분산 안정화는 항상 가장 먼저 시행해야 한다. 로그 변환을 시행해서 분산을 안정화 시킨 자료의 시계열 그래프와 ACF는 그림 4.6에서 볼 수 있다. ln_elec &lt;- log(elec) p1 &lt;- autoplot(ln_elec) + labs(x = NULL, y = NULL, title = &quot;log transformed data&quot;) p2 &lt;- ggAcf(ln_elec) + ggtitle(&quot;&quot;) p1 + p2 그림 4.6: elec에 로그 변환한 자료의 시계열 그래프와 ACF 뚜렷하게 존재하는 계절 성분을 제거하기 위해 계절 차분을 실시할 필요가 있는 것으로 보인다. 계절 차분의 경우에는 함수 forecast::nsdiffs()를 사용하면 계절 단위근 검정을 근거로 하여 계절 차분 횟수를 추정할 수 있다. 함수 nsdiffs()는 seasonal strength를 측정하는 통계량을 근거로 하여 차분 횟수를 추정하는 것이 디폴트이다. elec |&gt; log() |&gt; nsdiffs() ## [1] 1 계절 차분을 실시한 자료를 대상으로 시계열 그래프와 ACF를 작성해 보자. 작성된 그래프는 그림 4.7에서 확인할 수 있다. ln_elec_m &lt;- log(elec) %&gt;% diff(lag = 12) p3 &lt;- autoplot(ln_elec_m) + labs(x = NULL, y = NULL, title = &quot;log transformed and seasonally differenced data&quot;) p4 &lt;- ggAcf(ln_elec_m) + ggtitle(&quot;&quot;) p3 + p4 그림 4.7: 로그 변환된elec에 계절차분을 실시한 자료의 시계열 그래프와 ACF 그림 4.7에서 볼 수 있듯이 추세 성분이 아직 남아 있는 것으로 보인다. 이제 계절 차분된 자료에 1차 차분을 더 실시한 결과를 살펴보자. 그림 4.8에 나타난 패턴을 보면, 비정상 요소가 모두 제거되었음을 알 수 있다. ln_elec_m_1 &lt;- log(elec) %&gt;% diff(lag = 12) %&gt;% diff() p5 &lt;- autoplot(ln_elec_m_1) + labs(x = NULL, y = NULL, title = &quot;log transformed and doubly differenced data&quot;) p6 &lt;- ggAcf(ln_elec_m_1) + ggtitle(&quot;&quot;) p5 + p6 그림 4.8: 로그 변환된 elec에 계절차분과 1차 차분을 실시한 자료의 시계열 그래프와 ACF 비계절형 ARIMA 모형 예제 1: gas 자료 자료 파일 gas.csv에는 9초 간격으로 측정된 입력 가스 비율 (rate)에 따른 이산화탄소 배출 농도 (co2)가 입력되어 있다. 먼저 자료를 입력해 보자. gas &lt;- read_csv(&quot;https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/gas.csv&quot;) gas %&gt;% print(n = 5) ## # A tibble: 296 × 2 ## rate co2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.109 53.8 ## 2 0 53.6 ## 3 0.178 53.5 ## 4 0.339 53.5 ## 5 0.373 53.4 ## # … with 291 more rows 데이터 프레임 gas에는 변수 rate와 co2가 있는 것을 알 수 있다. 변수 rate를 ts 객체로 변환해야 하는데 시작 시점과 종료 시점에 대한 정보가 없는 상태이어서, 시점을 \\(t=1, 2, 3, \\ldots\\) 로 지정하고 주기도 1로 지정하도록 하자. 이런 작업은 함수 as.ts()를 사용하면 간편하게 할 수 있다. 이어서 시계열 그래프도 그림 4.9에 작성해 보자. rate.ts &lt;- as.ts(gas$rate) autoplot(rate.ts) + labs(y = NULL) 그림 4.9: gas 자료의 시계열 그래프 rate.ts에 대한 ARIMA 모형을 적합해 보자. 먼저 전체 자료를 training data와 test data로 분리하자. Test data는 마지막 10개 자료로 한다. train_r &lt;- window(rate.ts, end = length(rate.ts) - 10) test_r &lt;- window(rate.ts, start = length(rate.ts) - 9) Training data를 대상으로 최적의 모형을 적합해 보자. 먼저 자료의 정상성 여부를 시계열 그래프와 ACF로 확인해 보자. 필요한 그래프는 그림 4.10에서 볼 수 있다. ggtsdisplay(train_r) 그림 4.10: 자료 train_r의 정상성 여부 확인을 위한 그래프 그림 4.10의 시계열 그래프에는 명확한 추세가 없는 것으로 보이지만, 표본 ACF가 비교적 천천히 모습이 보인다. 단위근 검정 결과는 차분이 필요한 것으로 나온다. ndiffs(train_r) ## [1] 1 단위근 검정 결과에 따라 정상성이 만족되지 않는 것으로 보고 차분을 실시할 수 있지만, 시계열 그래프와 ACF를 근거로 정상성이 만족된 것으로 볼 수도 있기 때문에, 차분을 실시하는 것과 실시하지 않는 두 가지 상황을 모두 고려해서 모형 식별을 진행하는 것이 좋을 것으로 보인다. 먼저 차분을 실시하지 않는 경우에 대해서 모형 적합을 진행해 보자. 차분을 실시하지 않기 위해서 d = 0을 입력하고, 이어서 stepwise, approximation, seasonal을 모두 FALSE로 지정하자. trace = TRUE를 추가하면 비교 대상 모형의 AICc 값이 출력된다. fit1 &lt;- auto.arima(train_r, d = 0, stepwise = FALSE, approximation = FALSE, seasonal = FALSE, trace = TRUE) ## ## ARIMA(0,0,0) with zero mean : 862.9984 ## ARIMA(0,0,0) with non-zero mean : 864.2264 ## ARIMA(0,0,1) with zero mean : 502.5603 ## ARIMA(0,0,1) with non-zero mean : 503.849 ## ARIMA(0,0,2) with zero mean : 245.7837 ## ARIMA(0,0,2) with non-zero mean : 247.1783 ## ARIMA(0,0,3) with zero mean : 81.487 ## ARIMA(0,0,3) with non-zero mean : 83.02667 ## ARIMA(0,0,4) with zero mean : -20.65077 ## ARIMA(0,0,4) with non-zero mean : -19.01766 ## ARIMA(0,0,5) with zero mean : -84.62715 ## ARIMA(0,0,5) with non-zero mean : -82.85418 ## ARIMA(1,0,0) with zero mean : 184.3482 ## ARIMA(1,0,0) with non-zero mean : 186.3166 ## ARIMA(1,0,1) with zero mean : -16.72114 ## ARIMA(1,0,1) with non-zero mean : -14.73886 ## ARIMA(1,0,2) with zero mean : -74.34891 ## ARIMA(1,0,2) with non-zero mean : -72.35703 ## ARIMA(1,0,3) with zero mean : -115.7122 ## ARIMA(1,0,3) with non-zero mean : -113.7137 ## ARIMA(1,0,4) with zero mean : -133.8983 ## ARIMA(1,0,4) with non-zero mean : -131.9025 ## ARIMA(2,0,0) with zero mean : -89.86221 ## ARIMA(2,0,0) with non-zero mean : -88.00051 ## ARIMA(2,0,1) with zero mean : -113.8044 ## ARIMA(2,0,1) with non-zero mean : -111.8785 ## ARIMA(2,0,2) with zero mean : -116.6196 ## ARIMA(2,0,2) with non-zero mean : -114.6669 ## ARIMA(2,0,3) with zero mean : -130.7106 ## ARIMA(2,0,3) with non-zero mean : -128.7274 ## ARIMA(3,0,0) with zero mean : -123.114 ## ARIMA(3,0,0) with non-zero mean : -121.1507 ## ARIMA(3,0,1) with zero mean : -125.3355 ## ARIMA(3,0,1) with non-zero mean : -123.3294 ## ARIMA(3,0,2) with zero mean : -123.8663 ## ARIMA(3,0,2) with non-zero mean : -121.8527 ## ARIMA(4,0,0) with zero mean : -125.2705 ## ARIMA(4,0,0) with non-zero mean : -123.2711 ## ARIMA(4,0,1) with zero mean : -123.4833 ## ARIMA(4,0,1) with non-zero mean : -121.4641 ## ARIMA(5,0,0) with zero mean : -124.0066 ## ARIMA(5,0,0) with non-zero mean : -121.9828 ## ## ## ## Best model: ARIMA(1,0,4) with zero mean 적합 결과를 확인해 보자. ARMA(1,4) 모형이 선택되었다. fit1 ## Series: train_r ## ARIMA(1,0,4) with zero mean ## ## Coefficients: ## ar1 ma1 ma2 ma3 ma4 ## 0.7769 1.1456 1.0384 0.7892 0.3022 ## s.e. 0.0450 0.0657 0.0922 0.0880 0.0627 ## ## sigma^2 = 0.03511: log likelihood = 73.1 ## AIC=-134.2 AICc=-133.9 BIC=-112.26 이번에는 차분을 실시하는 경우에 대한 모형 적합을 진행해 보자. ARIMA(3,1,1) 모형이 선택된 것을 볼 수 있다. fit2 &lt;- auto.arima(train_r, stepwise = FALSE, approximation = FALSE, seasonal = FALSE) fit2 ## Series: train_r ## ARIMA(3,1,1) ## ## Coefficients: ## ar1 ar2 ar3 ma1 ## 1.9589 -1.3503 0.3304 -0.9855 ## s.e. 0.0580 0.1032 0.0576 0.0148 ## ## sigma^2 = 0.03717: log likelihood = 65.4 ## AIC=-120.81 AICc=-120.59 BIC=-102.55 차분을 실시하지 않은 모형 fit1의 모형 진단을 실시해 보자. 모든 가정을 만족하는 것으로 보인다. checkresiduals(fit1) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,0,4) with zero mean ## Q* = 1.5628, df = 5, p-value = 0.9057 ## ## Model df: 5. Total lags used: 10 차분을 실시한 모형 fit2의 모형 진단을 실시해 보자. 가정 만족에는 문제가 없는 것으로 보인다. checkresiduals(fit2) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(3,1,1) ## Q* = 11.352, df = 6, p-value = 0.07809 ## ## Model df: 4. Total lags used: 10 두 모형 모두 예측모형으로 사용이 가능한 모형으로 보인다. 이제 두 모형 중 한 모형을 최종 예측모형으로 선택하는 것이 필요한데, 모형 fit1은 차분을 하지 않은 자료를 사용한 것이고, 모형 fit2는 차분을 실시한 자료를 사용한 것이다. 즉, 서로 다른 자료를 사용하여 적합한 모형이기 때문에, 두 모형의 AICc 등의 값을 비교하는 것은 의미가 없다. 이런 경우, 최종 예측모형 선택에 사용할 수 있는 방법은 test data에 대한 예측 결과를 근거로 하는 것이다. 두 모형을 사용하여 예측을 실시하고 test data와 비교해 보자. fc1 &lt;- forecast(fit1) fc2 &lt;- forecast(fit2) accuracy(fc1, test_r) ## ME RMSE MAE MPE ## Training set -0.003485182 0.1857419 0.1308396 NaN ## Test set 0.197714969 0.2984918 0.2589217 261.7854 ## MAPE MASE ACF1 Theil&#39;s U ## Training set Inf 0.5071232 0.01278907 NA ## Test set 282.7786 1.0035587 0.63693511 1.231509 accuracy(fc2, test_r) ## ME RMSE MAE MPE ## Training set -0.008064075 0.1911149 0.1333927 NaN ## Test set 0.325580419 0.3713446 0.3255804 390.3076 ## MAPE MASE ACF1 Theil&#39;s U ## Training set Inf 0.5170188 -0.03694615 NA ## Test set 437.7347 1.2619224 0.57275035 1.400976 함수 accuracy()의 결과를 보면, ARMA(1,4) 모형인 fit1의 예측 오차가 조금 더 작은 것으로 보인다. 따라서 이 모형을 최종 예측모형으로 선택하기로 하자. 최종 예측모형의 모형식은 다음과 같다. \\[ (1-0.7769B)~y_{t} = (1+1.145B+1.038B^{2}+0.789B^{3}+0.302B^{4})~\\varepsilon_{t} \\] 예측 결과를 그래프로 나타내 보자. Test data와 함께 표시하는 것이 비교하기 좋을 것이며, 작성된 그래프는 그림 4.11에서 확인할 수 있다. autoplot(fc1, include = 20) + autolayer(test_r, color = &quot;red&quot;, size = .8) + labs(y = &quot;rate&quot;) 그림 4.11: rate 자료에 대한 예측 결과 그래프 예제 2 : 1996년 1월부터 2012년 3월까지 Euro 지역에서의 월별 전자 제품 생산량 자료 (fpp2::elecequip) 자료 elecequip은 계절 요인이 존재하는 월별 자료이다. 비계절형 ARIMA 모형을 적합하기 위해서는 계절 요소를 자료에서 제거해야 한다. 함수 stl()로 자료를 분해하고, 이어서 함수 forecast::seasadj()를 적용해서 계절 요소를 제거해 보자. elecequip_desea &lt;- stl(elecequip, s.window=&quot;periodic&quot;) %&gt;% seasadj() 원자료와 계절 조정된 자료의 시계열 그래프를 그림 4.12에서 비교해 보자. autoplot(elecequip, series = &quot;Monthly data&quot;) + autolayer(elecequip_desea, series = &quot;Seasonally adjusted&quot;, size = .8) + scale_color_manual(values = c(&quot;Monthly data&quot; = &quot;blue&quot;, &quot;Seasonally adjusted&quot; = &quot;red&quot;)) + theme(legend.position = &quot;top&quot;) + labs(y = NULL, color = NULL) 그림 4.12: elecequip 원자료와 계절 조정된 자료의 비교 계절 조정된 자료를 대상으로 자료 분리를 실시해 보자. Test data는 마지막 2년 자료로 한다. train_eq &lt;- window(elecequip_desea, end = c(2010,3)) test_eq &lt;- window(elecequip_desea, start = c(2010,4)) 정상성 판단을 위한 그래프를 그림 4.13에 작성해 보자. ggtsdisplay(train_eq) 그림 4.13: train_eq의 정상성 여부 확인을 위한 그래프 시간에 따른 level의 변화가 보이고, 표본 ACF가 매우 천천히 감소하는 것도 알 수 있다. 단위근 검정에서도 차분이 필요한 것으로 나타난다. ndiffs(train_eq) ## [1] 1 차분된 자료를 대상으로 시계열 그래프와 ACF를 그림 4.14에 작성해 보자. train_eq %&gt;% diff() %&gt;% ggtsdisplay() 그림 4.14: train_eq의 차분한 자료의 정상성 여부 확인을 위한 그래프 차분된 자료는 정상성을 만족하는 것으로 보인다. 또한 ACF는 지수적 감소, PACF는 3시차 이후 절단으로 볼 수 있기 때문에 차분된 자료는 AR(3) 모형으로 식별할 수 있고, 따라서 원자료는 ARIMA(3,1,0) 모형으로 식별할 수 있다. 함수 auto.arima()에 의한 모형 선택을 실시해 보자. fit1 &lt;- auto.arima(train_eq, stepwise = FALSE, approximation = FALSE, seasonal = FALSE) fit1 ## Series: train_eq ## ARIMA(3,1,0) ## ## Coefficients: ## ar1 ar2 ar3 ## -0.2922 -0.0635 0.3710 ## s.e. 0.0713 0.0748 0.0718 ## ## sigma^2 = 9.169: log likelihood = -428.36 ## AIC=864.73 AICc=864.97 BIC=877.27 ACF와 PACF에 의해 선택한 결과와 동일하게 ARIMA(3,1,0) 모형이 선택되었다. 모형식은 다음과 같다. \\[ (1+0.292B+0.064B^{2}-0.371B^{3})(1-B)~y_{t}=\\varepsilon_{t} \\] 적합된 모형의 검진을 실시해 보자. 잔차는 백색잡음 자료라고 할 수 있으며, 정규분포 가정에도 문제가 없는 것으로 보인다. checkresiduals(fit1) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(3,1,0) ## Q* = 20.702, df = 21, p-value = 0.4772 ## ## Model df: 3. Total lags used: 24 예측을 실시하고, 예측 오차를 확인해 보자. fc1 &lt;- forecast(fit1) accuracy(fc1, test_eq) ## ME RMSE MAE MPE ## Training set -0.002219982 2.992424 2.301026 -0.05081691 ## Test set 8.727507127 9.330976 8.727507 9.28015517 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 2.411491 0.2786977 -0.03178277 NA ## Test set 9.280155 1.0570657 0.38874430 2.481532 예측 결과를 그림 4.15에 그래프로 나타내 보자. 예측 결과가 test data와는 차이가 있음을 알 수 있다. autoplot(fc1, include = 20) + autolayer(test_eq, color = &quot;red&quot;, size = .8) + ylab(&quot;Electrical equipment manufactured&quot;) 그림 4.15: elecequip 자료에 대한 예측 결과 계절형 ARIMA 모형 예제 1 : 1984년 1월부터 1988년 12월 국내 백화점 매출액 1984년 1월부터 1988년 12월까지 국내 어떤 백화점의 매출액 자료를 계절형 ARIMA 모형으로 적합하고 예측을 실시해 보자. 비교적 소규모 자료이기 때문에 자료를 training data와 test data로 분리하지 않고 전체 자료를 모두 사용하여 모형 적합을 진행하기로 하자. 먼저 자료를 불러오고 ts 객체로 변환시키자. depart &lt;- scan(&quot;https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/depart.txt&quot;) depart.ts &lt;- ts(depart, start = 1984, freq = 12) 시계열 객체 depart.ts의 시계열 그래프를 작성해 보자. 그림 4.16의 시계열 그래프에서 뚜렷한 증가 추세와 계절 요소가 있음을 확인할 수 있다. 또한 계절 요소의 변동 폭이 증가 추세에 따라 함께 증가하고 있는 것도 볼 수 있다. autoplot(depart.ts) + ylab(NULL) 그림 4.16: 국내 백화점 매출액 자료 따라서 백화점 매출액 자료는 분산이 동일하지 않고, 추세와 계절 요소가 모두 있는 비정상 시계열자료임을 알 수 있다. 우선 로그변환을 실시한 자료의 시계열 그래프를 그림 4.17에 작성해서 분산이 일정하게 되었는지 확인해 보자. lndepart &lt;- log(depart.ts) autoplot(lndepart) + labs(title = &quot;log(depart.ts)&quot;, y = NULL) 그림 4.17: 로그 변환된 백화점 매출액 자료 계절 요소의 변동 폭이 일정하게 유지되고 있음을 알 수 있다. 이제 추세와 계절 요소를 제거하기 위한 차분 차수를 결정해 보자. 차분 차수는 시계열 그래프와 표본 ACF, 그리고 단위근 검정 결과를 모두 반영해서 결정하는 것이 좋다. 먼저 단위근 검정 결과를 확인해 보자. 1차 차분과 계절 차분이 모두 필요한 것으로 나타났다. ndiffs(lndepart) ## [1] 1 nsdiffs(lndepart) ## [1] 1 이제 시계열 그래프와 표본 ACF의 형태를 그림 4.17에서 확인해 보자. ggtsdisplay(lndepart, lag.max = 36, main = &quot;lndepart: log transformed data&quot;) 그림 4.18: lndepart의 시계열 그래프, ACF와 PACF 차분과 계절 차분이 모두 필요한 것으로 보이는 경우에는 계절 차분을 먼저 실시하는 것이 좋다. 계절차분을 실시한 자료를 대상으로 시계열 그래프와 ACF를 작성해 보자. 그림 4.19에서 표본 ACF가 1시차에서 6시차까지 매우 천천히 감소하는 것을 볼 수 있고, 따라서 일반 차분도 필요한 것으로 보인다. lndepart_12 &lt;- diff(lndepart, lag = 12) ggtsdisplay(lndepart_12, lag.max = 36, main = &quot;Seasonally differenced lndepart&quot;) 그림 4.19: 계절 차분을 실시한 lndepart의 시계열 그래프, ACF와 PACF 1차 차분과 계절 차분을 모두 실시한 자료의 시계열 그래프와 ACF를 작성해 보자. 더 이상 비정상성 요소가 남아 있지 않다는 것을 그림 4.20에서 확인할 수 있다. 즉, 단위근 검정과 시계열 그래프, 그리고 표본 ACF를 근거로 계절 차분과 1차 차분이 모두 필요한 것으로 결정할 수 있다. lndepart_12_1 &lt;- diff(lndepart_12) ggtsdisplay(lndepart_12_1, lag.max = 36, main = &quot;Doubly differenced lndepart&quot;) 그림 4.20: 계절 차분과 1차 차분을 실시한 lndepart의 시계열 그래프, ACF와 PACF 로그 변환과 계절 차분 및 1차 차분으로 비장상성을 모두 제거한 후에는 변환된 자료에 가장 적합한 모형을 식별해야 한다. 그림 4.20에서 볼 수 있는 표본 ACF와 PACF를 근거로 모형을 식별해 보자. 비계절형 AR 차수와 MA 차수는 시차 1에서 시차 6까지의 패턴을 보고 결정해야 하는데, 표본 ACF는 1 시차만 유의한 값이고, 이후 시차는 모두 파란 점선 안으로 들어와 있음을 알 수 있고, 표본 PACF는 1, 2 시차가 비교적 큰 값이고, 이후 시차는 모두 점선 안으로 확실하게 들어와 있는 작은 값이다. 따라서 ACF는 1시차 이후 절단, PACF는 감소 형태로 판단할 수 있어서, 비계절형은 p=0, q=1인 MA(1)으로 식별할 수 있다. 계절형 요소는 시차 12, 24, 36의 패턴으로 판단해야 하는데, ACF와 PACF가 12, 24, 36 시차에서 모두 작은 값을 보이고 있는 것을 볼 수 있다. 이러한 경우에는 P=0, Q=0으로 식별할 수도 있지만, P=1, Q=0 또는 P=0, Q=1으로 식별하는 것도 가능하다. 따라서 표본 ACF와 PACF를 근거로 식별을 시도한다면, ARIMA(0,1,1)(0,1,0)12 모형과 ARIMA(0,1,1)(1,1,0)12 모형, 그리고 ARIMA(0,1,1)(0,1,1)12 모형으로 식별할 수 있다. 이제 함수 auto.arima()를 사용하여 최적 모형을 식별해 보자. 함수 auto.arima()에서는 차분 차수를 단위근 검정에 의해 결정하는 것이 디폴트이며, 백화점 자료의 경우에는 가장 적절한 차분 차수가 단위근 검정 결과와 일치하기 때문에, d와 D에 다른 값을 지정할 필요는 없다. 또한 분산 안정화를 위해 로그 변환을 시행해야 하기 때문에 lambda에 로그변환에 해당하는 값인 0을 지정해야 한다. fit_d &lt;- auto.arima(depart.ts, lambda = 0, stepwise = FALSE, approximation = FALSE) summary(fit_d) ## Series: depart.ts ## ARIMA(0,1,1)(0,1,1)[12] ## Box Cox transformation: lambda= 0 ## ## Coefficients: ## ma1 sma1 ## -0.5840 -0.4159 ## s.e. 0.1093 0.1946 ## ## sigma^2 = 0.0005401: log likelihood = 110.29 ## AIC=-214.59 AICc=-214.03 BIC=-209.04 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE ## Training set -1.937472 16.9307 11.60509 -0.200563 1.36766 ## MASE ACF1 ## Training set 0.1084166 0.04358066 ACF와 PACF를 근거로 식별한 후보 모형 중 하나인 ARIMA(0,1,1)(0,1,1)12가 선택되었음을 알 수 있다. 추정된 모형식은 다음과 같다. \\[ (1-B^{12})(1-B)~\\log y_{t} = (1-0.584B)(1-0.4159B^{12})~\\varepsilon_{t} \\] 적합된 모형 fit_d의 모형의 진단을 실시해 보자. 잔차가 정규분포 백색잡음을 하는 것으로 보여서, 가정이 만족된다고 할 수 있다. checkresiduals(fit_d) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(0,1,1)(0,1,1)[12] ## Q* = 12.817, df = 10, p-value = 0.2341 ## ## Model df: 2. Total lags used: 12 예측 결과를 그림 4.21에 그래프로 나타내보자. 예측 결과는 정상성 확보 과정에서 이루어진 변환의 역변환을 실시해서 얻어진 것이다. forecast(fit_d) %&gt;% autoplot() + ylab(NULL) 그림 4.21: 백화점 자료 예측 결과 예제 2 : 1981년 1월부터 1992년 12월까지 국내에 입국한 월별 관광객 수 1981년 1월부터 1992년 12월까지 12년 동안 국내에 입국한 월별 관광객 수 자료를 대상으로 ARIMA 모형과 ETS 모형으로 예측 모형을 각각 적합하고, 예측 결과를 비교해 보자. 예측 결과의 비교를 위해 마지막 2년 자료를 test data로 남겨두고, 이전 10년 동안의 자료를 이용하여 모형 적합을 실시해 보자. tour &lt;- scan(&quot;https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/Ktour.txt&quot;) tour.ts &lt;- ts(tour, start = 1981, freq = 12) train_K &lt;- window(tour.ts, end = c(1990,12)) test_K &lt;- window(tour.ts, start = c(1991,1)) Training data에 대한 시계열 그래프를 그림 4.22에 작성해 보자. autoplot(train_K) + ylab(NULL) 그림 4.22: 국내 입국 관광객 수 자료 계절형 ARIMA 모형을 먼저 적합시켜 보자. 시계열자료가 증가하는 추세가 있고, 뚜렷한 계절 요소가 있으며, 계절 변동 폭이 점차 증가하는 모습을 보이는 비정상 시계열자료이다. 분산 안정화 변화가 필요한 것으로 보이며, 적절한 변환 형태를 결정하기 위해 Box-Cox 변환 모수 \\(\\lambda\\) 의 값을 추정해 보자. BoxCox.lambda(train_K) ## [1] 0.09573094 \\(\\hat{\\lambda}=0.09\\) 로 추정되었는데, 이 결과를 그대로 적용해서 \\(y_{t}^{0.09}\\) 로 변환시키는 것보다는 변환의 해석이 가능하면서 추정된 \\(\\lambda\\) 값과 큰 차이가 없는 \\(\\hat{\\lambda}=0\\) 에 해당하는 로그 변환을 선택하는 것이 더 좋을 듯 하다. 로그 변환된 자료에 대한 차분 차수를 결정해 보자. 먼저 로그 변환된 시계열자료의 시계열 그래프와 ACF를 그림 4.23에 작성해 보자. lntrain_K &lt;- log(train_K) ggtsdisplay(lntrain_K, main = &quot;log transformed:lntrain_K&quot;) 그림 4.23: lntrain_K의 시계열 그래프, ACF와 PACF 계절 차분을 먼저 실시해 보고, 그 결과를 살펴보자. 그림 4.24의 시계열 그래프에서 추세 성분이 남아 있는 것을 볼 수 있고, ACF의 1~6시차에서 상당히 큰 값을 볼 수 있다. 1차 차분이 필요한 것으로 보인다. lntrain_K_12 &lt;- diff(lntrain_K, lag = 12) ggtsdisplay(lntrain_K_12, main = &quot;Seasonally differenced&quot;) 그림 4.24: 계절 차분된 lntrain_K의 시계열 그래프, ACF와 PACF 계절 차분된 자료에 다시 1차 차분을 실시하고, 그 결과를 살펴보자. 그림 4.25의 그래프에서 비정상 요소가 모두 사라진 것을 알 수 있다. lntrain_K_12_1 &lt;- diff(lntrain_K_12) ggtsdisplay(lntrain_K_12_1, main = &quot;Doubly differenced&quot;) 그림 4.25: 계절 차분과 1차 차분된 lntrain_K의 시계열 그래프, ACF와 PACF 단위근 검정에서도 일치된 결과를 볼 수 있다. ndiffs(lntrain_K) ## [1] 1 nsdiffs(lntrain_K) ## [1] 1 로그변환과 차분을 통해 정산성을 만족한 자료의 ACF와 PACF인 그림 4.25를 이용하여 모형 식별을 시도해 보자. 1시차에서 6시차까지의 패턴으로 비계절 ARIMA 성분을 파악해 보자. ACF는 2시차까지 유의한 값을 보이고 있고, PACF는 1시차는 유의하고, 2시차의 값은 기준이 되는 파란 점선보다 약간 작은 값으로 보인다. 이런 경우에는 둘 중 하나를 절단으로 보든지, 아니면 둘 다 감소로 보는 것이 가능하기 떄문에 AR(1), AR(2), MA(2), 또는 ARMA(1,1) 등이 가능한 것으로 보인다. 계절형 ARIMA 성분은 ACF와 PACF 모두 12시차에서 유의한 값을 보이지만, 24시차와 36시차에서는 매우 작은 값을 보이고 있기 때문에 ACF와 PACF 중 하나를 절단으로 보든지, 둘 다 감소로 보는 것이 가능하며, AR(1)12, MA(1)12, 또는 ARMA(1,1)12 등이 가능한 것으로 보인다. 식별된 비계절형과 계절형을 조합해서 보면, 많은 모형이 가능한 것으로 보인다. ARIMA(1,1,0)(1,1,0)12모형, ARIMA(1,1,0)(0,1,1)12모형, ARIMA(1,1,0)(1,1,1)12모형과 ARIMA(2,1,0)(1,1,0)12모형, ARIMA(2,1,0)(0,1,1)12모형, ARIMA(2,1,0)(1,1,1)12모형, 그리고 ARIMA(1,1,1)(1,1,0)12모형, ARIMA(1,1,1)(0,1,1)12모형, ARIMA(1,1,1)(1,1,1)12모형 등이 가능한 모형으로 보인다. ACF와 PACF를 근거로 직접 모형 식별하는 것은 이렇듯 명확한 결과가 나오는 것이 아니어서, 많은 후보 모형을 식별하고 이어서 그 모형들을 비교하는 과정을 거쳐서 최종 모형을 선택해야 하는 어렵고 긴 작업 절차가 필요한 방법임을 알 수 있다. 따라서 이 과정이 모든 분석에서 반드시 필요하다고 생각하지는 않지만, 함수 auto.arima()로 선택된 모형이 ACF와 PACF를 근거로 식별된 후보 모형 중에 포함되는지 여부는 확인하는 것이 필요하다고 본다. 이제 함수 auto.arima()로 모형을 선택해 보자. fit_K &lt;- auto.arima(train_K, lambda = 0, stepwise = FALSE, approximation = FALSE) summary(fit_K) ## Series: train_K ## ARIMA(2,1,0)(1,1,1)[12] ## Box Cox transformation: lambda= 0 ## ## Coefficients: ## ar1 ar2 sar1 sma1 ## -0.6995 -0.2496 -0.2892 -0.3817 ## s.e. 0.0956 0.0947 0.1695 0.1736 ## ## sigma^2 = 0.002917: log likelihood = 159.82 ## AIC=-309.63 AICc=-309.04 BIC=-296.27 ## ## Training set error measures: ## ME RMSE MAE MPE ## Training set -117.8446 8079.833 5752.686 -0.1325567 ## MAPE MASE ACF1 ## Training set 3.815935 0.3223641 0.1387895 ARIMA(2,1,0)(1,1,1)12모형이 선택되었고, 이 모형은 ACF와 PACF를 근거로 선택한 후보 모형 중에 하나이다. 적합된 모형식은 다음과 같다. \\[ (1+0.69B+0.25B^{2})(1+0.29B^{12})(1-B)(1-B^{12})~\\log y_{t} = (1-0.382^{12})~\\varepsilon_{t} \\] 이제는 ETS 모형을 적합해 보자. ETS 모형에서는 승법모형이 가능하기 때문에 분산안정화를 위한 변환이 반드시 필요한 것은 아니다. 따라서 원자료에 의한 ETS 모형과 로그 변환된 자료의 ETS 모형을 모두 적합시켜 보자. 먼저 로그 변환된 자료를 대상으로 모형을 적합해 보자. fit_K_ets1 &lt;- ets(train_K, lambda = 0) summary(fit_K_ets1) ## ETS(A,Ad,A) ## ## Call: ## ets(y = train_K, lambda = 0) ## ## Box-Cox transformation: lambda= 0 ## ## Smoothing parameters: ## alpha = 0.3998 ## beta = 0.0242 ## gamma = 1e-04 ## phi = 0.978 ## ## Initial states: ## l = 11.3617 ## b = 0.0098 ## s = -0.2089 -0.0012 0.1585 0.0577 0.1123 0.035 ## 0.0516 0.1154 0.0989 0.0121 -0.2092 -0.2221 ## ## sigma: 0.0548 ## ## AIC AICc BIC ## -104.72171 -97.94943 -54.54685 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE ## Training set 1116.089 8322.678 5764.589 0.4909287 3.788076 ## MASE ACF1 ## Training set 0.3230311 0.09314822 ETS(A,Ad,A) 모형이 선택되었다. 이제 원자료를 대상으로 모형을 적합해 보자. fit_K_ets2 &lt;- ets(train_K) summary(fit_K_ets2) ## ETS(M,Ad,M) ## ## Call: ## ets(y = train_K) ## ## Smoothing parameters: ## alpha = 0.4275 ## beta = 0.0306 ## gamma = 1e-04 ## phi = 0.9799 ## ## Initial states: ## l = 89459.3204 ## b = 291.8495 ## s = 0.808 0.9953 1.172 1.0557 1.1073 1.0353 ## 1.0453 1.1046 1.0949 0.9939 0.7992 0.7886 ## ## sigma: 0.0562 ## ## AIC AICc BIC ## 2738.255 2745.028 2788.430 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE ## Training set 1147.204 8155.819 5774.677 0.5763675 3.839131 ## MASE ACF1 ## Training set 0.3235964 0.02357097 ETS(M,Ad,M) 모형이 선택되었다. 두 ETS 모형 모두 추세는 ’damped additive’가 선택되었지만, 로그 변환된 자료에 대해서는 계절 요소와 오차항이 모두 ’additive’이고, 원자료에 대해서는 계절 요소와 오차항이 모두 ’multiplicative’임을 알 수 있다. 이제 적합된 ARIMA 모형과 ETS 모형의 모형 진단을 각각 실시해 보자. 먼저 ARIMA 모형의 경우에는 오차에 대한 가정이 모두 만족되는 것으로 보인다. checkresiduals(fit_K) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(2,1,0)(1,1,1)[12] ## Q* = 27.495, df = 20, p-value = 0.1219 ## ## Model df: 4. Total lags used: 24 ETS 모형의 경우에는 Ljung-Box 검정의 p-value가 매우 작은 값으로 계산되었고, 따라서 오차의 독립성은 만족되지 않았다. 이런 경우에는 ETS 모형으로 예측된 결과에 대한 신빙성이 떨어진다고 볼 수 있는데, 점 예측값보다는 예측 구간에 대한 신뢰도에 더 큰 손상이 있었다고 할 수 있다. 구제적인 검진 결과를 살펴보자. 우선 ETS(A,Ad,A) 모형인 fit_K_ets1 모형의 검진 결과이다. checkresiduals(fit_K_ets1) ## ## Ljung-Box test ## ## data: Residuals from ETS(A,Ad,A) ## Q* = 36.158, df = 7, p-value = 6.769e-06 ## ## Model df: 17. Total lags used: 24 ETS(M,Ad,M) 모형인 fit_K_ets2 모형의 검진 결과도 살펴보자. checkresiduals(fit_K_ets2) ## ## Ljung-Box test ## ## data: Residuals from ETS(M,Ad,M) ## Q* = 34.451, df = 7, p-value = 1.418e-05 ## ## Model df: 17. Total lags used: 24 이제 test data에 대한 예측을 실시하고 예측 오차를 비교해 보자. fc_K &lt;- forecast(fit_K) accuracy(fc_K, test_K) ## ME RMSE MAE MPE ## Training set -117.8446 8079.833 5752.686 -0.1325567 ## Test set -33473.2740 45118.350 37348.980 -12.4581745 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 3.815935 0.3223641 0.1387895 NA ## Test set 13.967241 2.0929303 0.6467465 1.67741 fc_K_ets1 &lt;- forecast(fit_K_ets1) accuracy(fc_K_ets1, test_K) ## ME RMSE MAE MPE ## Training set 1116.089 8322.678 5764.589 0.4909287 ## Test set -26763.496 38813.714 33571.599 -9.9007782 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 3.788076 0.3230311 0.09314822 NA ## Test set 12.507782 1.8812566 0.55156580 1.469369 fc_K_ets2 &lt;- forecast(fit_K_ets2) accuracy(fc_K_ets2, test_K) ## ME RMSE MAE MPE ## Training set 1147.204 8155.819 5774.677 0.5763675 ## Test set -25539.311 37954.952 32640.675 -9.4299420 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 3.839131 0.3235964 0.02357097 NA ## Test set 12.153867 1.8290903 0.54315176 1.439223 큰 차이는 없지만 ETS(M,Ad,M) 모형인 fit_K_ets2 모형의 예측 오차가 조금 더 작은 것으로 나타났다. ARIMA 모형과 ETS(M,Ad,M) 모형의 예측 결과를 그림 4.26의 그래프로 비교해 보자. library(patchwork) p1 &lt;- autoplot(fc_K, include = 24) + autolayer(test_K, color = &quot;red&quot;, size = .8) + ylab(NULL) p2 &lt;- autoplot(fc_K_ets2, include = 24) + autolayer(test_K, color = &quot;red&quot;, size = .8) + ylab(NULL) p1 / p2 그림 4.26: 국내 입국 관광객 수 자료에 대한 예측 결과 "],["chapter-regression.html", "5 장 회귀모형 ARMA 오차 회귀모형 ARMA 오차 Dynamic 회귀모형", " 5 장 회귀모형 library(fpp2) library(tidyverse) ARMA 오차 회귀모형 예제 : 분기별 호주 맥주 생산량 자료 (fpp2::ausbeer) 1. 백색잡음오차 시계열 회귀모형 적합 ausbeer는 1956년 1분기부터 2010년 2분기까지 호주의 분기별 맥주 생산량이다. 전체 기간 중 1975년 1분기 이후 자료에 대한 회귀모형을 적합시켜보자. 마지막 2년 자료는 test data로 남겨두자. train_b &lt;- window(ausbeer, start = 1975, end = c(2008, 2)) test_b &lt;- window(ausbeer, start = c(2008, 3)) 그림 5.1은 전체 자료의 시계열 그래프이다. Test data는 빨간 색으로 구분했다. 그림 5.1: 자료 ausbeer의 시계열 그래프 시계열자료에 대한 회귀모형의 적합은 함수 tslm()으로 할 수 있다. 함수 tslm()은 lm()과 실질적으로 동일한 함수지만, ts 객체에 대한 회귀모형 적합을 위한 함수이다. 잔차 및 적합값이 ts 객체로 생성되고, 결측값 처리 방식이 시계열자료에 적합하도록 설정되었다. 추세 변수와 계절 변수를 시점 \\(t\\)를 이용하여 생성하는 방법을 살펴보자. 먼저 추세 변수는 함수 time()으로 자료가 관측된 시점을 생성할 수 있다. 자료 train_b에 대해 함수 time()을 적용한 결과를 살펴보자. 1975년 1분기 값을 1975.00으로 두고, 1/4 간격으로 다음 분기의 관측 시점을 생성하고 있다. time(train_b)[1:9] ## [1] 1975.00 1975.25 1975.50 1975.75 1976.00 1976.25 1976.50 ## [8] 1976.75 1977.00 관측 시점을 \\(t = 1, 2, 3, \\ldots\\) 로 하여 사용하고자 한다면, 1:length(train_b)를 추세 변수로 사용하거나, 함수 tslm()에서 trend를 추세 변수로 사용하면 된다. 계절 변수로 dummy 변수를 사용한다면 함수 forecast::seasonaldummy()를 사용하거나, 함수 tslm()에서 season을 변수로 사용하면 된다. 계절 주기에 맞추어 필요한 dummy 변수를 생성한다. seasonaldummy(train_b)[1:5,] ## Q1 Q2 Q3 ## [1,] 1 0 0 ## [2,] 0 1 0 ## [3,] 0 0 1 ## [4,] 0 0 0 ## [5,] 1 0 0 Fourier series 변수를 사용한다면 함수 forecast::fourier()를 사용하면 된다. 모형에 포함되는 fourier series 변수들의 최대 주기는 옵션 K에 지정하면 된다. fourier(train_b, K = 2)[1:5,] ## S1-4 C1-4 C2-4 ## [1,] 1 0 -1 ## [2,] 0 -1 1 ## [3,] -1 0 -1 ## [4,] 0 1 1 ## [5,] 1 0 -1 S1-4와 C1-4는 \\(K=1\\) 에 해당하는 \\(\\sin(2\\pi t/4)\\) 와 \\(\\cos(2\\pi t/4)\\) 를 의미하고, C2-4는 \\(K=2\\) 에 해당하는 \\(\\cos(2\\pi 2t/4)\\) 를 나타내고 있다. 함수 time()에 의한 추세 변수와 seasonaldummy()에 의한 계절 변수를 사용하여 회귀모형을 적합해 보고, 그 결과를 확인해 보자. fit1 &lt;- tslm(train_b ~ time(train_b) + seasonaldummy(train_b)) summary(fit1) ## ## Call: ## tslm(formula = train_b ~ time(train_b) + seasonaldummy(train_b)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -47.776 -11.771 -0.738 10.842 63.468 ## ## Coefficients: ## Estimate Std. Error t value ## (Intercept) 5335.5613 325.0641 16.41 ## time(train_b) -2.4112 0.1632 -14.78 ## seasonaldummy(train_b)Q1 -74.4299 4.4641 -16.67 ## seasonaldummy(train_b)Q2 -118.3271 4.4639 -26.51 ## seasonaldummy(train_b)Q3 -105.7240 4.4973 -23.51 ## Pr(&gt;|t|) ## (Intercept) &lt;2e-16 *** ## time(train_b) &lt;2e-16 *** ## seasonaldummy(train_b)Q1 &lt;2e-16 *** ## seasonaldummy(train_b)Q2 &lt;2e-16 *** ## seasonaldummy(train_b)Q3 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 18.27 on 129 degrees of freedom ## Multiple R-squared: 0.8911, Adjusted R-squared: 0.8877 ## F-statistic: 263.9 on 4 and 129 DF, p-value: &lt; 2.2e-16 이번에는 변수 trend와 season을 사용해서 적합해 보고, 결과를 확인해 보자. fit2 &lt;- tslm(train_b ~ trend + season) summary(fit2) ## ## Call: ## tslm(formula = train_b ~ trend + season) ## ## Residuals: ## Min 1Q Median 3Q Max ## -47.776 -11.771 -0.738 10.842 63.468 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 499.6812 4.1577 120.181 &lt; 2e-16 *** ## trend -0.6028 0.0408 -14.775 &lt; 2e-16 *** ## season2 -43.8972 4.4306 -9.908 &lt; 2e-16 *** ## season3 -31.2941 4.4639 -7.011 1.19e-10 *** ## season4 74.4299 4.4641 16.673 &lt; 2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 18.27 on 129 degrees of freedom ## Multiple R-squared: 0.8911, Adjusted R-squared: 0.8877 ## F-statistic: 263.9 on 4 and 129 DF, p-value: &lt; 2.2e-16 fit1과 fit2의 적합 결과가 서로 다른 것처럼 보인다. 그러나 추세의 기울기가 다른 것은 모형에서 사용된 추세 변수의 간격이 다르기 때문이다. 즉, 두 모형의 추세 기울기가 4배 차이 나는 이유는 모형 fit1에서 사용된 추세 변수의 간격이 1/4인 반면에 모형 fit2에서 사용된 추세 변수의 간격은 1이기 때문이다. 또한 절편이 다른 것은 두 모형의 기준 범주가 다르며, 사용된 추세 변수의 범위가 다르기 때문이다. 즉, fit1에서 사용된 추세 변수는 1975.00부터 값을 갖고 있지만, fit2에서는 추세 변수가 1부터 값을 갖고 있으며, 함수 seasonaldummy()는 마지막 범주를 기준 범주로 설정하는데, 변수 season은 첫 번째 범주를 기준 범주로 설정하고 있어서, dummy 변수의 구성도 다르게 된다. 두 모형의 적합값을 비교해 보면 실질적으로 같은 모형임을 알 수 있다. tibble(fit1 = fit1$fitted, fit2 = fit2$fitted) ## # A tibble: 134 × 2 ## fit1 fit2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 499. 499. ## 2 455. 455. ## 3 467. 467. ## 4 572. 572. ## 5 497. 497. ## 6 452. 452. ## 7 464. 464. ## 8 569. 569. ## 9 494. 494. ## 10 450. 450. ## # … with 124 more rows 이번에는 함수 time()에 의한 추세 변수와 fourier()에 의한 Fourier series 변수를 사용하여 회귀모형을 적합해 보고, 그 결과를 확인해 보자. 분기별 자료의 최대 주기인 K=2를 지정해서 확인해 보자. fit3 &lt;- tslm(train_b ~ time(train_b) + fourier(train_b, K=2)) summary(fit3) ## ## Call: ## tslm(formula = train_b ~ time(train_b) + fourier(train_b, K = 2)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -47.776 -11.771 -0.738 10.842 63.468 ## ## Coefficients: ## Estimate Std. Error t value ## (Intercept) 5260.9410 325.0320 16.186 ## time(train_b) -2.4112 0.1632 -14.775 ## fourier(train_b, K = 2)S1-4 15.6471 2.2319 7.011 ## fourier(train_b, K = 2)C1-4 59.1635 2.2319 26.508 ## fourier(train_b, K = 2)C2-4 15.4567 1.5784 9.793 ## Pr(&gt;|t|) ## (Intercept) &lt; 2e-16 *** ## time(train_b) &lt; 2e-16 *** ## fourier(train_b, K = 2)S1-4 1.19e-10 *** ## fourier(train_b, K = 2)C1-4 &lt; 2e-16 *** ## fourier(train_b, K = 2)C2-4 &lt; 2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 18.27 on 129 degrees of freedom ## Multiple R-squared: 0.8911, Adjusted R-squared: 0.8877 ## F-statistic: 263.9 on 4 and 129 DF, p-value: &lt; 2.2e-16 Fourier series의 모든 변수를 사용한 모형은 dummy 변수를 사용한 모형과 실질적으로 동일한 모형이 된다. fit1과 fit3의 적합값을 비교해 보자. tibble(fit1 = fit1$fitted, fit3 = fit3$fitted) ## # A tibble: 134 × 2 ## fit1 fit3 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 499. 499. ## 2 455. 455. ## 3 467. 467. ## 4 572. 572. ## 5 497. 497. ## 6 452. 452. ## 7 464. 464. ## 8 569. 569. ## 9 494. 494. ## 10 450. 450. ## # … with 124 more rows 시계열자료 회귀모형의 모형 진단을 실시해서, 가정 만족에 문제가 있는지 확인해 보자. 함수 checkresiduals()는 lm() 또는 tslm()으로 생성된 객체에 대해서 Breusch-Godfrey 검정으로 독립성을 확인한다. 검정 결과는 오차가 독립이 아니라는 결론이며, 잔차의 시계열 그래프와 ACF에서도 같은 모습을 확인할 수 있다. 시계열자료에 회귀모형을 적합해 생성된 잔차 사이에는 강한 상관 관계가 존재하고 있음을 확인할 수 있었다. 이것은 설명이 안 된 패턴이 남아 있음을 의미하는 것이며, 따라서 추가적인 작업이 필요한 것이다. checkresiduals(fit1) ## ## Breusch-Godfrey test for serial correlation of order ## up to 8 ## ## data: Residuals from Linear regression model ## LM test = 30.158, df = 8, p-value = 0.0001982 2. ARMA 오차 시계열 회귀모형 적합 자료 ausbeer에 대해 적합된 백색잡음 회귀모형은 잔차가 독립성을 만족하지 못하는 문제가 발견되었다. 잔차에 남아 있는 패턴을 ARMA 모형으로 설명하기 위해 ARMA 오차 회귀모형을 적합시켜보자. train_b &lt;- window(ausbeer, start = 1975, end = c(2008, 2)) test_b &lt;- window(ausbeer, start = c(2008, 3)) fit4 &lt;- auto.arima(train_b, xreg = cbind(Time = time(train_b), Qtr = seasonaldummy(train_b)), stepwise = FALSE) fit4 ## Series: train_b ## Regression with ARIMA(3,0,0)(1,0,0)[4] errors ## ## Coefficients: ## ar1 ar2 ar3 sar1 intercept Time ## -0.1233 0.1645 0.2440 0.4155 5227.3160 -2.3573 ## s.e. 0.0852 0.0831 0.0849 0.0817 611.6432 0.3071 ## Qtr.Q1 Qtr.Q2 Qtr.Q3 ## -73.4170 -117.2944 -105.5713 ## s.e. 6.0565 5.2917 6.0999 ## ## sigma^2 = 264.2: log likelihood = -559.59 ## AIC=1139.19 AICc=1140.97 BIC=1168.16 잔차에 가장 적합한 모형은 ARIMA(3,0,0)(1,0,0)4가 선택되었다. 즉, 잔차에 비계절형 요소 뿐 아니라 계절형 요소도 남아 있다는 것이다. ARMA 오차 회귀모형 fit4에 대한 모형 진단을 실시해 보자. 모든 가정이 만족되고 있음을 알 수 있다. checkresiduals(fit4) ## ## Ljung-Box test ## ## data: Residuals from Regression with ARIMA(3,0,0)(1,0,0)[4] errors ## Q* = 0.64935, df = 4, p-value = 0.9574 ## ## Model df: 4. Total lags used: 8 ARMA 오차 회귀모형의 예측은 함수 forecast()로 할 수 있다. 사용법은 forecast(object, xreg, ...)가 되는데, object에는 함수 Arima() 혹은 auto.arima()로 생성된 객체를 지정하고, xreg에는 예측 시점에 대한 설명변수의 자료를 벡터 또는 행렬의 형태로 지정하면 된다. Test data인 test_b에 대한 예측을 실시해 보자. fc4 &lt;- forecast(fit4, xreg = cbind(Time = time(test_b), Qtr = seasonaldummy(test_b))) ARMA 오차 회귀모형의 예측 결과와 백색잡음 회귀모형의 예측 결과를 비교해 보자. 함수 tslm()에 변수 trend와 season을 사용한 fit2에 대한 예측은 다음과 같이 실시할 수 있다. fit2 &lt;- tslm(train_b ~ trend + season) fc2 &lt;- forecast(fit2, h = length(test_b)) 점 예측 결과는 fc2$mean과 fc4$mean에 할당되어 있다. 두 결과를 비교해 보자. 큰 차이는 없는 것으로 보인다. tibble(fc2 = fc2$mean, fc4 = fc4$mean) ## # A tibble: 8 × 2 ## fc2 fc4 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 387. 383. ## 2 492. 485. ## 3 417. 420. ## 4 373. 378. ## 5 385. 384. ## 6 490. 487. ## 7 415. 416. ## 8 370. 373. 95% 예측 구간의 폭을 비교해 보자. 예측 구간의 상한은 fc2$upper과 fc4$upper에 할당되었고, 하한은 fc2$lower과 fc4$lower에 각각 할당되어 있다. 예측 구간의 신뢰수준으로 80%와 95%가 사용되는 것이 디폴트이며, 따라서 다음과 같이 95% 예측 구간의 폭을 계산할 수 있다. ARMA 오차 회귀모형의 예측 구간인 fc4의 폭이 더 좁은 것을 확인할 수 있다. tibble(fc2 = fc2$upper[,2] - fc2$lower[,2], fc4 = fc4$upper[,2] - fc4$lower[,2]) ## # A tibble: 8 × 2 ## fc2 fc4 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 74.2 63.7 ## 2 74.2 64.2 ## 3 74.2 65.2 ## 4 74.2 66.5 ## 5 74.3 71.0 ## 6 74.3 71.0 ## 7 74.3 71.3 ## 8 74.3 71.5 예측 오차의 크기를 비교해 보자. 예측 오차의 크기에는 큰 차이가 없음을 알 수 있다. accuracy(fc2, test_b) ## ME RMSE MAE MPE ## Training set 8.491860e-16 17.92314 13.57971 -0.1317235 ## Test set 9.745836e+00 17.30833 11.90530 2.4185316 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 2.924979 0.8311500 0.007149994 NA ## Test set 2.886254 0.7286673 0.048860146 0.3056324 accuracy(fc4, test_b) ## ME RMSE MAE MPE ## Training set 0.1677325 15.69822 12.11679 -0.07293605 ## Test set 10.0161277 17.40591 11.67960 2.42511984 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 2.618274 0.7416116 0.004529308 NA ## Test set 2.826267 0.7148528 0.049644862 0.2895782 예측 결과를 그래프로 나타내서 비교해 보자. library(patchwork) p1 &lt;- autoplot(fc2, include=8) + autolayer(test_b, color = &quot;red&quot;, size=.8) + labs(y = NULL, x = NULL) p2 &lt;- autoplot(fc4, include=8) + autolayer(test_b, color = &quot;red&quot;, size=.8) + labs(y = NULL, x = NULL) p1 + p2 그림 5.2: ausbeer 자료에 대한 예측 결과 예제: 1970년 1월부터 2005년 12월까지 지구 기온 자료 (global.txt) global.txt는 1856년 1월부터 2005년 12월까지의 지구 기온 자료 자료인데, 그 중 1970년 이후 자료만을 대상으로 ARMA 오차 회귀모형과 ARIMA 모형, 그리고 ETS 모형으로 예측 모형을 각각 적합시키고 예측 결과를 비교해 보자. 자료를 불러 들이고 training data와 test data로 분리시키자. global &lt;- scan(&quot;https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/global.txt&quot;) global.ts &lt;- ts(global, start = c(1856, 1), frequency = 12) train_g &lt;- window(global.ts, start = 1970, end = c(2003,12)) test_g &lt;- window(global.ts, start = 2004) 그림 5.3은 1970년부터 자료의 시계열 그래프이다. Test data는 빨간 색으로 구분했다. autoplot(train_g) + autolayer(test_g, color = &quot;red&quot;, size = .8) + labs(x = NULL, y = NULL) 그림 5.3: 자료 global.txt의 training data와 test data의 시계열 그래프 1. ARMA 오차 회귀모형 적합 계절 성분이 있는 시계열자료에 회귀모형을 적용할 때에는 계절 성분을 dummy 변수로 나타낼 것인지, Fourier series 변수로 나타낼 것인지를 선택해야 한다. 먼저 선형 추세와 dummy 변수를 사용한 회귀모형을 적합시켜 보자. 추세 변수는 함수 time()으로 생성하고, 계절 변수는 함수 seasonaldummy()로 생성한다. Time &lt;- time(train_g) Month &lt;- seasonaldummy(train_g) 모형 fit1의 적합 과정에서 stepwise = FASLE와 approximation = FALSE를 제외했는데, 두 옵션을 추가해도 같은 결과를 얻게 된다. fit1 &lt;- auto.arima(train_g, xreg = cbind(Time, Month)) summary(fit1) ## Series: train_g ## Regression with ARIMA(2,0,0) errors ## ## Coefficients: ## ar1 ar2 intercept Time Month.Jan ## 0.4932 0.3204 -34.5510 0.0175 0.0409 ## s.e. 0.0469 0.0472 4.2613 0.0021 0.0161 ## Month.Feb Month.Mar Month.Apr Month.May Month.Jun ## 0.0522 0.0268 0.0250 0.0093 0.0162 ## s.e. 0.0171 0.0195 0.0204 0.0211 0.0213 ## Month.Jul Month.Aug Month.Sep Month.Oct Month.Nov ## 0.0137 0.0151 0.0002 -0.015 -0.0304 ## s.e. 0.0211 0.0204 0.0194 0.017 0.0160 ## ## sigma^2 = 0.007112: log likelihood = 437.21 ## AIC=-842.41 AICc=-841.02 BIC=-778.23 ## ## Training set error measures: ## ME RMSE MAE MPE ## Training set -0.0007778394 0.08276884 0.06379682 22.62755 ## MAPE MASE ACF1 ## Training set 81.57672 0.4285951 0.006984407 잔차는 AR(2) 모형으로 적합되었다. 이번에는 선형 추세와 Fourier series 변수를 사용한 회귀모형을 적합시켜 보자. Fourier series 변수를 사용하기 위해서는 최적 주기를 결정해야 한다. Time &lt;- time(train_g) res &lt;- vector(&quot;numeric&quot;, 6) for(i in seq(res)){ xreg &lt;- cbind(Time, fourier(train_g, K = i)) fit &lt;- auto.arima(train_g, xreg = xreg) res[i] &lt;- fit$aicc } 객체 res에는 6개 모형의 AICc가 입력되어 있다. 그 중 두 번째 모형의 AICc가 가장 작은 값임을 확인할 수 있다. res ## [1] -840.8765 -851.6310 -850.3429 -846.7538 -842.5771 ## [6] -841.0206 (k_min &lt;- which.min(res)) ## [1] 2 이제 \\(K=2\\) 를 최적 주기로 하는 Fourier series 변수를 사용한 회귀모형을 적합시켜 보자. Fourier &lt;- fourier(train_g, K = k_min) fit2 &lt;- auto.arima(train_g, xreg = cbind(Time, Fourier)) summary(fit2) ## Series: train_g ## Regression with ARIMA(2,0,0) errors ## ## Coefficients: ## ar1 ar2 intercept Time Fourier.S1-12 ## 0.4919 0.3200 -34.4729 0.0174 0.0210 ## s.e. 0.0469 0.0472 4.2484 0.0021 0.0088 ## Fourier.C1-12 Fourier.S2-12 Fourier.C2-12 ## -0.0047 0.0192 -0.0054 ## s.e. 0.0087 0.0051 0.0051 ## ## sigma^2 = 0.007062: log likelihood = 435.04 ## AIC=-852.08 AICc=-851.63 BIC=-815.98 ## ## Training set error measures: ## ME RMSE MAE MPE ## Training set -0.0007984029 0.08320983 0.0640202 22.23643 ## MAPE MASE ACF1 ## Training set 80.56552 0.4300958 0.004973903 fit1의 경우와 동일하게 fit2에서도 잔차는 AR(2) 모형으로 적합되었다. 두 모형의 검진을 실시해 보자. 먼저 선형 추세와 dummy 변수를 사용한 회귀모형인 모형 fit1의 모형 검진을 진행해 보자. 모형 fit1의 경우에는 가정 만족에 큰 문제가 없는 것으로 보인다. checkresiduals(fit1) ## ## Ljung-Box test ## ## data: Residuals from Regression with ARIMA(2,0,0) errors ## Q* = 27.817, df = 22, p-value = 0.1818 ## ## Model df: 2. Total lags used: 24 선형 추세와 Fourier series 변수를 사용한 회귀모형인 모형 fit2의 모형 검진도 진행해 보자. 모형 fit2에도 큰 문제 없이 가정을 만족하고 있음을 알 수 있다. checkresiduals(fit2) ## ## Ljung-Box test ## ## data: Residuals from Regression with ARIMA(2,0,0) errors ## Q* = 27.53, df = 22, p-value = 0.1918 ## ## Model df: 2. Total lags used: 24 이제 두 회귀모형 중 한 모형을 선택해 보자. 선택 기준으로는 AICc를 사용해 보자. c(fit1$aicc, fit2$aicc) ## [1] -841.0206 -851.6310 모형 fit2의 AICc가 더 작게 계산되었고, 따라서 최종 예측 모형으로 선택하자. fit_reg &lt;- fit2 2. ARIMA 모형의 적합 차분 및 계절 차분이 필요한지 여부를 확인해 보자. ggtsdisplay(train_g) 뚜렷한 추세가 시계열 그래프에서 보이며, 표본 ACF 그래프에서 매우 큰 값의 \\(r_{1}\\) 과 천천히 감소하는 모습에서 1차 차분이 필요한 것을 알 수 있다. 그러나 계절 차분이 필요한지 여부는 명확하게 보이지 않는다. 단위근 검정 결과를 확인해 보자. ndiffs(train_g) ## [1] 1 nsdiffs(train_g) ## [1] 0 1차 차분은 필요하지만, 계절 차분은 필요 없는 것로 나타났다. 이제 1차 차분을 실시한 자료를 대상으로 시계열 그래프와 ACF, PACF를 작성해 보자. 정상성이 만족된 것으로 보인다. train_g %&gt;% diff() %&gt;% ggtsdisplay() 이제 잔차의 표본 ACF와 PACF를 이용해서 모형 식별을 시도해 보자. 비계절 요소는 1시차에서 6시차까지의 패턴으로 인식하게 되는데, ACF는 3시차까지 모두 유의하고, PACF는 1시차와 3시차가 유의한 것으로 나타났다. 이러한 경우에는 ACF를 감소, PACF는 감소 또는 3시차에서 절단으로 볼 수 있으며, 따라서 ARMA 모형이나 AR 모형이 가능할 것으로 보인다. 계절형 요소는 12, 24, 36시차에서 ACF와 PACF가 모두 매우 작은 값을 갖고 있기 때문에, 계절형 요소가 없는 것으로 볼 수도 있고, AR(1)12 또는 MA(1)12로 볼 수도 있는 상황이다. 함수 auto.arima()를 사용해서 AICc가 가장 작은 모형을 찾아 보자. fit_arima &lt;- auto.arima(train_g, stepwise = FALSE, approximation = FALSE) fit_arima ## Series: train_g ## ARIMA(2,1,1) ## ## Coefficients: ## ar1 ar2 ma1 ## 0.5198 0.3008 -0.9703 ## s.e. 0.0498 0.0492 0.0132 ## ## sigma^2 = 0.007576: log likelihood = 417.27 ## AIC=-826.55 AICc=-826.45 BIC=-810.51 적합 결과는 비계절형 요소만 있는 ARIMA(2,1,1)이 선택된 것을 알 수 있다. 모형 fit_arima에 대한 검진을 실시해 보자. 모든 가정이 만족되고 있음을 볼 수 있다. checkresiduals(fit_arima) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(2,1,1) ## Q* = 30.228, df = 21, p-value = 0.08751 ## ## Model df: 3. Total lags used: 24 3. ETS 모형의 적합 함수 ets()로 AICc가 최소인 모형을 선택해 보자. fit_ets &lt;- ets(train_g) 최적 모형은 ETS(A,N,N)이 선택되었다. fit_ets ## ETS(A,N,N) ## ## Call: ## ets(y = train_g) ## ## Smoothing parameters: ## alpha = 0.5868 ## ## Initial states: ## l = 0.0782 ## ## sigma: 0.0885 ## ## AIC AICc BIC ## 478.0785 478.1379 490.1123 모형 fit_ets에 대한 검진을 실시해 보자. checkresiduals(fit_ets) ## ## Ljung-Box test ## ## data: Residuals from ETS(A,N,N) ## Q* = 39.376, df = 22, p-value = 0.01277 ## ## Model df: 2. Total lags used: 24 독립성 가정에 문제가 있는 것으로 나타났다. 독립성 가정을 만족시키지 못하는 모형의 경우에는 예측의 신빙성에 문제가 있을 수 있는데, 점 예측 (point forecast) 결과보다 예측 구간에 더 큰 문제가 있을 수 있다. 간혹 모든 가정을 만족시키는 모형을 찾지 못하는 경우도 있는데, 이런 경우에는 예측 결과를 적용할 때 조심할 필요가 있다. 이제 세 가지 모형인 fit_reg, fit_arima, fit_ets에 의한 예측을 실시하고, 결과를 비교해 보자. new_reg &lt;- cbind(Time = time(test_g), Fourier = fourier(test_g, K = k_min)) fc_reg &lt;- forecast(fit_reg, xreg = new_reg) fc_arima &lt;- forecast(fit_arima, h = length(test_g)) fc_ets &lt;- forecast(fit_ets, h = length(test_g)) 예측 오차를 비교해 보자. accuracy(fc_reg, test_g) ## ME RMSE MAE MPE ## Training set -0.0007984029 0.08320983 0.06402020 22.236428 ## Test set -0.0266870191 0.09047869 0.06864433 -9.691571 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 80.56552 0.4300958 0.004973903 NA ## Test set 17.39724 0.4611613 0.300995351 1.015694 accuracy(fc_arima, test_g) ## ME RMSE MAE MPE ## Training set 0.006369769 0.08661271 0.06601014 24.330149 ## Test set 0.004650257 0.08557693 0.07319499 -2.829173 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 79.34066 0.4434645 0.003457635 NA ## Test set 17.33066 0.4917332 0.335253668 0.9396727 accuracy(fc_ets, test_g) ## ME RMSE MAE MPE ## Training set 0.001901676 0.08829198 0.06862716 20.00303 ## Test set -0.062218811 0.10436651 0.07564587 -17.55797 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 84.32056 0.4610460 -0.01131321 NA ## Test set 19.80559 0.5081986 0.26877094 1.191604 Test data에 대한 예측 결과를 비교해 보면, 전체적으로 큰 차이는 없는 것으로 보인다. MASE로는 ARMA 오차 회귀모형이 ARIMA 모형 보다 조금 작은 값을 보이고 있으나, RMSE와 MAPE로는 ARIMA 모형이 조금 작은 값을 보이고 있다. 예측 결과를 test data와 함께 표시한 그래프는 그림 5.4에서 볼 수 있다. 예측 구간의 폭을 비교할 수 있도록 세 그래프의 Y축 구간은 동일하게 설정하였다. library(patchwork) y_lim &lt;- c(-.06, 1.06) p1 &lt;- autoplot(fc_reg, include = 12) + autolayer(test_g, color = &quot;red&quot;, size = .8) + labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2]) p2 &lt;- autoplot(fc_arima, include = 12) + autolayer(test_g, color = &quot;red&quot;, size = .8) + labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2]) p3 &lt;- autoplot(fc_ets, include=12) + autolayer(test_g, color = &quot;red&quot;, size = .8) + labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2]) p1 / p2 / p3 그림 5.4: 자료 global.txt에 대한 세 모형의 예측 결과 예제: 1949년부터 1960년 월별 국제선 탑승자 수 자료 (AirPassengers) AirPassengers는 1949년 1월부터 1960년 12월까지 월별 국제선 탑승자 수 자료이다. ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형에 의한 예측 모형을 적합시키고, 예측 결과를 비교해 보자. 예측 결과의 평가를 위해 마지막 2년 자료는 test data로 남겨두자. train_AP &lt;- window(AirPassengers, end = c(1958, 12)) test_AP &lt;- window(AirPassengers, start = c(1959, 1)) 전체 기간에 대한 시계열 그래프를 그림 5.5에 작성해 보자. Test data는 빨간 색으로 구분하였다. autoplot(train_AP) + autolayer(test_AP, color = &quot;red&quot;, size = .8) + labs(x = NULL, y = NULL) 그림 5.5: 자료 AirPassengers의 시계열 그래프 증가 추세가 있고, 명확한 계절 성분이 있는 자료이다. 또한 계절 변동 폭이 추세가 증가함에 따라 점점 커지고 있음도 알 수 있다. 따라서 분산 안정화가 필요한 자료이다. 분산 안정화를 위해 Box-Cox 변환 모수를 추정해 보자. (lam &lt;- BoxCox.lambda(train_AP)) ## [1] -0.3096628 변환 모수가 \\(\\lambda=-0.31\\) 로 추정되었다. 추정된 변환 모수에 의한 변환 결과와 로그 변환에 의한 결과를 비교해 보자. 그림 5.6에서 볼 수 있듯이 두 변환 결과는 크게 차이가 나지 않는 것으로 보인다. 이런 경우에는 변환 결과에 대한 해석이 가능한 로그 변환을 선택하는 것이 일반적이라고 하겠다. library(patchwork) p1 &lt;- BoxCox(train_AP, lambda = lam) %&gt;% autoplot() + labs(title = paste(&quot;Box-Cox&quot;, &quot;lambda = &quot;, signif(lam, 3)), x = NULL) p2 &lt;- train_AP %&gt;% log() %&gt;% autoplot() + labs(title = &quot;Log&quot;, x = NULL) p1+p2 그림 5.6: 분산 안정화 변환 1. ETS 모형 적합 ETS 모형은 계절 성분을 승법 형태로 설명할 수 있는 모형이기 때문에, 계절 성분의 진폭 안정화가 반드시 필요한 모형은 아니다. 또한 모수에 대한 해석보다 예측이 주된 용도이기 때문에, 분산 안정화 변환 결과에 대한 해석이 그렇게 중요한 요소가 되지 않는다. 따라서 원자료에 대한 ETS 모형과 Box-Cox 변환 자료에 대한 ETS 모형, 그리고 로그 변환 자료에 대한 ETS 모형을 각각 적합하고 예측 결과를 비교해 보자. ets_1 &lt;- ets(train_AP, lambda = lam) ets_fc1 &lt;- forecast(ets_1, h = length(test_AP)) ets_2 &lt;- ets(train_AP, lambda = 0) ets_fc2 &lt;- forecast(ets_2, h = length(test_AP)) ets_3 &lt;- ets(train_AP) ets_fc3 &lt;- forecast(ets_3, h = length(test_AP)) 그림 5.7는 세 가지 ETS 모형의 예측 결과를 test data와 함께 나타낸 그래프이다. Box-Cox 변환 자료에 대한 ETS 모형의 예측 결과가 test data와 가장 근접한 것으로 보인다. Test data를 이용해서 모형을 선택하는 것이 바람직한 방식은 아니지만, 모형 비교를 위한 다른 마땅한 방법이 없는 상황을 고려하였다. 그림 5.7: AirPassengers 자료에 대한 ETS 모형의 예측 결과 비교 Box-Cox 변환 자료에 대한 ETS 모형을 최적 ETS 모형으로 선택하고, 모형 진단을 실시해 보자. 독립성 가정은 위반하는 것으로 나타났다. fit_ets &lt;- ets(train_AP, lambda = lam) checkresiduals(fit_ets) ## ## Ljung-Box test ## ## data: Residuals from ETS(A,A,A) ## Q* = 39.722, df = 8, p-value = 3.61e-06 ## ## Model df: 16. Total lags used: 24 2. ARMA 오차 회귀모형 적합 회귀모형은 분산 안정화가 필수적인 모형이며, 변환 결과에 대한 해석도 필요한 모형이다. 따라서 로그 변환된 자료를 대상으로 모형 적합을 진행해 보자. 계절 성분을 dummy 변수로 나타내는 모형을 적합해 보자. Time &lt;- time(train_AP) Month &lt;- seasonaldummy(train_AP) fit_r1 &lt;- auto.arima(train_AP, xreg = cbind(Time, Month), lambda = 0) stepwise = FALSE를 포함시키면 실행 시간이 지나치게 오래 걸리기 때문에 제외했다. 적합 결과를 살펴보자. fit_r1 ## Series: train_AP ## Regression with ARIMA(1,0,0)(0,0,1)[12] errors ## Box Cox transformation: lambda= 0 ## ## Coefficients: ## ar1 sma1 intercept Time Month.Jan ## 0.7766 0.1651 -236.9229 0.124 0.0127 ## s.e. 0.0674 0.0994 9.7959 0.005 0.0133 ## Month.Feb Month.Mar Month.Apr Month.May Month.Jun ## 0.0017 0.1369 0.0956 0.0872 0.2124 ## s.e. 0.0173 0.0198 0.0212 0.0220 0.0223 ## Month.Jul Month.Aug Month.Sep Month.Oct Month.Nov ## 0.3096 0.3018 0.1660 0.0254 -0.1166 ## s.e. 0.0219 0.0211 0.0195 0.0170 0.0128 ## ## sigma^2 = 0.001265: log likelihood = 237.46 ## AIC=-442.92 AICc=-437.64 BIC=-398.32 잔차에 계절형과 비계절형 요소가 모두 남아 있는 것을 알 수 있다. 모형 검진을 실시해 보자. 큰 문제는 없는 것으로 보인다. checkresiduals(fit_r1) ## ## Ljung-Box test ## ## data: Residuals from Regression with ARIMA(1,0,0)(0,0,1)[12] errors ## Q* = 21.798, df = 22, p-value = 0.472 ## ## Model df: 2. Total lags used: 24 이번에는 Fourier series 변수를 사용한 회귀모형을 적합해 보자. 먼저 최적 차수를 확인하자. Time &lt;- time(train_AP) res &lt;- vector(&quot;numeric&quot;, 6) for(i in seq(res)){ xreg &lt;- cbind(Time, fourier(train_AP, K = i)) fit &lt;- auto.arima(train_AP, xreg = xreg, lambda = 0) res[i] &lt;- fit$aicc } (min_k &lt;- which.min(res)) ## [1] 5 \\(K=5\\) 가 최적 차수로 확인되었다. 최적 차수에 의한 Fourier series 변수를 사용한 회귀모형을 적합하고 결과를 확인해 보자. Time &lt;- time(train_AP) Fourier &lt;- fourier(train_AP, K = min_k) fit_r2 &lt;- auto.arima(train_AP, xreg = cbind(Time, Fourier), lambda = 0) summary(fit_r2) ## Series: train_AP ## Regression with ARIMA(2,0,0)(1,0,0)[12] errors ## Box Cox transformation: lambda= 0 ## ## Coefficients: ## ar1 ar2 sar1 intercept Time ## 0.6384 0.1782 0.2060 -233.8237 0.1224 ## s.e. 0.0910 0.0964 0.1057 12.3191 0.0063 ## Fourier.S1-12 Fourier.C1-12 Fourier.S2-12 ## -0.0464 -0.1379 0.0773 ## s.e. 0.0090 0.0090 0.0051 ## Fourier.C2-12 Fourier.S3-12 Fourier.C3-12 ## -0.0259 -0.0107 0.0264 ## s.e. 0.0051 0.0039 0.0039 ## Fourier.S4-12 Fourier.C4-12 Fourier.S5-12 ## 0.0245 0.0261 0.0206 ## s.e. 0.0036 0.0036 0.0036 ## Fourier.C5-12 ## 0.0060 ## s.e. 0.0036 ## ## sigma^2 = 0.001256: log likelihood = 237.75 ## AIC=-443.49 AICc=-438.21 BIC=-398.89 ## ## Training set error measures: ## ME RMSE MAE MPE ## Training set 0.1302685 8.156184 6.052862 -0.05051831 ## MAPE MASE ACF1 ## Training set 2.597827 0.2118306 0.09399082 잔차에 계절형과 비계절형 요소가 모두 남아 있는 것을 알 수 있다. 모형 검진을 실시해 보자. 큰 문제가 없는 것으로 보인다. checkresiduals(fit_r2) ## ## Ljung-Box test ## ## data: Residuals from Regression with ARIMA(2,0,0)(1,0,0)[12] errors ## Q* = 17.88, df = 21, p-value = 0.6566 ## ## Model df: 3. Total lags used: 24 이제 두 모형 중 한 모형을 최적 모형으로 선택해야 한다. 사실 두 모형은 거의 동일한 모형이다. 두 번째 모형이 11개의 Fourier series 변수 중 10개 사용한 모형이기 때문인데, 만일 \\(K=6\\) 이 선택되어 11개의 Fourier series 변수를 모두 사용한다면 dummy 변수를 사용한 모형과 사실상 동일한 모형이 된다. 두 모형의 AICc를 근거로 한 모형을 선택해 보자. c(fit_r1$aicc, fit_r2$aicc) ## [1] -437.6420 -438.2119 두 번째 모형의 AICc가 조금 더 작은 값으로 계산되었다. 따라서 Fourier series 변수를 사용한 모형을 최적 회귀모형으로 선택하자. fit_reg &lt;- fit_r2 3. ARIMA 모형 적합 ARIMA 모형도 회귀모형의 경우처럼 분산 안정화가 필수적인 모형이며, 변환 결과에 대한 해석도 필요한 모형이다. 따라서 로그 변환된 자료를 대상으로 모형 적합을 진행해 보자. 우선 로그 변환된 자료에 대한 시계열 그래프와 표본 ACF를 작성해 보자. train_AP %&gt;% log() %&gt;% ggtsdisplay() 뚜렷한 추세와 계절 성분이 있는 자료임을 알 수 있다. 계절 차분을 실시하고, 그 결과를 확인해 보자. train_AP %&gt;% log() %&gt;% diff(lag = 12) %&gt;% ggtsdisplay() 시계열 그래프와 ACF로는 1차 차분이 더 필요한지 여부를 확실하게 결정하기 어려워 보인다. 이런 상황에서는 계절 차분만 실시한 자료에 대한 ARIMA 모형 적합도 시도해 볼 필요가 있는 것으로 보인다. 계절 차분된 자료에 1차 차분을 추가로 실시하고, 그 결과를 확인해 보자. 비정상성 요소가 완전히 제거된 것을 볼 수 있다. train_AP %&gt;% log() %&gt;% diff(lag = 12) %&gt;% diff() %&gt;% ggtsdisplay() 단위근 검정 결과를 확인해 보자. 계절 차분과 1차 차분이 모두 필요한 것으로 나타난다. train_AP %&gt;% log() %&gt;% ndiffs() ## [1] 1 train_AP %&gt;% log() %&gt;% nsdiffs() ## [1] 1 단위근 검정 결과에도 불구하고 1차 차분이 명확하게 필요한 상황으로 판단하기 어렵다고 보고, 계절 차분만 실시한 경우와 계절 차분과 1차 차분을 모두 실시한 경우에 대해서 각각 ARIMA 모형을 적합시켜 보자. 먼저 계절 차분과 1차 차분을 모두 실시한 자료를 대상으로 ARIMA 모형을 적합해 보자. fit_a1 &lt;- auto.arima(train_AP, lambda = 0, stepwise = FALSE) 적합 결과는 다음과 같다. summary(fit_a1) ## Series: train_AP ## ARIMA(0,1,1)(0,1,1)[12] ## Box Cox transformation: lambda= 0 ## ## Coefficients: ## ma1 sma1 ## -0.3424 -0.5405 ## s.e. 0.1009 0.0877 ## ## sigma^2 = 0.001432: log likelihood = 197.51 ## AIC=-389.02 AICc=-388.78 BIC=-381 ## ## Training set error measures: ## ME RMSE MAE MPE ## Training set -0.2372088 8.835339 6.51704 -0.07508532 ## MAPE MASE ACF1 ## Training set 2.637955 0.2280753 0.04249699 모형 검진 결과에서는 어떤 문제도 발견되지 않았다. checkresiduals(fit_a1) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(0,1,1)(0,1,1)[12] ## Q* = 20.34, df = 22, p-value = 0.5618 ## ## Model df: 2. Total lags used: 24 이번에는 계절 차분만을 실시한 자료를 대상으로 ARIMA 모형을 적합해 보자. fit_a2 &lt;- auto.arima(train_AP, d = 0, lambda = 0, stepwise = FALSE) 적합 결과는 다음과 같다. fit_a2 ## Series: train_AP ## ARIMA(2,0,0)(0,1,1)[12] with drift ## Box Cox transformation: lambda= 0 ## ## Coefficients: ## ar1 ar2 sma1 drift ## 0.6159 0.2356 -0.5562 0.0101 ## s.e. 0.0944 0.0965 0.0898 0.0010 ## ## sigma^2 = 0.001382: log likelihood = 201.77 ## AIC=-393.53 AICc=-392.95 BIC=-380.12 모형 검진을 실시해 보면, 모든 가정이 만족되는 것으로 보인다. checkresiduals(fit_a2) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(2,0,0)(0,1,1)[12] with drift ## Q* = 20.83, df = 21, p-value = 0.4694 ## ## Model df: 3. Total lags used: 24 이제 두 모형 중 하나의 모형을 선택해 보자. 두 모형은 차분을 실시한 횟수가 각기 다른 자료를 사용한 것이기 때문에 AICc 등의 비교는 의미가 없다. 따라서 Test data를 대상으로 더 근접한 예측 결과를 산출하는 모형을 선택하기로 하자. fc_a1 &lt;- forecast(fit_a1, h = length(test_AP)) fc_a2 &lt;- forecast(fit_a2, h = length(test_AP)) 그림 5.8: ARIMA 모형의 예측 결과 두 번째 모형인 ARIMA(2,0,0)(0,1,1)12의 예측 결과가 test data에 더 근접한 것으로 보인다. fit_arima &lt;- fit_a2 이제는 ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형의 예측 결과를 비교해 보자. new_t &lt;- cbind(Time = time(test_AP), Fourier = fourier(test_AP, K = min_k)) fc_reg &lt;- forecast(fit_r2, xreg = new_t) fc_ets &lt;- forecast(fit_ets, h = length(test_AP)) fc_arima &lt;- forecast(fit_arima, h = length(test_AP)) accuracy(fc_reg, test_AP) ## ME RMSE MAE MPE ## Training set 0.1302685 8.156184 6.052862 -0.05051831 ## Test set -10.8769172 22.234136 15.437231 -2.58040950 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 2.597827 0.2118306 0.09399082 NA ## Test set 3.488570 0.5402531 0.39683635 0.4785114 accuracy(fc_ets, test_AP) ## ME RMSE MAE MPE ## Training set 0.1851383 9.164883 6.647767 0.1873228 ## Test set -6.3756691 19.752432 14.199026 -1.4099460 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 2.862835 0.2326503 0.3728555 NA ## Test set 3.219620 0.4969199 0.1682524 0.4355005 accuracy(fc_arima, test_AP) ## ME RMSE MAE MPE ## Training set 0.05350955 8.616827 6.212913 0.05341167 ## Test set -3.33508240 14.125641 10.626775 -0.66418334 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 2.560180 0.2174318 0.04419876 NA ## Test set 2.356519 0.3719027 0.14856147 0.2945598 ARIMA 모형의 예측 오차가 가장 작은 것으로 나타났다. 예측 결과를 그래프로 비교해 보자. 그림 5.9: AirPassengers 자료에 대한 예측 결과 비교 ARMA 오차 Dynamic 회귀모형 예제 : 2014년 호주 빅토리아주의 일일 전기 수요량 자료 (fpp2::elecdaily) elecdaily는 \\(365 \\times 3\\) 의 ts 객체 행렬이다. 처음 3개 행을 출력해 보자. elecdaily[1:3,] ## Demand WorkDay Temperature ## [1,] 174.8963 0 26.0 ## [2,] 188.5909 1 23.0 ## [3,] 188.9169 1 22.2 첫 번째 열인 Demand는 일일 전기 수요량이고, 두 번째 열인 WorkDay는 휴일이면 0, 근무일이면 1을 값으로 갖고 있으며, 세 번째 열인 Temperature는 당일 최고 기온이다. 세 변수의 시계열 그래프를 그림 5.10에 작성해 보자. autoplot(elecdaily, facets = TRUE) 그림 5.10: 자료 elecdaily를 구성하고 있는 세 변수의 시계열 그래프 시계열자료 행렬 elecdaily의 각 열을 개별 시계열자료로 분리해 보자. Demand &lt;- elecdaily[,1] Work &lt;- elecdaily[,2] Temp &lt;- elecdaily[,3] 세 시계열자료는 동일한 기간과 주기를 갖고 있는데, 변수 Demand로 확인해 보자. start(Demand); end(Demand); frequency(Demand) ## [1] 1 4 ## [1] 53 4 ## [1] 7 시작 시점은 2014년 첫 번째 주 네 번째 날이고, 종료 시점은 2014년 53번째 주 네 번째 날이다. 일일 자료이므로 주기는 7로 설정되어 있다. 주 중 네 번째 날의 요일은 다음과 같이 패키지 lubridate의 함수 wday()로 할 수 있다. library(lubridate) wday(ymd(&quot;2014-1-1&quot;), label = TRUE) ## [1] 수 ## Levels: 일 &lt; 월 &lt; 화 &lt; 수 &lt; 목 &lt; 금 &lt; 토 반응변수인 Demand와 셜명변수인 Temp의 정상성 만족 여부를 확인해 보자. 두 변수 모두 차분이 필요한 것으로 보인다. 단위근 검정 결과도 확인해 보자. ndiffs(Demand) ## [1] 1 ndiffs(Temp) ## [1] 1 이제 두 변수의 관계를 산점도를 이용해서 살펴보자. 그림 5.11에서 두 변수 사이에 2차 함수의 관계가 있음을 볼 수 있다. 회귀모형에 변수 Temp의 제곱항도 포함시켜야 할 것으로 보인다. tibble(Demand, Temp) %&gt;% ggplot(aes(x = as.numeric(Temp), y = as.numeric(Demand))) + geom_point() + geom_smooth(se = FALSE) + labs(x = &quot;Temperature&quot;, y = &quot;Demand&quot;) 그림 5.11: Demand와 Temperature의 산점도 Dynamic 회귀모형을 적합시켜보자. 함수 auto.arima()에 설명변수 Temp와 Temp^2, Work를 행렬 형태로 xreg에 지정해 보자. xreg &lt;- cbind(Temp, Temp2 = Temp^2, Work) fit &lt;- auto.arima(Demand, xreg = xreg, stepwise = FALSE) 적합 결과를 확인해 보자. summary(fit) ## Series: Demand ## Regression with ARIMA(2,1,1)(2,0,0)[7] errors ## ## Coefficients: ## ar1 ar2 ma1 sar1 sar2 Temp ## 0.8247 -0.0225 -0.9806 0.2216 0.4008 -7.8847 ## s.e. 0.0700 0.0666 0.0203 0.0552 0.0566 0.4457 ## Temp2 Work ## 0.1849 30.3192 ## s.e. 0.0088 1.3390 ## ## sigma^2 = 44.7: log likelihood = -1205.77 ## AIC=2429.54 AICc=2430.04 BIC=2464.61 ## ## Training set error measures: ## ME RMSE MAE MPE ## Training set 0.01290229 6.602876 4.767955 -0.09519977 ## MAPE MASE ACF1 ## Training set 2.159123 0.3273729 -0.000989946 적합된 회귀모형에 절편이 없는 것을 볼 수 있는데, 이것은 차분을 실시한 자료를 대상으로 회귀모형을 적합시켰기 때문이다. 적합된 모형의 진단을 실시해 보자. 독립성 가정에는 문제가 있는 것으로 보인다. checkresiduals(fit) ## ## Ljung-Box test ## ## data: Residuals from Regression with ARIMA(2,1,1)(2,0,0)[7] errors ## Q* = 36.219, df = 9, p-value = 3.625e-05 ## ## Model df: 5. Total lags used: 14 이제 적합된 Dynamic 회귀모형을 이용해서 2015년 1월 1이부터 1월 10일까지의 전력 수요량을 예측해 보자. 이 때 문제가 되는 것은 해당 기간에 대한 변수 Temp의 값도 미리 알 수 없다는 것이다. 이 문제는 변수 Temp의 미래 값을 다른 방법으로 예측해서 사용하거나, 특정한 값으로 가정하고 Demand의 미래 값을 예측해야 한다. 여기에서는 2014년 1월 1일부터 1월 10일까지의 Temp 값을 그대로 사용해서 예측을 실시해 보자. 변수 Work의 값은 2015년 1월 1일 목요일부터 1월 10일 토요일까지 휴일과 근무일을 구분해서 입력할 수 있다. old_T &lt;- Temp[1:10] new_x &lt;- cbind(Temp = old_T, Temp2 = old_T^2, Work = c(0,1,0,0,1,1,1,1,1,0)) fc &lt;- forecast(fit, xreg = new_x) 예측 결과에 대한 그래프를 작성해 보자. autoplot(fc) 그림 5.12: Demand의 예측 결과 예제: 미국 소득, 소비 등의 1970년 1분기부터 2016년 3분기까지 분기별 변화 비율 (fpp2::uschange) uschange는 \\(187 \\times 5\\) 의 ts 객체 행렬이다. uschange[1:3,] ## Consumption Income Production Savings Unemployment ## [1,] 0.6159862 0.972261 -2.4527003 4.810312 0.9 ## [2,] 0.4603757 1.169085 -0.5515251 7.287992 0.5 ## [3,] 0.8767914 1.553271 -0.3587079 7.289013 0.5 다섯 개 시계열자료는 동일한 시작 시점, 종료 시점과 주기를 갖고 있는데, 첫 번째 시계열자료를 이용해서 확인해 보자. 분기별 자료이므로 주기는 4이고, 시작 시점은 1970년 1분기이며, 종료 시점은 2016년 3분기이다. start(uschange[,1]) ## [1] 1970 1 end(uschange[,1]) ## [1] 2016 3 frequency(uschange[,1]) ## [1] 4 첫 번째 시계열자료인 Consumption에 대한 예측 모형을 적합해 보자. ARIMA 모형과 ETS 모형에 의한 예측 모형, ARMA 오차 회귀모형, 그리고 행렬 uschange의 다른 시계열자료를 설명변수로 사용하는 dynamic 회귀모형에 의한 예측 모형을 적합해 보자. uschange를 구성하고 있는 다섯 변수의 시계열 그래프를 그림 5.13에 작성해 보자. 뚜렷한 추세나 계절 성분이 있는 시계열자료는 없는 것으로 보인다. autoplot(uschange, facets=TRUE) + labs(y = NULL, x = NULL) 그림 5.13: uschange의 다섯 시계열자료의 그래프 다섯 시계열자료의 ACF는 함수 ggAcf()에 개별 시계열자료를 각각 입력해서 작성할 수도 있지만, 조금은 번거로운 작업이 된다. 대신 함수 ggAcf()에 행렬 uschange를 그대로 입력하면 두 변수씩의 모든 조합에 대한 상관 행렬이 작성되는데, 그 중 대각 패널에 각 변수의 ACF가 작성된다. ggAcf(uschange) 그림 5.14: uschange의 다섯 시계열자료의 표본 ACF 그림 5.13과 그림 5.14을 근거로 다섯 시계열자료는 모두 정상성을 만족하고 있는 것으로 보인다. Dynamic 회귀모형에서 설명변수로 사용할 수 있는 시계열자료는 Income, Production, Savings, 그리고 Unemployment이다. 함수 GGally::ggpairs()로 다섯 변수의 산점도 행렬을 작성해 보자. GGally::ggpairs(as_tibble(uschange) %&gt;% relocate(Consumption, .after=last_col()), lower=list(continuous=&quot;smooth_loess&quot;)) 그림 5.15: uschange의 다섯 시계열자료의 산점도 행렬 변수 (Income, Savings)과 (Production, Uneployment) 사이에 높은 관련성이 있는 것으로 보여서, 변수 Income과 Production만을 설명변수로 포함시키고자 한다. 엄격하고 타당한 변수 선택 방식은 아니지만 가능하면 간단한 모형을 구성하고자 한다. 이제 자료를 분리하고 예측 모형을 적합시켜보자. uschange_te &lt;- tail(uschange, n = 8) uschange_tr &lt;- head(uschange, n = nrow(uschange)-8) ARIMA 모형을 적합하고, 결과를 확인해 보자. fit_arima &lt;- auto.arima(uschange_tr[,1], stepwise = FALSE, approximation = FALSE) fit_arima ## Series: uschange_tr[, 1] ## ARIMA(3,0,0)(2,0,0)[4] with non-zero mean ## ## Coefficients: ## ar1 ar2 ar3 sar1 sar2 mean ## 0.2267 0.1771 0.2218 -0.0351 -0.1792 0.7482 ## s.e. 0.0739 0.0738 0.0726 0.0774 0.0745 0.0951 ## ## sigma^2 = 0.3544: log likelihood = -158.39 ## AIC=330.78 AICc=331.44 BIC=353.09 ETS 모형을 적합하고, 결과를 확인해 보자. fit_ets &lt;- ets(uschange_tr[,1]) fit_ets ## ETS(A,N,N) ## ## Call: ## ets(y = uschange_tr[, 1]) ## ## Smoothing parameters: ## alpha = 0.3315 ## ## Initial states: ## l = 0.6877 ## ## sigma: 0.633 ## ## AIC AICc BIC ## 768.8004 768.9376 778.3626 관측 시점만을 설명변수로 사용하는 ARMA 오차 회귀모형을 적합해 보자. 추세 변수는 함수 time()으로 생성하고, 계절 성분은 dummy 변수로 표현해 보자. Time &lt;- time(uschange_tr[,1]) Qtr &lt;- seasonaldummy(uschange_tr[,1]) fit_reg &lt;- auto.arima(uschange_tr[,1], xreg = cbind(Time, Qtr), stepwise = FALSE, approximation = FALSE) fit_reg ## Series: uschange_tr[, 1] ## Regression with ARIMA(3,0,0)(0,0,2)[4] errors ## ## Coefficients: ## ar1 ar2 ar3 sma1 sma2 Time ## 0.2564 0.1608 0.2482 -0.1066 -0.1942 3e-04 ## s.e. 0.0742 0.0737 0.0729 0.0773 0.0707 1e-04 ## Qtr.Q1 Qtr.Q2 Qtr.Q3 ## 0.0554 0.0122 0.172 ## s.e. 0.0700 0.0748 0.070 ## ## sigma^2 = 0.349: log likelihood = -155.52 ## AIC=331.03 AICc=332.34 BIC=362.91 Dynamic 회귀모형도 적합해 보자. fit_dyn &lt;- auto.arima(uschange_tr[,1], d = 0, xreg = uschange_tr[,c(2,3)], stepwise = FALSE, approximation = FALSE) fit_dyn ## Series: uschange_tr[, 1] ## Regression with ARIMA(3,0,0) errors ## ## Coefficients: ## ar1 ar2 ar3 intercept Income Production ## 0.0060 0.1960 0.1890 0.5288 0.1741 0.1758 ## s.e. 0.0813 0.0734 0.0735 0.0708 0.0457 0.0262 ## ## sigma^2 = 0.2696: log likelihood = -133.71 ## AIC=281.41 AICc=282.07 BIC=303.72 적합시킨 네 모형에 대한 모형 검진도 실시해 보자. 다른 가정 사항에는 모든 모형에 문제가 없는 것으로 나타났지만, Ljung-Box 검정 결과에서 ETS 모형이 독립성 가정을 위반하고 있는 것으로 보인다. checkresiduals(fit_arima) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(3,0,0)(2,0,0)[4] with non-zero mean ## Q* = 0.6507, df = 3, p-value = 0.8847 ## ## Model df: 5. Total lags used: 8 checkresiduals(fit_ets) ## ## Ljung-Box test ## ## data: Residuals from ETS(A,N,N) ## Q* = 15.865, df = 6, p-value = 0.0145 ## ## Model df: 2. Total lags used: 8 checkresiduals(fit_reg) ## ## Ljung-Box test ## ## data: Residuals from Regression with ARIMA(3,0,0)(0,0,2)[4] errors ## Q* = 0.32544, df = 3, p-value = 0.9552 ## ## Model df: 5. Total lags used: 8 checkresiduals(fit_dyn) ## ## Ljung-Box test ## ## data: Residuals from Regression with ARIMA(3,0,0) errors ## Q* = 1.5616, df = 5, p-value = 0.9059 ## ## Model df: 3. Total lags used: 8 이제 test data에 대한 예측을 실시해 보자. 모형 fit_dyn의 경우에는 test data 시점에서 설명변수의 관측 문제가 있지만, 다른 모형과의 비교를 위해서 설명변수의 값이 알려져 있다고 가정하겠다. 이 가정으로 모형 fit_dyn의 예측은 결과가 더 좋게 나올 수 있다. fc_arima &lt;- forecast(fit_arima, h = 8) fc_ets &lt;- forecast(fit_ets, h = 8) fc_dyn &lt;- forecast(fit_dyn, xreg = uschange_te[,c(2,3)]) Time &lt;- time(uschange_te[,1]) Qtr &lt;- seasonaldummy(uschange_te[,1]) fc_reg &lt;- forecast(fit_reg, xreg = cbind(Time, Qtr)) 예측 결과를 test data와 비교해 보자. 모형 fit_dyn의 예측 오류가 가장 작은 것으로 나타났다. ETS 모형도 예측 오류가 다른 모형보다 비교적 작은 것으로 나타났다. accuracy(fc_arima, uschange_te[,1]) ## ME RMSE MAE MPE ## Training set 0.0002559072 0.5852267 0.4396851 65.90037 ## Test set -0.0475341277 0.2500710 0.2185770 -17.75795 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 189.15841 0.670526 0.00952753 NA ## Test set 33.64265 0.333333 -0.21075717 0.6797118 accuracy(fc_ets, uschange_te[,1]) ## ME RMSE MAE MPE ## Training set 0.0008292707 0.6294144 0.4622752 15.94476 ## Test set -0.0071405456 0.2275948 0.1819332 -11.07730 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 163.66594 0.7049764 -0.004088847 NA ## Test set 27.12135 0.2774507 -0.208694082 0.5901059 accuracy(fc_reg, uschange_te[,1]) ## ME RMSE MAE MPE ## Training set 0.0008586772 0.5757214 0.4336545 62.73093 ## Test set -0.0460208936 0.2877620 0.2542229 -18.22233 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 184.11947 0.6613293 0.003604112 NA ## Test set 37.33168 0.3876936 -0.360236167 0.7215638 accuracy(fc_dyn, uschange_te[,1]) ## ME RMSE MAE MPE ## Training set -0.0006526438 0.5104141 0.3844923 43.024517 ## Test set 0.1004867937 0.2061923 0.1498566 8.058113 ## MAPE MASE ACF1 Theil&#39;s U ## Training set 189.5903 0.5863563 0.002548898 NA ## Test set 18.8564 0.2285334 -0.413909940 0.6493148 예측 결과를 그래프로 나타내서 비교해 보자. ETS 모형의 경우 비교적 작은 예측 오류가 나왔지만 모든 시점에서 동일한 예측 결과을 보이는 모형이 선택되었고, 예측 구간의 폭이 가장 넓다는 점을 고려한다면, 바람직한 예측 모형은 아니라고 하겠다. library(patchwork) y_lim &lt;- c(-1, 2.5) p1 &lt;- autoplot(fc_arima, include = 8) + autolayer(uschange_te[,1], color = &quot;red&quot;, size = .8) + ylab(NULL) + ylim(y_lim[1], y_lim[2]) p2 &lt;- autoplot(fc_ets, include = 8) + autolayer(uschange_te[,1], color = &quot;red&quot;, size = .8) + ylab(NULL) + ylim(y_lim[1], y_lim[2]) p3 &lt;- autoplot(fc_reg, include = 8) + autolayer(uschange_te[,1], color = &quot;red&quot;, size = .8) + ylab(NULL) + ylim(y_lim[1], y_lim[2]) p4 &lt;- autoplot(fc_dyn, include = 8) + autolayer(uschange_te[,1], color = &quot;red&quot;, size = .8) + ylab(NULL) + ylim(y_lim[1], y_lim[2]) (p1 + p2) / (p3 + p4) 그림 5.16: uschange의 Consumption에 대한 예측 결과 비교 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
