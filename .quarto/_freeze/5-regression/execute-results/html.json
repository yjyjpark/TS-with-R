{
  "hash": "206bde4ccbe703234db654c17b69521a",
  "result": {
    "engine": "knitr",
    "markdown": "# 회귀모형 {#sec-regression}\n\n\n::: {.cell}\n\n:::\n\n\n## ARMA 오차 회귀모형 {-}\n\n- 예제 : 분기별 호주 맥주 생산량 자료 (`fpp2::ausbeer`)\n\n**1. 백색잡음오차 시계열 회귀모형 적합**\n\n`ausbeer`는 1956년 1분기부터 2010년 2분기까지 호주의 분기별 맥주 생산량이다. 전체 기간 중 1975년 1분기 이후 자료에 대한 회귀모형을 적합시켜보자. 마지막 2년 자료는 test data로 남겨두자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_b <- window(ausbeer, start = 1975, end = c(2008, 2))\ntest_b <- window(ausbeer, start = c(2008, 3))\n```\n:::\n\n\n@fig-ausbeer-1 은 전체 자료의 시계열 그래프이다. Test data는 빨간 색으로 구분했다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(train_b) + \n  autolayer(test_b, color = \"red\", size = 0.8) + \n  labs(y = NULL, x = NULL)\n```\n\n::: {.cell-output-display}\n![자료 `ausbeer`의 시계열 그래프](5-regression_files/figure-html/fig-ausbeer-1-1.png){#fig-ausbeer-1 width=672}\n:::\n:::\n\n\n시계열자료에 대한 회귀모형의 적합은 함수 `tslm()`으로 할 수 있다. 함수 `tslm()`은 `lm()`과 실질적으로 동일한 함수지만, `ts` 객체에 대한 회귀모형 적합을 위한 함수이다. 잔차 및 적합값이 `ts` 객체로 생성되고, 결측값 처리 방식이 시계열자료에 적합하도록 설정되었다.\n\n추세 변수와 계절 변수를 시점 $t$를 이용하여 생성하는 방법을 살펴보자. 먼저 추세 변수는 함수 `time()`으로 자료가 관측된 시점을 생성할 수 있다. 자료 `train_b`에 대해 함수 `time()`을 적용한 결과를 살펴보자. 1975년 1분기 값을 1975.00으로 두고, 1/4 간격으로 다음 분기의 관측 시점을 생성하고 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntime(train_b)[1:9]\n## [1] 1975.00 1975.25 1975.50 1975.75 1976.00 1976.25 1976.50 1976.75 1977.00\n```\n:::\n\n\n관측 시점을 $t = 1, 2, 3, \\ldots$ 로 하여 사용하고자 한다면, `1:length(train_b)`를 추세 변수로 사용하거나, 함수 `tslm()`에서 `trend`를 추세 변수로 사용하면 된다.\n\n계절 변수로 dummy 변수를 사용한다면 함수 `forecast::seasonaldummy()`를 사용하거나, 함수 `tslm()`에서 `season`을 변수로 사용하면 된다. 계절 주기에 맞추어 필요한 dummy 변수를 생성한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseasonaldummy(train_b)[1:5,]\n##      Q1 Q2 Q3\n## [1,]  1  0  0\n## [2,]  0  1  0\n## [3,]  0  0  1\n## [4,]  0  0  0\n## [5,]  1  0  0\n```\n:::\n\n\nFourier series 변수를 사용한다면 함수 `forecast::fourier()`를 사용하면 된다. 모형에 포함되는 fourier series 변수들의 최대 주기는 옵션 `K`에 지정하면 된다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfourier(train_b, K = 2)[1:5,]\n##      S1-4 C1-4 C2-4\n## [1,]    1    0   -1\n## [2,]    0   -1    1\n## [3,]   -1    0   -1\n## [4,]    0    1    1\n## [5,]    1    0   -1\n```\n:::\n\n\nS1-4와 C1-4는 $K=1$ 에 해당하는 $\\sin(2\\pi t/4)$ 와 $\\cos(2\\pi t/4)$ 를 의미하고, C2-4는 $K=2$ 에 해당하는 $\\cos(2\\pi 2t/4)$ 를 나타내고 있다.\n\n함수 `time()`에 의한 추세 변수와 `seasonaldummy()`에 의한 계절 변수를 사용하여 회귀모형을 적합해 보고, 그 결과를 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- tslm(train_b ~ time(train_b) + seasonaldummy(train_b))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit1)\n## \n## Call:\n## tslm(formula = train_b ~ time(train_b) + seasonaldummy(train_b))\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -47.776 -11.771  -0.738  10.842  63.468 \n## \n## Coefficients:\n##                           Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)              5335.5613   325.0641   16.41   <2e-16 ***\n## time(train_b)              -2.4112     0.1632  -14.78   <2e-16 ***\n## seasonaldummy(train_b)Q1  -74.4299     4.4641  -16.67   <2e-16 ***\n## seasonaldummy(train_b)Q2 -118.3271     4.4639  -26.51   <2e-16 ***\n## seasonaldummy(train_b)Q3 -105.7240     4.4973  -23.51   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 18.27 on 129 degrees of freedom\n## Multiple R-squared:  0.8911,\tAdjusted R-squared:  0.8877 \n## F-statistic: 263.9 on 4 and 129 DF,  p-value: < 2.2e-16\n```\n:::\n\n\n이번에는 변수 `trend`와 `season`을 사용해서 적합해 보고, 결과를 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- tslm(train_b ~ trend + season)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit2)\n## \n## Call:\n## tslm(formula = train_b ~ trend + season)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -47.776 -11.771  -0.738  10.842  63.468 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 499.6812     4.1577 120.181  < 2e-16 ***\n## trend        -0.6028     0.0408 -14.775  < 2e-16 ***\n## season2     -43.8972     4.4306  -9.908  < 2e-16 ***\n## season3     -31.2941     4.4639  -7.011 1.19e-10 ***\n## season4      74.4299     4.4641  16.673  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 18.27 on 129 degrees of freedom\n## Multiple R-squared:  0.8911,\tAdjusted R-squared:  0.8877 \n## F-statistic: 263.9 on 4 and 129 DF,  p-value: < 2.2e-16\n```\n:::\n\n\n\n`fit1`과 `fit2`의 적합 결과가 서로 다른 것처럼 보인다. 그러나 추세의 기울기가 다른 것은 모형에서 사용된 추세 변수의 간격이 다르기 때문이다. 즉, 두 모형의 추세 기울기가 4배 차이 나는 이유는 모형 `fit1`에서 사용된 추세 변수의 간격이 1/4인 반면에 모형 `fit2`에서 사용된 추세 변수의 간격은 1이기 때문이다.\n\n또한 절편이 다른 것은 두 모형의 기준 범주가 다르며, 사용된 추세 변수의 범위가 다르기 때문이다. 즉, `fit1`에서 사용된 추세 변수는 1975.00부터 값을 갖고 있지만, `fit2`에서는 추세 변수가 1부터 값을 갖고 있으며, 함수 `seasonaldummy()`는 마지막 범주를 기준 범주로 설정하는데, 변수 `season`은 첫 번째 범주를 기준 범주로 설정하고 있어서, dummy 변수의 구성도 다르게 된다.\n\n두 모형의 적합값을 비교해 보면 실질적으로 같은 모형임을 알 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(fit1 = fit1$fitted, fit2 = fit2$fitted)\n## # A tibble: 134 × 2\n##     fit1  fit2\n##    <dbl> <dbl>\n##  1  499.  499.\n##  2  455.  455.\n##  3  467.  467.\n##  4  572.  572.\n##  5  497.  497.\n##  6  452.  452.\n##  7  464.  464.\n##  8  569.  569.\n##  9  494.  494.\n## 10  450.  450.\n## # ℹ 124 more rows\n```\n:::\n\n\n이번에는 함수 `time()`에 의한 추세 변수와 `fourier()`에 의한 Fourier series 변수를 사용하여 회귀모형을 적합해 보고, 그 결과를 확인해 보자. 분기별 자료의 최대 주기인 `K=2`를 지정해서 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3 <- tslm(train_b ~ time(train_b) + fourier(train_b, K=2))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit3)\n## \n## Call:\n## tslm(formula = train_b ~ time(train_b) + fourier(train_b, K = 2))\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -47.776 -11.771  -0.738  10.842  63.468 \n## \n## Coefficients:\n##                              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                 5260.9410   325.0320  16.186  < 2e-16 ***\n## time(train_b)                 -2.4112     0.1632 -14.775  < 2e-16 ***\n## fourier(train_b, K = 2)S1-4   15.6471     2.2319   7.011 1.19e-10 ***\n## fourier(train_b, K = 2)C1-4   59.1635     2.2319  26.508  < 2e-16 ***\n## fourier(train_b, K = 2)C2-4   15.4567     1.5784   9.793  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 18.27 on 129 degrees of freedom\n## Multiple R-squared:  0.8911,\tAdjusted R-squared:  0.8877 \n## F-statistic: 263.9 on 4 and 129 DF,  p-value: < 2.2e-16\n```\n:::\n\n\nFourier series의 모든 변수를 사용한 모형은 dummy 변수를 사용한 모형과 실질적으로 동일한 모형이 된다. `fit1`과 `fit3`의 적합값을 비교해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(fit1 = fit1$fitted, fit3 = fit3$fitted)\n## # A tibble: 134 × 2\n##     fit1  fit3\n##    <dbl> <dbl>\n##  1  499.  499.\n##  2  455.  455.\n##  3  467.  467.\n##  4  572.  572.\n##  5  497.  497.\n##  6  452.  452.\n##  7  464.  464.\n##  8  569.  569.\n##  9  494.  494.\n## 10  450.  450.\n## # ℹ 124 more rows\n```\n:::\n\n\n시계열자료 회귀모형의 모형 진단을 실시해서, 가정 만족에 문제가 있는지 확인해 보자. 함수 `checkresiduals()`는 `lm()` 또는 `tslm()`으로 생성된 객체에 대해서 Breusch-Godfrey 검정으로 독립성을 확인한다.\n검정 결과는 오차가 독립이 아니라는 결론이며, 잔차의 시계열 그래프와 ACF에서도 같은 모습을 확인할 수 있다.\n시계열자료에 회귀모형을 적합해 생성된 잔차 사이에는 강한 상관 관계가 존재하고 있음을 확인할 수 있었다. 이것은 설명이 안 된 패턴이 남아 있음을 의미하는 것이며, 따라서 추가적인 작업이 필요한 것이다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit1)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```\n## \n## \tBreusch-Godfrey test for serial correlation of order up to 8\n## \n## data:  Residuals from Linear regression model\n## LM test = 30.158, df = 8, p-value = 0.0001982\n```\n:::\n\n\n\n**2.  ARMA 오차 시계열 회귀모형 적합**\n\n자료 `ausbeer`에 대해 적합된 백색잡음 회귀모형은 잔차가 독립성을 만족하지 못하는 문제가 발견되었다. 잔차에 남아 있는 패턴을 ARMA 모형으로 설명하기 위해 ARMA 오차 회귀모형을 적합시켜보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_b <- window(ausbeer, start = 1975, end = c(2008, 2))\ntest_b <- window(ausbeer, start = c(2008, 3))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit4 <- auto.arima(train_b,\n                   xreg = cbind(Time = time(train_b), \n                                Qtr = seasonaldummy(train_b)),\n                   stepwise = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit4\n## Series: train_b \n## Regression with ARIMA(3,0,0)(1,0,0)[4] errors \n## \n## Coefficients:\n##           ar1     ar2     ar3    sar1  intercept     Time    Qtr.Q1     Qtr.Q2\n##       -0.1233  0.1645  0.2440  0.4155  5227.3160  -2.3573  -73.4170  -117.2944\n## s.e.   0.0852  0.0831  0.0849  0.0817   611.6437   0.3071    6.0565     5.2917\n##          Qtr.Q3\n##       -105.5713\n## s.e.     6.0999\n## \n## sigma^2 = 264.2:  log likelihood = -559.59\n## AIC=1139.19   AICc=1140.97   BIC=1168.16\n```\n:::\n\n\n잔차에 가장 적합한 모형은 ARIMA(3,0,0)(1,0,0)~4~가 선택되었다. 즉, 잔차에 비계절형 요소 뿐 아니라 계절형 요소도 남아 있다는 것이다.\n\nARMA 오차 회귀모형 `fit4`에 대한 모형 진단을 실시해 보자. 모든 가정이 만족되고 있음을 알 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit4)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from Regression with ARIMA(3,0,0)(1,0,0)[4] errors\n## Q* = 0.64935, df = 4, p-value = 0.9574\n## \n## Model df: 4.   Total lags used: 8\n```\n:::\n\n\nARMA 오차 회귀모형의 예측은 함수 `forecast()`로 할 수 있다. 사용법은 `forecast(object, xreg, ...)`가 되는데, `object`에는 함수 `Arima()` 혹은 `auto.arima()`로 생성된 객체를 지정하고, `xreg`에는 예측 시점에 대한 설명변수의 자료를 벡터 또는 행렬의 형태로 지정하면 된다.\n\nTest data인 `test_b`에 대한 예측을 실시해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc4 <- forecast(fit4, \n                xreg = cbind(Time = time(test_b), \n                             Qtr = seasonaldummy(test_b))\n                )\n```\n:::\n\n\nARMA 오차 회귀모형의 예측 결과와 백색잡음 회귀모형의 예측 결과를 비교해 보자. 함수 `tslm()`에 변수 `trend`와 `season`을 사용한 `fit2`에 대한 예측은 다음과 같이 실시할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- tslm(train_b ~ trend + season)\nfc2 <- forecast(fit2, h = length(test_b))\n```\n:::\n\n\n점 예측 결과는 `fc2$mean`과 `fc4$mean`에 할당되어 있다. 두 결과를 비교해 보자. 큰 차이는 없는 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(fc2 = fc2$mean, fc4 = fc4$mean)\n## # A tibble: 8 × 2\n##     fc2   fc4\n##   <dbl> <dbl>\n## 1  387.  383.\n## 2  492.  485.\n## 3  417.  420.\n## 4  373.  378.\n## 5  385.  384.\n## 6  490.  487.\n## 7  415.  416.\n## 8  370.  373.\n```\n:::\n\n\n95% 예측 구간의 폭을 비교해 보자. 예측 구간의 상한은 `fc2$upper`과 `fc4$upper`에 할당되었고, 하한은 `fc2$lower`과 `fc4$lower`에 각각 할당되어 있다. 예측 구간의 신뢰수준으로 80%와 95%가 사용되는 것이 디폴트이며, 따라서 다음과 같이 95% 예측 구간의 폭을 계산할 수 있다. ARMA 오차 회귀모형의 예측 구간인 `fc4`의 폭이 더 좁은 것을 확인할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(fc2 = fc2$upper[,2] - fc2$lower[,2], \n       fc4 = fc4$upper[,2] - fc4$lower[,2])\n## # A tibble: 8 × 2\n##     fc2   fc4\n##   <dbl> <dbl>\n## 1  74.2  63.7\n## 2  74.2  64.2\n## 3  74.2  65.2\n## 4  74.2  66.5\n## 5  74.3  71.0\n## 6  74.3  71.0\n## 7  74.3  71.3\n## 8  74.3  71.5\n```\n:::\n\n\n예측 오차의 크기를 비교해 보자. 예측 오차의 크기에는 큰 차이가 없음을 알 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc2, test_b)\n##                         ME     RMSE      MAE        MPE     MAPE      MASE\n## Training set -1.696987e-15 17.92314 13.57971 -0.1317235 2.924979 0.8311500\n## Test set      9.745836e+00 17.30833 11.90530  2.4185316 2.886254 0.7286673\n##                     ACF1 Theil's U\n## Training set 0.007149994        NA\n## Test set     0.048860146 0.3056324\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc4, test_b)\n##                      ME     RMSE      MAE         MPE     MAPE      MASE\n## Training set  0.1677325 15.69822 12.11679 -0.07293605 2.618274 0.7416116\n## Test set     10.0161277 17.40591 11.67960  2.42511984 2.826267 0.7148528\n##                     ACF1 Theil's U\n## Training set 0.004529308        NA\n## Test set     0.049644862 0.2895782\n```\n:::\n\n\n예측 결과를 그래프로 나타내서 비교해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- autoplot(fc2, include=8) +\n  autolayer(test_b, color = \"red\", size=.8) +\n  labs(y = NULL, x = NULL)\n\np2 <- autoplot(fc4, include=8) +\n  autolayer(test_b, color = \"red\", size=.8) +\n  labs(y = NULL, x = NULL)\np1 + p2\n```\n\n::: {.cell-output-display}\n![`ausbeer` 자료에 대한 예측 결과](5-regression_files/figure-html/fig-ausbeer-2-1.png){#fig-ausbeer-2 width=768}\n:::\n:::\n\n\n-   예제: 1970년 1월부터 2005년 12월까지 지구 기온 자료 (`global.txt`)\n\n`global.txt`는 1856년 1월부터 2005년 12월까지의 지구 기온 자료 자료인데, 그 중 1970년 이후 자료만을 대상으로 ARMA 오차 회귀모형과 ARIMA 모형, 그리고 ETS 모형으로 예측 모형을 각각 적합시키고 예측 결과를 비교해 보자.\n\n자료를 불러 들이고 training data와 test data로 분리시키자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal <- scan(\"https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/global.txt\")\nglobal.ts <- ts(global, start = c(1856, 1), frequency = 12)\ntrain_g <- window(global.ts, start = 1970, end = c(2003,12))\ntest_g <- window(global.ts, start = 2004)\n```\n:::\n\n\n@fig-global-1 은 1970년부터 자료의 시계열 그래프이다. Test data는 빨간 색으로 구분했다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(train_g) + \n  autolayer(test_g, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL)\n```\n\n::: {.cell-output-display}\n![자료 `global.txt`의 training data와 test data의 시계열 그래프](5-regression_files/figure-html/fig-global-1-1.png){#fig-global-1 width=672}\n:::\n:::\n\n\n**1.  ARMA 오차 회귀모형 적합**\n\n계절 성분이 있는 시계열자료에 회귀모형을 적용할 때에는 계절 성분을 dummy 변수로 나타낼 것인지, Fourier series 변수로 나타낼 것인지를 선택해야 한다.\n먼저 선형 추세와 dummy 변수를 사용한 회귀모형을 적합시켜 보자. 추세 변수는 함수 `time()`으로 생성하고, 계절 변수는 함수 `seasonaldummy()`로 생성한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTime <- time(train_g)\nMonth <- seasonaldummy(train_g)\n```\n:::\n\n\n모형 `fit1`의 적합 과정에서 `stepwise = FASLE`와 `approximation = FALSE`를 제외했는데, 두 옵션을 추가해도 같은 결과를 얻게 된다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- auto.arima(train_g, xreg = cbind(Time, Month))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit1)\n## Series: train_g \n## Regression with ARIMA(2,0,0) errors \n## \n## Coefficients:\n##          ar1     ar2  intercept    Time  Month.Jan  Month.Feb  Month.Mar\n##       0.4932  0.3204   -34.5510  0.0175     0.0409     0.0522     0.0268\n## s.e.  0.0469  0.0472     4.2613  0.0021     0.0161     0.0171     0.0195\n##       Month.Apr  Month.May  Month.Jun  Month.Jul  Month.Aug  Month.Sep\n##          0.0250     0.0093     0.0162     0.0137     0.0151     0.0002\n## s.e.     0.0204     0.0211     0.0213     0.0211     0.0204     0.0194\n##       Month.Oct  Month.Nov\n##          -0.015    -0.0304\n## s.e.      0.017     0.0160\n## \n## sigma^2 = 0.007112:  log likelihood = 437.21\n## AIC=-842.41   AICc=-841.02   BIC=-778.23\n## \n## Training set error measures:\n##                         ME       RMSE        MAE      MPE     MAPE      MASE\n## Training set -0.0007778394 0.08276884 0.06379682 22.62755 81.57672 0.4285951\n##                     ACF1\n## Training set 0.006984407\n```\n:::\n\n\n잔차는 AR(2) 모형으로 적합되었다.\n\n이번에는 선형 추세와 Fourier series 변수를 사용한 회귀모형을 적합시켜 보자. Fourier series 변수를 사용하기 위해서는 최적 주기를 결정해야 한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTime <- time(train_g)\nres <- vector(\"numeric\", 6)\nfor(i in seq(res)){\n  xreg <- cbind(Time, fourier(train_g, K = i))\n  fit <- auto.arima(train_g, xreg = xreg)\n  res[i] <- fit$aicc\n}\n```\n:::\n\n\n객체 `res`에는 6개 모형의 AICc가 입력되어 있다. 그 중 두 번째 모형의 AICc가 가장 작은 값임을 확인할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres\n## [1] -840.8765 -851.6310 -850.3429 -846.7538 -842.5771 -841.0206\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n(k_min <- which.min(res))\n## [1] 2\n```\n:::\n\n\n이제 $K=2$ 를 최적 주기로 하는 Fourier series 변수를 사용한 회귀모형을 적합시켜 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFourier <- fourier(train_g, K = k_min)\nfit2 <- auto.arima(train_g, xreg = cbind(Time, Fourier))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit2)\n## Series: train_g \n## Regression with ARIMA(2,0,0) errors \n## \n## Coefficients:\n##          ar1     ar2  intercept    Time  Fourier.S1-12  Fourier.C1-12\n##       0.4919  0.3200   -34.4729  0.0174         0.0210        -0.0047\n## s.e.  0.0469  0.0472     4.2484  0.0021         0.0088         0.0087\n##       Fourier.S2-12  Fourier.C2-12\n##              0.0192        -0.0054\n## s.e.         0.0051         0.0051\n## \n## sigma^2 = 0.007062:  log likelihood = 435.04\n## AIC=-852.08   AICc=-851.63   BIC=-815.98\n## \n## Training set error measures:\n##                         ME       RMSE       MAE      MPE     MAPE      MASE\n## Training set -0.0007984029 0.08320983 0.0640202 22.23643 80.56552 0.4300958\n##                     ACF1\n## Training set 0.004973903\n```\n:::\n\n\n`fit1`의 경우와 동일하게 `fit2`에서도 잔차는 AR(2) 모형으로 적합되었다.\n\n두 모형의 검진을 실시해 보자. \n먼저 선형 추세와 dummy 변수를 사용한 회귀모형인 모형 `fit1`의 모형 검진을 진행해 보자. \n모형 `fit1`의 경우에는 가정 만족에 큰 문제가 없는 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit1)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from Regression with ARIMA(2,0,0) errors\n## Q* = 27.817, df = 22, p-value = 0.1818\n## \n## Model df: 2.   Total lags used: 24\n```\n:::\n\n\n선형 추세와 Fourier series 변수를 사용한 회귀모형인 모형 `fit2`의 모형 검진도 진행해 보자. \n모형 `fit2`에도 큰 문제 없이 가정을 만족하고 있음을 알 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit2)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from Regression with ARIMA(2,0,0) errors\n## Q* = 27.53, df = 22, p-value = 0.1918\n## \n## Model df: 2.   Total lags used: 24\n```\n:::\n\n\n이제 두 회귀모형 중 한 모형을 선택해 보자. 선택 기준으로는 AICc를 사용해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(fit1$aicc, fit2$aicc)\n## [1] -841.0206 -851.6310\n```\n:::\n\n\n모형 `fit2`의 AICc가 더 작게 계산되었고, 따라서 최종 예측 모형으로 선택하자. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_reg <- fit2\n```\n:::\n\n\n**2.  ARIMA 모형의 적합**\n\n차분 및 계절 차분이 필요한지 여부를 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggtsdisplay(train_g)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n\n뚜렷한 추세가 시계열 그래프에서 보이며, 표본 ACF 그래프에서 매우 큰 값의 $r_{1}$ 과 천천히 감소하는 모습에서 1차 차분이 필요한 것을 알 수 있다. 그러나 계절 차분이 필요한지 여부는 명확하게 보이지 않는다. 단위근 검정 결과를 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nndiffs(train_g)\n## [1] 1\nnsdiffs(train_g)\n## [1] 0\n```\n:::\n\n\n1차 차분은 필요하지만, 계절 차분은 필요 없는 것로 나타났다. 이제 1차 차분을 실시한 자료를 대상으로 시계열 그래프와 ACF, PACF를 작성해 보자. 정상성이 만족된 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_g |> \n  diff() |> \n  ggtsdisplay()\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n\n이제 잔차의 표본 ACF와 PACF를 이용해서 모형 식별을 시도해 보자. 비계절 요소는 1시차에서 6시차까지의 패턴으로 인식하게 되는데, ACF는 3시차까지 모두 유의하고, PACF는 1시차와 3시차가 유의한 것으로 나타났다. 이러한 경우에는 ACF를 감소, PACF는 감소 또는 3시차에서 절단으로 볼 수 있으며, 따라서 ARMA 모형이나 AR 모형이 가능할 것으로 보인다. 계절형 요소는 12, 24, 36시차에서 ACF와 PACF가 모두 매우 작은 값을 갖고 있기 때문에, 계절형 요소가 없는 것으로 볼 수도 있고, AR(1)~12~ 또는 MA(1)~12~로 볼 수도 있는 상황이다.\n\n함수 `auto.arima()`를 사용해서 AICc가 가장 작은 모형을 찾아 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_arima <- auto.arima(train_g,\n                        stepwise = FALSE,\n                        approximation = FALSE)\n```\n:::\n\n\n적합 결과는 비계절형 요소만 있는 ARIMA(2,1,1)이 선택된 것을 알 수 있다. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_arima\n## Series: train_g \n## ARIMA(2,1,1) \n## \n## Coefficients:\n##          ar1     ar2      ma1\n##       0.5198  0.3008  -0.9703\n## s.e.  0.0498  0.0492   0.0132\n## \n## sigma^2 = 0.007576:  log likelihood = 417.27\n## AIC=-826.55   AICc=-826.45   BIC=-810.51\n```\n:::\n\n\n모형 `fit_arima`에 대한 검진을 실시해 보자. 모든 가정이 만족되고 있음을 볼 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_arima)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from ARIMA(2,1,1)\n## Q* = 30.228, df = 21, p-value = 0.08751\n## \n## Model df: 3.   Total lags used: 24\n```\n:::\n\n\n**3.  ETS 모형의 적합**\n\n함수 `ets()`로 AICc가 최소인 모형을 선택해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_ets <- ets(train_g)\n```\n:::\n\n\n최적 모형은 ETS(A,N,N)이 선택되었다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_ets\n## ETS(A,N,N) \n## \n## Call:\n## ets(y = train_g)\n## \n##   Smoothing parameters:\n##     alpha = 0.5868 \n## \n##   Initial states:\n##     l = 0.0782 \n## \n##   sigma:  0.0885\n## \n##      AIC     AICc      BIC \n## 478.0785 478.1379 490.1123\n```\n:::\n\n\n모형 `fit_ets`에 대한 검진을 실시해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_ets)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-47-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from ETS(A,N,N)\n## Q* = 39.376, df = 24, p-value = 0.02493\n## \n## Model df: 0.   Total lags used: 24\n```\n:::\n\n\n독립성 가정에 문제가 있는 것으로 나타났다.\n독립성 가정을 만족시키지 못하는 모형의 경우에는 예측의 신빙성에 문제가 있을 수 있는데, 점 예측 (point forecast) 결과보다 예측 구간에 더 큰 문제가 있을 수 있다. 간혹 모든 가정을 만족시키는 모형을 찾지 못하는 경우도 있는데, 이런 경우에는 예측 결과를 적용할 때 조심할 필요가 있다.\n\n이제 세 가지 모형인 `fit_reg`, `fit_arima`, `fit_ets`에 의한 예측을 실시하고, 결과를 비교해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_reg <- cbind(Time = time(test_g), \n                Fourier = fourier(test_g, K = k_min)) \nfc_reg <- forecast(fit_reg, xreg = new_reg)\nfc_arima <- forecast(fit_arima, h = length(test_g))\nfc_ets <- forecast(fit_ets, h = length(test_g))\n```\n:::\n\n\n예측 오차를 비교해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_reg, test_g)\n##                         ME       RMSE        MAE       MPE     MAPE      MASE\n## Training set -0.0007984029 0.08320983 0.06402020 22.236428 80.56552 0.4300958\n## Test set     -0.0266870191 0.09047869 0.06864433 -9.691571 17.39724 0.4611613\n##                     ACF1 Theil's U\n## Training set 0.004973903        NA\n## Test set     0.300995351  1.015694\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_arima, test_g)\n##                       ME       RMSE        MAE       MPE     MAPE      MASE\n## Training set 0.006369769 0.08661271 0.06601014 24.330149 79.34066 0.4434645\n## Test set     0.004650257 0.08557693 0.07319499 -2.829173 17.33066 0.4917332\n##                     ACF1 Theil's U\n## Training set 0.003457635        NA\n## Test set     0.335253668 0.9396727\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_ets, test_g)\n##                        ME       RMSE        MAE       MPE     MAPE      MASE\n## Training set  0.001901676 0.08829198 0.06862716  20.00303 84.32056 0.4610460\n## Test set     -0.062218811 0.10436651 0.07564587 -17.55797 19.80559 0.5081986\n##                     ACF1 Theil's U\n## Training set -0.01131321        NA\n## Test set      0.26877094  1.191604\n```\n:::\n\n\nTest data에 대한 예측 결과를 비교해 보면, 전체적으로 큰 차이는 없는 것으로 보인다. MASE로는 ARMA 오차 회귀모형이 ARIMA 모형 보다 조금 작은 값을 보이고 있으나, RMSE와 MAPE로는 ARIMA 모형이 조금 작은 값을 보이고 있다.\n예측 결과를 test data와 함께 표시한 그래프는 @fig-global-2 에서 볼 수 있다. \n예측 구간의 폭을 비교할 수 있도록 세 그래프의 Y축 구간은 동일하게 설정하였다.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_lim <- c(-.06, 1.06)\np1 <- autoplot(fc_reg, include = 12) + \n  autolayer(test_g, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2])\np2 <- autoplot(fc_arima, include = 12) + \n  autolayer(test_g, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2])\np3 <- autoplot(fc_ets, include=12) + \n  autolayer(test_g, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL) + ylim(y_lim[1], y_lim[2])\n\np1 / p2 / p3\n```\n\n::: {.cell-output-display}\n![자료 `global.txt`에 대한 세 모형의 예측 결과](5-regression_files/figure-html/fig-global-2-1.png){#fig-global-2 width=768}\n:::\n:::\n\n\n-   예제: 1949년부터 1960년 월별 국제선 탑승자 수 자료 (`AirPassengers`)\n\n`AirPassengers`는 1949년 1월부터 1960년 12월까지 월별 국제선 탑승자 수 자료이다. ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형에 의한 예측 모형을 적합시키고, 예측 결과를 비교해 보자. 예측 결과의 평가를 위해 마지막 2년 자료는 test data로 남겨두자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_AP <- window(AirPassengers, end = c(1958, 12))\ntest_AP <- window(AirPassengers, start = c(1959, 1))\n```\n:::\n\n\n전체 기간에 대한 시계열 그래프를 @fig-AP-1 에 작성해 보자. Test data는 빨간 색으로 구분하였다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(train_AP) + \n  autolayer(test_AP, color = \"red\", size = .8) +\n  labs(x = NULL, y = NULL)\n```\n\n::: {.cell-output-display}\n![자료 `AirPassengers`의 시계열 그래프](5-regression_files/figure-html/fig-AP-1-1.png){#fig-AP-1 width=672}\n:::\n:::\n\n\n증가 추세가 있고, 명확한 계절 성분이 있는 자료이다. 또한 계절 변동 폭이 추세가 증가함에 따라 점점 커지고 있음도 알 수 있다. 따라서 분산 안정화가 필요한 자료이다.\n분산 안정화를 위해 Box-Cox 변환 모수를 추정해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(lam <- BoxCox.lambda(train_AP))\n## [1] -0.3096628\n```\n:::\n\n\n변환 모수가 $\\lambda=$ -0.3096628 로 추정되었다. 추정된 변환 모수에 의한 변환 결과와 로그 변환에 의한 결과를 비교해 보자. @fig-AP-2 에서 볼 수 있듯이 두 변환 결과는 크게 차이가 나지 않는 것으로 보인다. 이런 경우에는 변환 결과에 대한 해석이 가능한 로그 변환을 선택하는 것이 일반적이라고 하겠다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- BoxCox(train_AP, lambda = lam) |> \n  autoplot() + \n  labs(title = paste(\"Box-Cox\", \"lambda = \", signif(lam, 3)), x = NULL)\np2 <- train_AP |> \n  log() |> \n  autoplot() + labs(title = \"Log\", x = NULL)\np1+p2\n```\n\n::: {.cell-output-display}\n![분산 안정화 변환](5-regression_files/figure-html/fig-AP-2-1.png){#fig-AP-2 width=768}\n:::\n:::\n\n\n**1.  ETS 모형 적합**\n\nETS 모형은 계절 성분을 승법 형태로 설명할 수 있는 모형이기 때문에, 계절 성분의 진폭 안정화가 반드시 필요한 모형은 아니다. 또한 모수에 대한 해석보다 예측이 주된 용도이기 때문에, 분산 안정화 변환 결과에 대한 해석이 그렇게 중요한 요소가 되지 않는다. 따라서 원자료에 대한 ETS 모형과 Box-Cox 변환 자료에 대한 ETS 모형, 그리고 로그 변환 자료에 대한 ETS 모형을 각각 적합하고 예측 결과를 비교해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nets_1 <- ets(train_AP, lambda = lam) \nets_fc1 <- forecast(ets_1, h = length(test_AP)) \n\nets_2 <- ets(train_AP, lambda = 0)\nets_fc2 <- forecast(ets_2, h = length(test_AP)) \n\nets_3 <- ets(train_AP)\nets_fc3 <- forecast(ets_3, h = length(test_AP)) \n```\n:::\n\n\n@fig-AP-3 는 세 가지 ETS 모형의 예측 결과를 test data와 함께 나타낸 그래프이다. Box-Cox 변환 자료에 대한 ETS 모형의 예측 결과가 test data와 가장 근접한 것으로 보인다. Test data를 이용해서 모형을 선택하는 것이 바람직한 방식은 아니지만, 모형 비교를 위한 다른 마땅한 방법이 없는 상황을 고려하였다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- autoplot(ets_fc1, include = 0) +\n  autolayer(test_AP, color = \"red\", size = .8) + labs(y = NULL, subtitle = \"ets_fc1\")\np2 <- autoplot(ets_fc2, include = 0) +\n  autolayer(test_AP, color = \"red\", size = .8) + labs(y = NULL, subtitle = \"ets_fc2\")\np3 <- autoplot(ets_fc3, include = 0) +\n  autolayer(test_AP, color = \"red\", size = .8) + labs(y = NULL, subtitle = \"ets_fc3\")\np1/p2/p3\n```\n\n::: {.cell-output-display}\n![`AirPassengers` 자료에 대한 ETS 모형의 예측 결과 비교](5-regression_files/figure-html/fig-AP-3-1.png){#fig-AP-3 width=768}\n:::\n:::\n\n\nBox-Cox 변환 자료에 대한 ETS 모형을 최적 ETS 모형으로 선택하고, 모형 진단을 실시해 보자.\n독립성 가정을 위반하는 것으로 나타났다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_ets <- ets(train_AP, lambda = lam)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_ets)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-56-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from ETS(A,A,A)\n## Q* = 39.722, df = 24, p-value = 0.02291\n## \n## Model df: 0.   Total lags used: 24\n```\n:::\n\n\n\n**2.  ARMA 오차 회귀모형 적합**\n\n회귀모형은 분산 안정화가 필수적인 모형이며, 변환 결과에 대한 해석도 필요한 모형이다. 따라서 로그 변환된 자료를 대상으로 모형 적합을 진행해 보자.\n\n계절 성분을 dummy 변수로 나타내는 모형을 적합해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTime <- time(train_AP)\nMonth <- seasonaldummy(train_AP)\nfit_r1 <- auto.arima(train_AP, xreg = cbind(Time, Month),\n                     lambda = 0) \n```\n:::\n\n\n`stepwise = FALSE`를 포함시키면 실행 시간이 지나치게 오래 걸리기 때문에 제외했다. 적합 결과를 살펴보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_r1\n## Series: train_AP \n## Regression with ARIMA(1,0,0)(0,0,1)[12] errors \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##          ar1    sma1  intercept   Time  Month.Jan  Month.Feb  Month.Mar\n##       0.7766  0.1651  -236.9229  0.124     0.0127     0.0017     0.1369\n## s.e.  0.0674  0.0994     9.7959  0.005     0.0133     0.0173     0.0198\n##       Month.Apr  Month.May  Month.Jun  Month.Jul  Month.Aug  Month.Sep\n##          0.0956     0.0872     0.2124     0.3096     0.3018     0.1660\n## s.e.     0.0212     0.0220     0.0223     0.0219     0.0211     0.0195\n##       Month.Oct  Month.Nov\n##          0.0254    -0.1166\n## s.e.     0.0170     0.0128\n## \n## sigma^2 = 0.001265:  log likelihood = 237.46\n## AIC=-442.92   AICc=-437.64   BIC=-398.32\n```\n:::\n\n\n잔차에 계절형과 비계절형 요소가 모두 남아 있는 것을 알 수 있다. 모형 검진을 실시해 보자. 큰 문제는 없는 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_r1)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-59-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from Regression with ARIMA(1,0,0)(0,0,1)[12] errors\n## Q* = 21.798, df = 22, p-value = 0.472\n## \n## Model df: 2.   Total lags used: 24\n```\n:::\n\n\n이번에는 Fourier series 변수를 사용한 회귀모형을 적합해 보자. 먼저 최적 차수를 확인하자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTime <- time(train_AP)\nres <- vector(\"numeric\", 6)\nfor(i in seq(res)){\n  xreg <- cbind(Time, fourier(train_AP, K = i))\n  fit <- auto.arima(train_AP, xreg = xreg, \n                    lambda = 0)\n  res[i] <- fit$aicc\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n(min_k <- which.min(res))\n## [1] 5\n```\n:::\n\n\n\n$K=5$ 가 최적 차수로 확인되었다. 최적 차수에 의한 Fourier series 변수를 사용한 회귀모형을 적합하고 결과를 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTime <- time(train_AP)\nFourier <- fourier(train_AP, K = min_k)\nfit_r2 <- auto.arima(train_AP, xreg = cbind(Time, Fourier),\n                     lambda = 0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_r2)\n## Series: train_AP \n## Regression with ARIMA(2,0,0)(1,0,0)[12] errors \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##          ar1     ar2    sar1  intercept    Time  Fourier.S1-12  Fourier.C1-12\n##       0.6384  0.1782  0.2060  -233.8237  0.1224        -0.0464        -0.1379\n## s.e.  0.0910  0.0964  0.1057    12.3191  0.0063         0.0090         0.0090\n##       Fourier.S2-12  Fourier.C2-12  Fourier.S3-12  Fourier.C3-12  Fourier.S4-12\n##              0.0773        -0.0259        -0.0107         0.0264         0.0245\n## s.e.         0.0051         0.0051         0.0039         0.0039         0.0036\n##       Fourier.C4-12  Fourier.S5-12  Fourier.C5-12\n##              0.0261         0.0206         0.0060\n## s.e.         0.0036         0.0036         0.0036\n## \n## sigma^2 = 0.001256:  log likelihood = 237.75\n## AIC=-443.49   AICc=-438.21   BIC=-398.89\n## \n## Training set error measures:\n##                     ME     RMSE      MAE         MPE     MAPE      MASE\n## Training set 0.1302685 8.156184 6.052862 -0.05051831 2.597827 0.2118306\n##                    ACF1\n## Training set 0.09399082\n```\n:::\n\n\n잔차에 계절형과 비계절형 요소가 모두 남아 있는 것을 알 수 있다. 모형 검진을 실시해 보자. 큰 문제가 없는 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_r2)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-64-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from Regression with ARIMA(2,0,0)(1,0,0)[12] errors\n## Q* = 17.88, df = 21, p-value = 0.6566\n## \n## Model df: 3.   Total lags used: 24\n```\n:::\n\n\n이제 두 모형 중 한 모형을 최적 모형으로 선택해야 한다. 사실 두 모형은 거의 동일한 모형이다. 두 번째 모형이 11개의 Fourier series 변수 중 10개 사용한 모형이기 때문인데, 만일 $K=6$ 이 선택되어 11개의 Fourier series 변수를 모두 사용한다면 dummy 변수를 사용한 모형과 사실상 동일한 모형이 된다. 두 모형의 AICc를 근거로 한 모형을 선택해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(fit_r1$aicc, fit_r2$aicc)\n## [1] -437.6420 -438.2119\n```\n:::\n\n\n두 번째 모형의 AICc가 조금 더 작은 값으로 계산되었다. 따라서 Fourier series 변수를 사용한 모형을 최적 회귀모형으로 선택하자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_reg <- fit_r2\n```\n:::\n\n\n**3.  ARIMA 모형 적합**\n\nARIMA 모형도 회귀모형의 경우처럼 분산 안정화가 필수적인 모형이며, 변환 결과에 대한 해석도 필요한 모형이다. 따라서 로그 변환된 자료를 대상으로 모형 적합을 진행해 보자. 우선 로그 변환된 자료에 대한 시계열 그래프와 표본 ACF를 작성해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_AP |> \n  log() |> \n  ggtsdisplay()\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-67-1.png){width=672}\n:::\n:::\n\n\n뚜렷한 추세와 계절 성분이 있는 자료임을 알 수 있다. 계절 차분을 실시하고, 그 결과를 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_AP |> \n  log() |> \n  diff(lag = 12) |> \n  ggtsdisplay()\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-68-1.png){width=672}\n:::\n:::\n\n\n시계열 그래프와 ACF로는 1차 차분이 더 필요한지 여부를 확실하게 결정하기 어려워 보인다.\n이런 상황에서는 계절 차분만 실시한 자료에 대한 ARIMA 모형 적합도 시도해 볼 필요가 있는 것으로 보인다.\n\n계절 차분된 자료에 1차 차분을 추가로 실시하고, 그 결과를 확인해 보자. 비정상성 요소가 완전히 제거된 것을 볼 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_AP |> \n  log() |> \n  diff(lag = 12) |> \n  diff() |> \n  ggtsdisplay()\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-69-1.png){width=672}\n:::\n:::\n\n\n단위근 검정 결과를 확인해 보자. 계절 차분과 1차 차분이 모두 필요한 것으로 나타난다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_AP |> \n  log() |> \n  ndiffs()\n## [1] 1\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_AP |> \n  log() |> \n  nsdiffs()\n## [1] 1\n```\n:::\n\n\n단위근 검정 결과에도 불구하고 1차 차분이 명확하게 필요한 상황으로 판단하기 어렵다고 보고, 계절 차분만 실시한 경우와 계절 차분과 1차 차분을 모두 실시한 경우에 대해서 각각 ARIMA 모형을 적합시켜 보자. \n먼저 계절 차분과 1차 차분을 모두 실시한 자료를 대상으로 ARIMA 모형을 적합해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_a1 <- auto.arima(train_AP, lambda = 0, \n                    stepwise = FALSE)\n```\n:::\n\n\n적합 결과는 다음과 같다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_a1)\n## Series: train_AP \n## ARIMA(0,1,1)(0,1,1)[12] \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##           ma1     sma1\n##       -0.3424  -0.5405\n## s.e.   0.1009   0.0877\n## \n## sigma^2 = 0.001432:  log likelihood = 197.51\n## AIC=-389.02   AICc=-388.78   BIC=-381\n## \n## Training set error measures:\n##                      ME     RMSE     MAE         MPE     MAPE      MASE\n## Training set -0.2372088 8.835339 6.51704 -0.07508532 2.637955 0.2280753\n##                    ACF1\n## Training set 0.04249699\n```\n:::\n\n\n모형 검진 결과에서는 어떤 문제도 발견되지 않았다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_a1)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-74-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from ARIMA(0,1,1)(0,1,1)[12]\n## Q* = 20.34, df = 22, p-value = 0.5618\n## \n## Model df: 2.   Total lags used: 24\n```\n:::\n\n\n이번에는 계절 차분만을 실시한 자료를 대상으로 ARIMA 모형을 적합해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_a2 <- auto.arima(train_AP, d = 0, lambda = 0, \n                     stepwise = FALSE)\n```\n:::\n\n\n적합 결과는 다음과 같다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_a2\n## Series: train_AP \n## ARIMA(2,0,0)(0,1,1)[12] with drift \n## Box Cox transformation: lambda= 0 \n## \n## Coefficients:\n##          ar1     ar2     sma1   drift\n##       0.6159  0.2356  -0.5562  0.0101\n## s.e.  0.0944  0.0965   0.0898  0.0010\n## \n## sigma^2 = 0.001382:  log likelihood = 201.77\n## AIC=-393.53   AICc=-392.95   BIC=-380.12\n```\n:::\n\n\n모형 검진을 실시해 보면, 모든 가정이 만족되는 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_a2)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-77-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from ARIMA(2,0,0)(0,1,1)[12] with drift\n## Q* = 20.83, df = 21, p-value = 0.4694\n## \n## Model df: 3.   Total lags used: 24\n```\n:::\n\n\n이제 두 모형 중 하나의 모형을 선택해 보자. 두 모형은 차분을 실시한 횟수가 각기 다른 자료를 사용한 것이기 때문에 AICc 등의 비교는 의미가 없다. 따라서 Test data를 대상으로 더 근접한 예측 결과를 산출하는 모형을 선택하기로 하자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc_a1 <- forecast(fit_a1, h = length(test_AP))\nfc_a2 <- forecast(fit_a2, h = length(test_AP))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- autoplot(fc_a1, include = 0) +\n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(y = NULL, subtitle = \"fc_a1\")\np2 <- autoplot(fc_a2, include = 0) +\n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(y = NULL, subtitle = \"fc_a2\")\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![ARIMA 모형의 예측 결과](5-regression_files/figure-html/fig-AP-4-1.png){#fig-AP-4 width=768}\n:::\n:::\n\n\n두 번째 모형인 ARIMA(2,0,0)(0,1,1)~12~의 예측 결과가 test data에 더 근접한 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_arima <- fit_a2\n```\n:::\n\n\n이제는 ETS 모형과 ARIMA 모형, 그리고 ARMA 오차 회귀모형의 예측 결과를 비교해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_t <- cbind(Time = time(test_AP), \n               Fourier = fourier(test_AP, K = min_k))\nfc_reg <- forecast(fit_r2, xreg = new_t)\n\nfc_ets <- forecast(fit_ets, h = length(test_AP))\nfc_arima <- forecast(fit_arima, h = length(test_AP))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_reg, test_AP)\n##                       ME      RMSE       MAE         MPE     MAPE      MASE\n## Training set   0.1302685  8.156184  6.052862 -0.05051831 2.597827 0.2118306\n## Test set     -10.8769174 22.234136 15.437231 -2.58040955 3.488570 0.5402531\n##                    ACF1 Theil's U\n## Training set 0.09399082        NA\n## Test set     0.39683635 0.4785114\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_ets, test_AP)\n##                      ME      RMSE       MAE        MPE     MAPE      MASE\n## Training set  0.1851383  9.164883  6.647767  0.1873228 2.862835 0.2326503\n## Test set     -6.3756691 19.752432 14.199026 -1.4099460 3.219620 0.4969199\n##                   ACF1 Theil's U\n## Training set 0.3728555        NA\n## Test set     0.1682524 0.4355005\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_arima, test_AP)\n##                       ME      RMSE       MAE         MPE     MAPE      MASE\n## Training set  0.05350955  8.616827  6.212913  0.05341167 2.560180 0.2174318\n## Test set     -3.33508240 14.125641 10.626775 -0.66418334 2.356519 0.3719027\n##                    ACF1 Theil's U\n## Training set 0.04419876        NA\n## Test set     0.14856147 0.2945598\n```\n:::\n\n\nARIMA 모형의 예측 오차가 가장 작은 것으로 나타났다. 예측 결과를 그래프로 비교해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- autoplot(fc_reg, include = 0) + \n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(x=NULL, y=NULL) \np2 <- autoplot(fc_arima, include = 0) + \n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(x=NULL, y=NULL) \np3 <- autoplot(fc_ets, include = 0) + \n  autolayer(test_AP, color = \"red\", size = 1) +\n  labs(x=NULL, y=NULL)\n\np1 + p2 + p3\n```\n\n::: {.cell-output-display}\n![`AirPassengers` 자료에 대한 예측 결과 비교](5-regression_files/figure-html/fig-AP-5-1.png){#fig-AP-5 width=768}\n:::\n:::\n\n\n## ARMA 오차 Dynamic 회귀모형 {-}\n\n\n-   예제 : 2014년 호주 빅토리아주의 일일 전기 수요량 자료 (`fpp2::elecdaily`)\n\n`elecdaily`는 $365 \\times 3$ 의 ts 객체 행렬이다. 처음 3개 행을 출력해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nelecdaily[1:3,]\n##        Demand WorkDay Temperature\n## [1,] 174.8963       0        26.0\n## [2,] 188.5909       1        23.0\n## [3,] 188.9169       1        22.2\n```\n:::\n\n\n첫 번째 열인 `Demand`는 일일 전기 수요량이고, 두 번째 열인 `WorkDay`는 휴일이면 0, 근무일이면 1을 값으로 갖고 있으며, 세 번째 열인 `Temperature`는 당일 최고 기온이다. \n세 변수의 시계열 그래프를 @fig-elecd-1 에 작성해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(elecdaily, facets = TRUE)\n```\n\n::: {.cell-output-display}\n![자료 `elecdaily`를 구성하고 있는 세 변수의 시계열 그래프](5-regression_files/figure-html/fig-elecd-1-1.png){#fig-elecd-1 width=672}\n:::\n:::\n\n\n시계열자료 행렬 `elecdaily`의 각 열을 개별 시계열자료로 분리해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDemand <- elecdaily[,1]\nWork <- elecdaily[,2]\nTemp <- elecdaily[,3]\n```\n:::\n\n\n세 시계열자료는 동일한 기간과 주기를 갖고 있는데, 변수 `Demand`로 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart(Demand); end(Demand); frequency(Demand)\n## [1] 1 4\n## [1] 53  4\n## [1] 7\n```\n:::\n\n\n시작 시점은 2014년 첫 번째 주 네 번째 날이고, 종료 시점은 2014년 53번째 주 네 번째 날이다. 일일 자료이므로 주기는 7로 설정되어 있다. 주 중 네 번째 날의 요일은 다음과 같이 패키지 `lubridate`의 함수 `wday()`로 할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nwday(ymd(\"2014-1-1\"), label = TRUE)\n## [1] 수\n## Levels: 일 < 월 < 화 < 수 < 목 < 금 < 토\n```\n:::\n\n\n반응변수인 `Demand`와 셜명변수인 `Temp`의 정상성 만족 여부를 확인해 보자. 두 변수 모두 차분이 필요한 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDemand |> \n  ggtsdisplay(main = \"Demand\")\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-88-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nTemp |> \n  ggtsdisplay(main = \"Temperature\")\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-89-1.png){width=672}\n:::\n:::\n\n\n단위근 검정 결과도 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nndiffs(Demand)\n## [1] 1\nndiffs(Temp)\n## [1] 1\n```\n:::\n\n\n이제 두 변수의 관계를 산점도를 이용해서 살펴보자. @fig-elecd-2 에서 두 변수 사이에 2차 함수의 관계가 있음을 볼 수 있다. 회귀모형에 변수 `Temp`의 제곱항도 포함시켜야 할 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(Demand, Temp) |> \n  ggplot(aes(x = as.numeric(Temp), y = as.numeric(Demand))) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  labs(x = \"Temperature\", y = \"Demand\")\n```\n\n::: {.cell-output-display}\n![`Demand`와 `Temperature`의 산점도](5-regression_files/figure-html/fig-elecd-2-1.png){#fig-elecd-2 width=672}\n:::\n:::\n\n\nDynamic 회귀모형을 적합시켜보자. 함수 `auto.arima()`에 설명변수 `Temp`와 `Temp^2`, `Work`를 행렬 형태로 `xreg`에 지정해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxreg <- cbind(Temp, Temp2 = Temp^2, Work)\nfit <- auto.arima(Demand, xreg = xreg, stepwise = FALSE)\n```\n:::\n\n\n적합 결과를 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit)\n## Series: Demand \n## Regression with ARIMA(2,1,1)(2,0,0)[7] errors \n## \n## Coefficients:\n##          ar1      ar2      ma1    sar1    sar2     Temp   Temp2     Work\n##       0.8246  -0.0225  -0.9805  0.2216  0.4006  -7.8848  0.1849  30.3212\n## s.e.  0.0704   0.0673   0.0199  0.0521  0.0564   0.4468  0.0088   1.3402\n## \n## sigma^2 = 44.7:  log likelihood = -1205.77\n## AIC=2429.54   AICc=2430.04   BIC=2464.61\n## \n## Training set error measures:\n##                      ME     RMSE      MAE         MPE     MAPE      MASE\n## Training set 0.01265983 6.602908 4.768043 -0.09527382 2.159183 0.3273789\n##                      ACF1\n## Training set -0.001104215\n```\n:::\n\n\n적합된 회귀모형에 절편이 없는 것을 볼 수 있는데, 이것은 차분을 실시한 자료를 대상으로 회귀모형을 적합시켰기 때문이다.\n\n적합된 모형의 진단을 실시해 보자. 독립성 가정에는 문제가 있는 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-93-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from Regression with ARIMA(2,1,1)(2,0,0)[7] errors\n## Q* = 36.211, df = 9, p-value = 3.637e-05\n## \n## Model df: 5.   Total lags used: 14\n```\n:::\n\n\n이제 적합된 Dynamic 회귀모형을 이용해서 2015년 1월 1이부터 1월 10일까지의 전력 수요량을 예측해 보자. 이 때 문제가 되는 것은 해당 기간에 대한 변수 `Temp`의 값도 미리 알 수 없다는 것이다. 이 문제는 변수 `Temp`의 미래 값을 다른 방법으로 예측해서 사용하거나, 특정한 값으로 가정하고 `Demand`의 미래 값을 예측해야 한다.\n\n여기에서는 2014년 1월 1일부터 1월 10일까지의 `Temp` 값을 그대로 사용해서 예측을 실시해 보자. 변수 `Work`의 값은 2015년 1월 1일 목요일부터 1월 10일 토요일까지 휴일과 근무일을 구분해서 입력할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nold_T <- Temp[1:10]\nnew_x <- cbind(Temp = old_T, Temp2 = old_T^2,\n               Work = c(0,1,0,0,1,1,1,1,1,0))\nfc <- forecast(fit, xreg = new_x)\n```\n:::\n\n\n예측 결과에 대한 그래프를 작성해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(fc)\n```\n\n::: {.cell-output-display}\n![`Demand`의 예측 결과](5-regression_files/figure-html/fig-elecd-3-1.png){#fig-elecd-3 width=672}\n:::\n:::\n\n\n-   예제: 미국 소득, 소비 등의 1970년 1분기부터 2016년 3분기까지 분기별 변화 비율 (`fpp2::uschange`)\n\n`uschange`는 $187 \\times 5$ 의 ts 객체 행렬이다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuschange[1:3,]\n##      Consumption   Income Production  Savings Unemployment\n## [1,]   0.6159862 0.972261 -2.4527003 4.810312          0.9\n## [2,]   0.4603757 1.169085 -0.5515251 7.287992          0.5\n## [3,]   0.8767914 1.553271 -0.3587079 7.289013          0.5\n```\n:::\n\n\n다섯 개 시계열자료는 동일한 시작 시점, 종료 시점과 주기를 갖고 있는데, 첫 번째 시계열자료를 이용해서 확인해 보자. 분기별 자료이므로 주기는 4이고, 시작 시점은 1970년 1분기이며, 종료 시점은 2016년 3분기이다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart(uschange[,1])\n## [1] 1970    1\nend(uschange[,1])\n## [1] 2016    3\nfrequency(uschange[,1])\n## [1] 4\n```\n:::\n\n\n첫 번째 시계열자료인 `Consumption`에 대한 예측 모형을 적합해 보자. ARIMA 모형과 ETS 모형에 의한 예측 모형, ARMA 오차 회귀모형, 그리고 행렬 `uschange`의 다른 시계열자료를 설명변수로 사용하는 dynamic 회귀모형에 의한 예측 모형을 적합해 보자.\n\n`uschange`를 구성하고 있는 다섯 변수의 시계열 그래프를 @fig-uschange-1 에 작성해 보자.\n뚜렷한 추세나 계절 성분이 있는 시계열자료는 없는 것으로 보인다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(uschange, facets=TRUE) + \n  labs(y = NULL, x = NULL)\n```\n\n::: {.cell-output-display}\n![`uschange`의 다섯 시계열자료의 그래프](5-regression_files/figure-html/fig-uschange-1-1.png){#fig-uschange-1 width=672}\n:::\n:::\n\n\n다섯 시계열자료의 ACF는 함수 `ggAcf()`에 개별 시계열자료를 각각 입력해서 작성할 수도 있지만, 조금은 번거로운 작업이 된다. 대신 함수 `ggAcf()`에 행렬 `uschange`를 그대로 입력하면 두 변수씩의 모든 조합에 대한 상관 행렬이 작성되는데, 그 중 대각 패널에 각 변수의 ACF가 작성된다. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggAcf(uschange)\n```\n\n::: {.cell-output-display}\n![`uschange`의 다섯 시계열자료의 표본 ACF](5-regression_files/figure-html/fig-uschange-2-1.png){#fig-uschange-2 width=672}\n:::\n:::\n\n\n@fig-uschange-1 과 @fig-uschange-2 을 근거로 다섯 시계열자료는 모두 정상성을 만족하고 있는 것으로 보인다.\n\nDynamic 회귀모형에서 설명변수로 사용할 수 있는 시계열자료는 `Income`, `Production`, `Savings`, 그리고 `Unemployment`이다. 함수 `GGally::ggpairs()`로 다섯 변수의 산점도 행렬을 작성해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGGally::ggpairs(as_tibble(uschange) |> \n                  relocate(Consumption, .after=last_col()),\n                lower=list(continuous=\"smooth_loess\"))\n```\n\n::: {.cell-output-display}\n![`uschange`의 다섯 시계열자료의 산점도 행렬](5-regression_files/figure-html/fig-uschange-3-1.png){#fig-uschange-3 width=768}\n:::\n:::\n\n\n변수 (`Income`, `Savings`)과 (`Production`, `Uneployment`) 사이에 높은 관련성이 있는 것으로 보여서, 변수 `Income`과 `Production`만을 설명변수로 포함시키고자 한다. 엄격하고 타당한 변수 선택 방식은 아니지만 가능하면 간단한 모형을 구성하고자 한다.\n\n이제 자료를 분리하고 예측 모형을 적합시켜보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuschange_te <- tail(uschange, n = 8)\nuschange_tr <- head(uschange, n = nrow(uschange)-8)\n```\n:::\n\n\nARIMA 모형을 적합하고, 결과를 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_arima <- auto.arima(uschange_tr[,1], \n                   stepwise = FALSE, approximation = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_arima\n## Series: uschange_tr[, 1] \n## ARIMA(3,0,0)(2,0,0)[4] with non-zero mean \n## \n## Coefficients:\n##          ar1     ar2     ar3     sar1     sar2    mean\n##       0.2267  0.1771  0.2218  -0.0351  -0.1792  0.7482\n## s.e.  0.0739  0.0738  0.0726   0.0774   0.0745  0.0951\n## \n## sigma^2 = 0.3544:  log likelihood = -158.39\n## AIC=330.78   AICc=331.44   BIC=353.09\n```\n:::\n\n\nETS 모형을 적합하고, 결과를 확인해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_ets <- ets(uschange_tr[,1])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_ets\n## ETS(A,N,N) \n## \n## Call:\n## ets(y = uschange_tr[, 1])\n## \n##   Smoothing parameters:\n##     alpha = 0.3315 \n## \n##   Initial states:\n##     l = 0.6877 \n## \n##   sigma:  0.633\n## \n##      AIC     AICc      BIC \n## 768.8004 768.9376 778.3626\n```\n:::\n\n\n관측 시점만을 설명변수로 사용하는 ARMA 오차 회귀모형을 적합해 보자. 추세 변수는 함수 `time()`으로 생성하고, 계절 성분은 dummy 변수로 표현해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTime <-  time(uschange_tr[,1])\nQtr <-  seasonaldummy(uschange_tr[,1])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_reg <- auto.arima(uschange_tr[,1],\n                      xreg = cbind(Time, Qtr),\n                      stepwise = FALSE, approximation = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_reg\n## Series: uschange_tr[, 1] \n## Regression with ARIMA(3,0,0)(0,0,2)[4] errors \n## \n## Coefficients:\n##          ar1     ar2     ar3     sma1     sma2   Time  Qtr.Q1  Qtr.Q2  Qtr.Q3\n##       0.2564  0.1608  0.2482  -0.1066  -0.1942  3e-04  0.0554  0.0122   0.172\n## s.e.  0.0742  0.0737  0.0729   0.0773   0.0707  1e-04  0.0700  0.0748   0.070\n## \n## sigma^2 = 0.349:  log likelihood = -155.52\n## AIC=331.03   AICc=332.34   BIC=362.91\n```\n:::\n\n\nDynamic 회귀모형도 적합해 보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_dyn <- auto.arima(uschange_tr[,1], d = 0,     \n                   xreg = uschange_tr[,c(2,3)], \n                   stepwise = FALSE, approximation = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_dyn\n## Series: uschange_tr[, 1] \n## Regression with ARIMA(3,0,0) errors \n## \n## Coefficients:\n##          ar1     ar2     ar3  intercept  Income  Production\n##       0.0060  0.1960  0.1890     0.5288  0.1741      0.1758\n## s.e.  0.0813  0.0734  0.0735     0.0708  0.0457      0.0262\n## \n## sigma^2 = 0.2696:  log likelihood = -133.71\n## AIC=281.41   AICc=282.07   BIC=303.72\n```\n:::\n\n\n적합시킨 네 모형에 대한 모형 검진도 실시해 보자.\n다른 가정 사항에는 모든 모형에 문제가 없는 것으로 나타났지만,\nLjung-Box 검정 결과에서 ETS 모형이 독립성 가정을 위반하고 있는 것으로 보인다. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_arima)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-107-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from ARIMA(3,0,0)(2,0,0)[4] with non-zero mean\n## Q* = 0.6507, df = 3, p-value = 0.8847\n## \n## Model df: 5.   Total lags used: 8\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_ets)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-108-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from ETS(A,N,N)\n## Q* = 15.865, df = 8, p-value = 0.04436\n## \n## Model df: 0.   Total lags used: 8\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_reg)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-109-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from Regression with ARIMA(3,0,0)(0,0,2)[4] errors\n## Q* = 0.32544, df = 3, p-value = 0.9552\n## \n## Model df: 5.   Total lags used: 8\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(fit_dyn)\n```\n\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-110-1.png){width=672}\n:::\n\n```\n## \n## \tLjung-Box test\n## \n## data:  Residuals from Regression with ARIMA(3,0,0) errors\n## Q* = 1.5616, df = 5, p-value = 0.9059\n## \n## Model df: 3.   Total lags used: 8\n```\n:::\n\n\n이제 test data에 대한 예측을 실시해 보자. 모형 `fit_dyn`의 경우에는 test data 시점에서 설명변수의 관측 문제가 있지만, 다른 모형과의 비교를 위해서 설명변수의 값이 알려져 있다고 가정하겠다. 이 가정으로 모형 `fit_dyn`의 예측은 결과가 더 좋게 나올 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc_arima <- forecast(fit_arima, h = 8)\nfc_ets <- forecast(fit_ets, h = 8)\nfc_dyn <- forecast(fit_dyn, \n                   xreg = uschange_te[,c(2,3)])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nTime <-  time(uschange_te[,1])\nQtr <-  seasonaldummy(uschange_te[,1])\nfc_reg <- forecast(fit_reg, \n                   xreg = cbind(Time, Qtr))\n```\n:::\n\n\n예측 결과를 test data와 비교해 보자.\n모형 `fit_dyn`의 예측 오류가 가장 작은 것으로 나타났다. \nETS 모형도 예측 오류가 다른 모형보다 비교적 작은 것으로 나타났다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_arima, uschange_te[,1])\n##                         ME      RMSE       MAE       MPE      MAPE     MASE\n## Training set  0.0002559072 0.5852267 0.4396851  65.90037 189.15841 0.670526\n## Test set     -0.0475341277 0.2500710 0.2185770 -17.75795  33.64265 0.333333\n##                     ACF1 Theil's U\n## Training set  0.00952753        NA\n## Test set     -0.21075717 0.6797118\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_ets, uschange_te[,1])\n##                         ME      RMSE       MAE       MPE      MAPE      MASE\n## Training set  0.0008292707 0.6294144 0.4622752  15.94476 163.66594 0.7049764\n## Test set     -0.0071405456 0.2275948 0.1819332 -11.07730  27.12135 0.2774507\n##                      ACF1 Theil's U\n## Training set -0.004088847        NA\n## Test set     -0.208694082 0.5901059\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_reg, uschange_te[,1])\n##                         ME      RMSE       MAE       MPE      MAPE      MASE\n## Training set  0.0008586772 0.5757214 0.4336545  62.73093 184.11947 0.6613293\n## Test set     -0.0460208935 0.2877620 0.2542229 -18.22233  37.33168 0.3876936\n##                      ACF1 Theil's U\n## Training set  0.003604112        NA\n## Test set     -0.360236166 0.7215638\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(fc_dyn, uschange_te[,1])\n##                         ME      RMSE       MAE       MPE     MAPE      MASE\n## Training set -0.0006526438 0.5104141 0.3844923 43.024517 189.5903 0.5863563\n## Test set      0.1004867937 0.2061923 0.1498566  8.058113  18.8564 0.2285334\n##                      ACF1 Theil's U\n## Training set  0.002548898        NA\n## Test set     -0.413909940 0.6493148\n```\n:::\n\n\n예측 결과를 그래프로 나타내서 비교해 보자.\nETS 모형의 경우 비교적 작은 예측 오류가 나왔지만 모든 시점에서 동일한 예측 결과을 보이는 모형이 선택되었고, 예측 구간의 폭이 가장 넓다는 점을 고려한다면, 바람직한 예측 모형은 아니라고 하겠다.  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_lim <- c(-1, 2.5)\np1 <- autoplot(fc_arima, include = 8) + \n  autolayer(uschange_te[,1], color = \"red\", size = .8) + \n  ylab(NULL) + ylim(y_lim[1], y_lim[2])\np2 <- autoplot(fc_ets, include = 8) + \n  autolayer(uschange_te[,1], color = \"red\", size = .8) + \n  ylab(NULL) + ylim(y_lim[1], y_lim[2])\np3 <- autoplot(fc_reg, include = 8) + \n  autolayer(uschange_te[,1], color = \"red\", size = .8) + \n  ylab(NULL) + ylim(y_lim[1], y_lim[2])\np4 <- autoplot(fc_dyn, include = 8) + \n  autolayer(uschange_te[,1], color = \"red\", size = .8) + \n  ylab(NULL) + ylim(y_lim[1], y_lim[2])\n\n(p1 + p2) / (p3 + p4)\n```\n\n::: {.cell-output-display}\n![`uschange`의 `Consumption`에 대한 예측 결과 비교](5-regression_files/figure-html/fig-uschange-4-1.png){#fig-uschange-4 width=768}\n:::\n:::\n\n\n\n\n## 연습문제 {-}\n\n**1.** 파일 `total_energy.csv`에는 1997년 1월부터 2023년 2월까지 연료원별 발전된 전기의 월별 소비량 자료가 입력되어 있으며,\n웹 서버 `https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/` 에서 불러올 수 있다.\n\n\n::: {.cell}\n\n:::\n\n\n변수로는 관측 시점(`time`)과 석탄(`coal`), 석유(`oil`), 액화천연가스(`gas`), 수력(`water`), 원자력(`neclear`), 신재생 및 기타(`renewal`)를 원료로 발전된 전기의 소비량이다.\n자료의 처음과 마지막 5 케이스는 다음과 같다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntotal_energy |> slice_head(n = 5)\n## # A tibble: 5 × 7\n##   time    coal   oil   gas water neclear renewal\n##   <chr>  <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>\n## 1 Jan-97  2820 10749  1796    95    1521     103\n## 2 Feb-97  2490  9049  1435    76    1255      99\n## 3 Mar-97  2995  9776  1482    73    1195     109\n## 4 Apr-97  2646  8683  1250    80    1431     113\n## 5 May-97  2855  8287  1181   111    1468     116\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntotal_energy |> slice_tail(n = 5)\n## # A tibble: 5 × 7\n##   time    coal   oil   gas water neclear renewal\n##   <chr>  <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>\n## 1 22-Oct  5128  9469  3954   123    3063    2020\n## 2 22-Nov  5237  9607  4674   112    2983    1859\n## 3 22-Dec  6136 10987  7491   109    3244    1952\n## 4 23-Jan  5993 10164  6860   110    3335    2092\n## 5 23-Feb  5333  9172  5823    91    2898    1926\n```\n:::\n\n\n\n**1)** `total_energy`에 있는 6가지 원료별 전기 소비량의 추이를 살펴보고 서로 비교할 수 있는 그래프를 작성하라. 6가지 연료별 전기 소비량에는 어떤 변화가 있었는지 설명하라. \n\n**2)** 석탄(`coal`)과 신재생 에너지(`renewal`) 시계열자료에 대한 예측 모형을 수립하고자 한다. 모형 적합을 위한 training data는 2010년 1월부터 2020년 12월까지로 하고, 예측 결과의 확인을 위한 test data는 2021년 1월 이후 자료로 한다. \n\n- 자료 `renewal`과 `coal`을 구성하고 있는 추세, 계절 및 불규칙 성분을 분해하고, 그 특징을 설명하라.\n\n- 자료 `renewal`에 대하여 ETS 모형, 계절형 ARIMA 모형, ARMA 오차 회귀모형을 각각 적합하고 적합 결과를 설명하며, test data에 대한 예측을 실시하고 그 결과를 비교해 보자.  \n\n- 자료 `coal`에 대하여 ETS 모형, 계절형 ARIMA 모형, ARMA 오차 회귀모형, `renewal`을 설명변수로 사용하는 ARMA 오차 dynamic 회귀모형을 각각 적합하고 적합 결과를 설명하며, test data에 대한 예측을 실시하고 그 결과를 비교해 보자.\n\n\n**2.** 파일 `PCI.csv`의 변수 `income`에는 우리나라 1인당 국민소득 자료가 입력되어 있고, 변수 `time`에는 자료의 관측 시점이 입력되어 있으며, 웹 서버 `https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/` 에서 불러올 수 있다. 국민소득 자료에 대한 시계열 그래프는 다음과 같다. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-120-1.png){width=672}\n:::\n:::\n\n\n\n**1)** 1990년부터 2023년까지 관측된 자료를 대상으로 분석을 실시하고자 한다. 가장 최근 7년 자료는 모형 평가를 위한 test data로 분리하고, 나머지 자료만으로 모형 적합을 실시하기로 한다. 모형 적합에 사용될 자료의 자료의 특성을 그래프를 이용해서 설명하라. \n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n**2)** 자료가 정상상을 만족하고 있는지 판단하라. 만일 만족되지 않는다고 생각한다면, 어떤 변환을 실시해야 정상성을 만족시킬 수 있는지 확인하라. \n\n\n\n\n\n**3)** 1인당 국민소득 자료에 대해 ETS 모형을 적합하고, 적합 결과를 설명하라. 모형 검진은 생략한다.\n\n\n::: {.cell}\n\n:::\n\n\n\n\n**4)** 1인당 국민소득 자료에 대해 ARIMA 모형을 적합해 보자. 표본 ACF와 PACF를 근거로 모형식별을 진행하고, 함수 `auto.arima()`에 의한 결과와 비교하라. 추정된 모형식을 작성하고, 적합 결과를 설명하라. 함수 `auto.arima()`에서 `stepwise`와 `approximation`은 모두 `FALSE`로 지정한다. 또한 모형 검진은 생략한다.\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n**5)** 1인당 국민소득 자료에 대해 ARMA 오차 회귀모형을 적합하라. 적합된 회귀모형식을 작성하고, 결과를 설명하라. 모형 검진은 생략한다.\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n**6)** 추정된 ETS 모형, ARIMA 모형, ARMA 오차 회귀모형을 이용해서 test data에 대한 예측을 실시하라. 예측 오차와 예측결과 그래프를 이용해서, 세 예측 모형의 예측 결과를 비교, 평가하라. \n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n**3.** 파일 `Credit_card2.csv`의 `num`에는 우리나라 신용카드 개인 할부구매 이용 건수 자료가 입력되어 있고, `time`에는 관측 시점이 입력되어 있으며,  웹 서버 `https://raw.githubusercontent.com/yjyjpark/TS-with-R/main/Data/` 에서 불러올 수 있다. 신용카드 개인 할부구매 이용 건수 자료에 대한 시계열 그래프는 다음과 같다.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-regression_files/figure-html/unnamed-chunk-134-1.png){width=672}\n:::\n:::\n\n\n\n**1)** 마지막 24개월 자료는 모형 평가를 위한 test data로 분리하고, 나머지 자료만으로 모형 적합을 실시하기로 한다. \n모형 적합에 사용될 자료의 특성이 잘 나타날 수 있는 그래프를 작성하고, 파악된 자료의 특성을 설명하라. \n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n**2)** 신용카드 할부 구매 건수 자료는 정상성이 만족되지 않는 자료이다. 정상성 조건 중 위반되는 조건이 무엇인지 보여줄 근거를 제시하라. \n\n\n\n\n\n\n**3)** 신용카드 할부 구매 건수 자료에 대해 ETS 모형을 적합하고, 적합 결과를 설명하라. 모형 검진은 생략한다. \n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n**4)** 신용카드 할부 구매 건수 자료에 대해 ARIMA 모형을 적합해 보자. 함수 `auto.arima()`에 의해 모형을 선택하되, 표본 ACF와 PACF에 의한 모형식별 결과와 비교해서, 필요한 수정 사항이 있는지 확인하라. 또한 추정된 계수 중 비유의적인 계수가 있는 경우, 해당 계수의 제외 가능성도 확인하라. 최종 추정된 모형의 모형식을 작성하라. 함수 `auto.arima()`에서 `stepwise`와 `approximation`은 모두 `FALSE`로 지정한다. 또한 모형 검진은 생략한다.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n**5)** 신용카드 할부 구매 건수 자료에 대해 ARMA 오차 회귀모형을 적합하라. 계절성분에 대해서는 dummy 변수를 사용하는 모형과 Fourier 변수를 사용하는 모형을 비교해서, 한 모형을 선택하라. 적합 결과에 대해 설명하라. 모형 검진은 생략한다.\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n**6)** Test data에 대해서 추정된 세 가지 예측모형의 예측을 실시하고, 예측 결과를 비교해서 최선의 결과를 보이는 예측 모형을 선택하라. 선택된 최적 예측모형의 예측 결과를 평가하라.   \n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n",
    "supporting": [
      "5-regression_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}